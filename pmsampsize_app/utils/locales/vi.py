VI = {
        "title": "Prognostic Research Sample Size Tool",
        "sidebar_title": "C·∫•u h√¨nh",
        "language": "Ng√¥n ng·ªØ / Language",
        "mode": "Ch·ªçn Ph∆∞∆°ng ph√°p",
        "mode_riley": "Ph∆∞∆°ng ph√°p 1: Riley et al. (C√¥ng th·ª©c)",
        "mode_bayes": "Ph∆∞∆°ng ph√°p 2: Bayesian Assurance (M√¥ ph·ªèng)",
        "mode_single": "K·ªãch b·∫£n ƒë∆°n (Single)",
        "mode_batch": "Ph√¢n t√≠ch ƒë·ªô nh·∫°y (Nhi·ªÅu gi√° tr·ªã)",
        "method1_tab": "Ph∆∞∆°ng ph√°p 1 (Riley)",
        "method2_tab": "Ph∆∞∆°ng ph√°p 2 (Bayesian)",
        "nav_title": "ƒêi·ªÅu h∆∞·ªõng",
        "nav_readme": "T√†i li·ªáu Chi ti·∫øt (README)",
        "nav_intro": "Gi·ªõi thi·ªáu & C√¥ng th·ª©c",
        "nav_calc": "C√¥ng c·ª• t√≠nh to√°n",
        "intro_heading": "Gi·ªõi thi·ªáu",
        "intro_text": "·ª®ng d·ª•ng h·ªó tr·ª£ ∆∞·ªõc t√≠nh c·ª° m·∫´u t·ªëi thi·ªÉu cho m√¥ h√¨nh d·ª± b√°o l√¢m s√†ng (bi·∫øn nh·ªã ph√¢n).",
        "formula_heading": "C∆° s·ªü To√°n h·ªçc (Ph∆∞∆°ng ph√°p 1)",
        "formula_intro": "Ph∆∞∆°ng ph√°p 1 d√πng c√¥ng th·ª©c gi·∫£i t√≠ch (Riley), Ph∆∞∆°ng ph√°p 2 d√πng m√¥ ph·ªèng Bayesian MCMC.",
        "sens_guide_title": "üí° H∆∞·ªõng d·∫´n nh·∫≠p Ph√¢n t√≠ch ƒê·ªô nh·∫°y",
        "sens_guide_text": """
        - **Kho·∫£ng gi√° tr·ªã**: Nh·∫≠p `min-max` (VD: `0.05-0.10`).
        - **Danh s√°ch gi√° tr·ªã**: Nh·∫≠p d·∫•u ph·∫©y (VD: `0.05, 0.10, 0.15`).
        """,
        "detail_view": "Xem chi ti·∫øt",
        "footer_refs": "T√†i li·ªáu tham kh·∫£o: Riley et al. (2018, 2020), BayesAssurance.",
        "calc_btn": "T√≠nh to√°n",
        "results": "K·∫øt qu·∫£",
        "sanity": "Ki·ªÉm tra nhanh (EPV)",
        "download_csv": "T·∫£i xu·ªëng CSV",
        "download_report": "T·∫£i B√°o c√°o ƒê·∫ßy ƒë·ªß",
        "error_p": "T·ª∑ l·ªá ph·∫£i t·ª´ 0 ƒë·∫øn 1.",
        "error_auc": "AUC ph·∫£i t·ª´ 0.5 ƒë·∫øn 1.",
        "error_parse": "L·ªói nh·∫≠p li·ªáu.",
        
        # Riley specific
        "riley_inputs": "Tham s·ªë ƒë·∫ßu v√†o (Riley)",
        "prevalence": "T·ª∑ l·ªá bi·∫øn c·ªë (Prevalence)",
        "prevalence_help": "T·ª∑ l·ªá ng∆∞·ªùi c√≥ bi·∫øn c·ªë (0 < p < 1).",
        "parameters": "S·ªë tham s·ªë d·ª± b√°o (df)",
        "parameters_help": "T·ªïng b·∫≠c t·ª± do c·ªßa c√°c bi·∫øn (tr·ª´ intercept).",
        "shrinkage": "H·ªá s·ªë co tr∆∞·ª£t (Shrinkage)",
        "shrinkage_help": "H·ªá s·ªë S mong mu·ªën (m·∫∑c ƒë·ªãnh 0.9).",
        "perf_measure": "Hi·ªáu nƒÉng d·ª± ki·∫øn",
        "perf_auc": "AUC (C-statistic)",
        "perf_r2": "Cox-Snell R-squared",
        "perf_cons": "Th·∫≠n tr·ªçng (Conservative)",
        
        # Bayesian specific
        "bayes_inputs": "C√†i ƒë·∫∑t M√¥ ph·ªèng (Bayesian Assurance)",
        "dgm_settings": "C∆° ch·∫ø Sinh D·ªØ li·ªáu (DGM)",
        "sim_settings": "C√†i ƒë·∫∑t M√¥ ph·ªèng & MCMC",
        "eval_settings": "Ti√™u chu·∫©n ƒê√°nh gi√°",
        "n_candidates": "C√°c m·ª©c C·ª° m·∫´u th·ª≠ nghi·ªám (c√°ch nhau b·ªüi d·∫•u ph·∫©y)",
        "n_candidates_help": "Danh s√°ch N mu·ªën ki·ªÉm tra, VD: 500, 1000, 1500.",
        "correlation": "H·ªá s·ªë t∆∞∆°ng quan (rho)",
        "n_sims": "S·ªë l·∫ßn m√¥ ph·ªèng cho m·ªói N",
        "assurance_threshold": "Ng∆∞·ª°ng Assurance (X√°c su·∫•t ƒë·∫°t y√™u c·∫ßu)",
        "run_simulation": "Ch·∫°y M√¥ ph·ªèng",
        "simulation_running": "ƒêang ch·∫°y m√¥ ph·ªèng... Vui l√≤ng ƒë·ª£i.",
        "assurance_result": "Ph√¢n t√≠ch Assurance",

        # Method 6 (Dev Sim)
        "mode_dev_sim": "Ph∆∞∆°ng ph√°p 6: M√¥ ph·ªèng Ph√°t tri·ªÉn (Freq)",
        "method6_tab": "PP 6 (M√¥ ph·ªèng)",
        "dev_sim_intro": "T√≠nh c·ª° m·∫´u ph√°t tri·ªÉn m√¥ h√¨nh d·ª±a tr√™n m√¥ ph·ªèng (theo ph∆∞∆°ng ph√°p `samplesizedev`).",
        "dev_mode_simple": "Ch·∫ø ƒë·ªô A: ƒê∆°n gi·∫£n (theo AUC)",
        "dev_mode_custom": "Ch·∫ø ƒë·ªô B: DGM T√πy ch·ªânh",
        "target_auc": "AUC M·ª•c ti√™u (C-statistic trung b√¨nh)",
        "target_auc_help": "Thu·∫≠t to√°n s·∫Ω t·ª± t√¨m h·ªá s·ªë Beta ƒë·ªÉ ƒë·∫°t AUC n√†y.",
        "criteria_settings": "Ti√™u ch√≠ ƒê·∫°t (Pass/Fail)",
        "crit_slope_mean": "Calibration Slope TB >= 0.9",
        "crit_slope_ci": "Pr(0.9 <= Slope <= 1.1) >= 80%",
        "crit_auc": "AUC TB >= M·ª•c ti√™u",
        "audit_trail": "RNG Audit Trail (JSON)",
        "future_methods": "S·∫Øp ra m·∫Øt...",

        # Quick Methods
        "method_quick_tab": "A. Nhanh / C∆° b·∫£n",
        "quick_mode_epv": "A1: Quy t·∫Øc EPV / EPP (Kinh nghi·ªám)",
        "quick_mode_risk": "A2: ∆Ø·ªõc l∆∞·ª£ng T·ª∑ l·ªá n·ªÅn (ƒê·ªô r·ªông CI)",
        "target_epv": "S·ªë bi·∫øn c·ªë tr√™n tham s·ªë m·ª•c ti√™u (EPP)",
        "target_epv_help": "Gi√° tr·ªã th∆∞·ªùng d√πng: 10, 15, 20. EPP t·ªët h∆°n EPV.",
        "epv_warning_title": "‚ö†Ô∏è C·∫£nh b√°o Quan tr·ªçng",
        "epv_warning_text": "EPV/EPP ch·ªâ l√† quy t·∫Øc kinh nghi·ªám th√¥. N√≥ KH√îNG ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c, ph√¢n bi·ªát hay ngƒÉn ng·ª´a overfitting. R·∫•t nh·∫°y c·∫£m v·ªõi vi·ªác ch·ªçn bi·∫øn v√† ƒëa c·ªông tuy·∫øn.",
        "ci_level": "ƒê·ªô tin c·∫≠y (Confidence Level)",
        "ci_half_width": "B√°n k√≠nh CI mong mu·ªën (Sai s·ªë bi√™n)",
        "ci_method": "Ph∆∞∆°ng ph√°p CI",
        "ci_method_wilson": "Wilson Score (Khuy√™n d√πng)",
        "ci_method_wald": "Wald (ƒê∆°n gi·∫£n)",
        "ci_method_cp": "Clopper-Pearson (Th·∫≠n tr·ªçng)",
        "risk_help": "T√≠nh N ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng t·ª∑ l·ªá p v·ªõi ƒë·ªô ch√≠nh x√°c nh·∫•t ƒë·ªãnh. KH√îNG ƒë·∫£m b·∫£o hi·ªáu nƒÉng m√¥ h√¨nh d·ª± b√°o.",
        
        # Power Methods (B)
        "title_b3": "B3: Logistic Power (Hsieh)",
        "title_b4": "B4: Cox Power (Schoenfeld)",
        "interpretation": "Gi·∫£i th√≠ch k·∫øt qu·∫£",
        
        # Validations (D)
        "title_d8": "D8: AUC Precision (Hanley-McNeil)",
        "d8_desc": "Calculate sample size for estimating AUC with desired precision (CI width).",
        "auc_expected": "AUC d·ª± ki·∫øn (C-statistic)",
        "formulas_header": "üìö C√¥ng th·ª©c & Chi ti·∫øt k·ªπ thu·∫≠t",
        "d8_assumptions": "**Gi·∫£ ƒë·ªãnh**: S·ª≠ d·ª•ng x·∫•p x·ªâ ph∆∞∆°ng sai Hanley & McNeil (1982). Gi·∫£ ƒë·ªãnh ph√¢n ph·ªëi chu·∫©n ƒë·ªëi x·ª©ng cho AUC. T·ªëi ∆∞u h√≥a s·ªë h·ªçc ƒë·ªÉ t√¨m N.",
        "d8_mode_n_to_width": "T√≠nh ƒë·ªô r·ªông CI t·ª´ N",
        "d8_mode_width_to_n": "T√≠nh N t·ª´ ƒë·ªô r·ªông CI",
        "d8_opt_settings": "C√†i ƒë·∫∑t T·ªëi ∆∞u h√≥a N√¢ng cao",
        "d8_practical_rounding": "Hi·ªÉn th·ªã l√†m tr√≤n s·ªë nguy√™n (Th·ª±c t·∫ø)",
        "d8_n_input": "C·ª° m·∫´u (N)",
        "d8_width_input": "ƒê·ªô r·ªông CI (T·ªïng)",
        "d8_opt_bound": "C·∫≠n tr√™n t√¨m ki·∫øm (Upper Limit)",
        "d8_opt_tol": "Dung sai (Tolerance)",
        
        # D9
        "title_d9": "D9: Th·∫©m ƒë·ªãnh ngo√†i (Tailored)",
        "common_inputs": "Tham s·ªë chung",
        
        # UI Basics
        "intro_heading": "Ch√†o m·ª´ng ƒë·∫øn v·ªõi Prognostic Research Sample Size Tool",
        "search_placeholder": "T√¨m ph∆∞∆°ng ph√°p...",
        "settings": "C√†i ƒë·∫∑t",

        # Footer
        "footer_copyright": "¬© 2026 Prognostic Research Sample Size Tool. D√†nh cho nghi√™n c·ª©u/h·ªçc thu·∫≠t. Kh√¥ng b√°n th∆∞∆°ng m·∫°i.",
        "footer_author": "T√°c gi·∫£ & B·∫£o tr√¨: Minh Nguyen (minhnt@ump.edu.vn)",
        "footer_disclaimer": "Mi·ªÖn tr·ª´ tr√°ch nhi·ªám: Kh√¥ng ƒë·∫£m b·∫£o t√≠nh ·ª©ng d·ª•ng l√¢m s√†ng; ng∆∞·ªùi d√πng t·ª± ch·ªãu tr√°ch nhi·ªám ki·ªÉm ƒë·ªãnh.",

        "intro_complete_md": """
### Ch√†o m·ª´ng

·ª®ng d·ª•ng n√†y gi√∫p c√°c nh√† l√¢m s√†ng v√† nh√† nghi√™n c·ª©u t√≠nh to√°n c·ª° m·∫´u t·ªëi thi·ªÉu cho nghi√™n c·ª©u ti√™n l∆∞·ª£ng, bao g·ªìm:
* Nghi√™n c·ª©u y·∫øu t·ªë ti√™n l∆∞·ª£ng (power ƒë·ªÉ ph√°t hi·ªán li√™n quan),
* X√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o l√¢m s√†ng (prediction model development), v√†
* Th·∫©m ƒë·ªãnh/ngo·∫°i ki·ªÉm & c·∫≠p nh·∫≠t m√¥ h√¨nh (validation/updating).

·ª®ng d·ª•ng ph√π h·ª£p cho k·∫øt c·ª•c nh·ªã ph√¢n (c√≥/kh√¥ng bi·∫øn c·ªë) v√† m·ªôt s·ªë m√¥-ƒëun cho k·∫øt c·ª•c th·ªùi gian s·ªëng (Cox PH).

M√£ ngu·ªìn (t·∫£i v·ªÅ): [https://gitlab.com/minhthiennguyen/pmsample/](https://gitlab.com/minhthiennguyen/pmsample/)
ho·∫∑c [https://github.com/nguyenminh2301/pmsample.git](https://github.com/nguyenminh2301/pmsample.git)

### H∆∞·ªõng d·∫´n nhanh cho ng∆∞·ªùi m·ªõi

#### 1. X√°c ƒë·ªãnh m·ª•c ti√™u nghi√™n c·ª©u
* B·∫°n mu·ªën ki·ªÉm ƒë·ªãnh m·ªôt y·∫øu t·ªë ti√™n l∆∞·ª£ng (li√™n quan OR/HR)?
* B·∫°n mu·ªën x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o?
* B·∫°n mu·ªën ngo·∫°i ki·ªÉm m√¥ h√¨nh c√≥ s·∫µn ·ªü qu·∫ßn th·ªÉ m·ªõi?

#### 2. ∆Ø·ªõc t√≠nh t·ª∑ l·ªá bi·∫øn c·ªë $p$ (ho·∫∑c t·ª∑ l·ªá bi·∫øn c·ªë t√≠ch l≈©y cho s·ªëng c√≤n)
* ∆Øu ti√™n l·∫•y t·ª´ d·ªØ li·ªáu b·ªánh vi·ªán (best).
* N·∫øu ch∆∞a ch·∫Øc, nh·∫≠p kho·∫£ng gi√° tr·ªã v√† ch·∫°y ƒë·ªô nh·∫°y.

#### 3. ƒê·∫øm ƒë√∫ng ƒë·ªô ph·ª©c t·∫°p m√¥ h√¨nh (tham s·ªë/df)
C·∫ßn d√πng s·ªë tham s·ªë (df), kh√¥ng ch·ªâ "s·ªë bi·∫øn". Quy t·∫Øc c∆° b·∫£n:
* Bi·∫øn nh·ªã ph√¢n: 1 df
* Bi·∫øn ph√¢n lo·∫°i $L$ m·ª©c: $L-1$ df
* Spline RCS $K$ n√∫t: $K-1$ df
* T∆∞∆°ng t√°c: $df(A \\times B) = df(A) \\cdot df(B)$

#### 4. Ch·ªçn ph∆∞∆°ng ph√°p ph√π h·ª£p
* **"Quick tools"** ch·ªâ ƒë·ªÉ ki·ªÉm tra s∆° b·ªô.
* N·∫øu x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o: ∆∞u ti√™n **Riley / m√¥ ph·ªèng / assurance**.

---

### Khi n√†o n√™n d√πng (v√† khi n√†o kh√¥ng n√™n d√πng)

**N√™n d√πng khi:**
* L·∫≠p k·∫ø ho·∫°ch ƒëo√†n h·ªá h·ªìi c·ª©u/ti·∫øn c·ª©u trong ti√™n l∆∞·ª£ng/d·ª± b√°o
* X√¢y d·ª±ng/ngo·∫°i ki·ªÉm m√¥ h√¨nh d·ª± b√°o nguy c∆°
* C·∫ßn ∆∞·ªõc t√≠nh c·ª° m·∫´u theo ƒë·ªô ch√≠nh x√°c (ƒë·ªô r·ªông KTC) cho t·ª∑ l·ªá ho·∫∑c AUC
* Thi·∫øt k·∫ø ngo·∫°i ki·ªÉm v·ªõi m·ª•c ti√™u calibration + discrimination

**Kh√¥ng n√™n d√πng nh∆∞ c√¥ng c·ª• ch√≠nh khi:**
* Thi·∫øt k·∫ø th·ª≠ nghi·ªám ng·∫´u nhi√™n (RCT) (c·∫ßn ph∆∞∆°ng ph√°p c·ª° m·∫´u ri√™ng cho RCT)
* Nghi√™n c·ª©u ƒë·ªô ch√≠nh x√°c ch·∫©n ƒëo√°n (Se/Sp) kh√¥ng g·∫Øn v·ªõi m√¥ h√¨nh d·ª± b√°o
* Mong mu·ªën "m·ªôt con s·ªë ƒë√∫ng tuy·ªát ƒë·ªëi": c·ª° m·∫´u ph·ª• thu·ªôc gi·∫£ ƒë·ªãnh v√† c·∫ßn ph√¢n t√≠ch ƒë·ªô nh·∫°y

---

### Danh m·ª•c ph∆∞∆°ng ph√°p (t√≥m t·∫Øt)

#### A. Quick / Basic (nhanh, x·∫•p x·ªâ)

**A1 ‚Äî Quy t·∫Øc kinh nghi·ªám (EPV/EPP) (heuristic)**
* **D√πng khi:** c·∫ßn ki·ªÉm tra s∆° b·ªô "s·ªë bi·∫øn c·ªë c√≥ ƒë·ªß t∆∞∆°ng ƒë·ªëi kh√¥ng" theo ƒë·ªô ph·ª©c t·∫°p m√¥ h√¨nh.
* **Kh√¥ng d√πng khi:** c√≥ spline/t∆∞∆°ng t√°c/ch·ªçn bi·∫øn/bi·∫øn c·ªë hi·∫øm‚ÄîEPV/EPP kh√¥ng ƒë·∫£m b·∫£o calibration ho·∫∑c √≠t optimism.
* **ƒê·∫ßu v√†o:** t·ª∑ l·ªá bi·∫øn c·ªë $p$, s·ªë tham s·ªë $P$ (df), EPP m·ª•c ti√™u (10/15/20)
* **ƒê·∫ßu ra:** $E=t \\cdot P$, $N=\\lceil E/p \\rceil$
* **M·∫°nh:** r·∫•t ƒë∆°n gi·∫£n, nhanh
* **Y·∫øu:** d·ªÖ g√¢y l·∫°c quan, kh√¥ng d·ª±a tr√™n hi·ªáu nƒÉng

**A2 ‚Äî ƒê·ªô ch√≠nh x√°c nguy c∆° n·ªÅn (KTC cho t·ª∑ l·ªá)**
* **D√πng khi:** m·ª•c ti√™u l√† ∆∞·ªõc t√≠nh t·ª∑ l·ªá bi·∫øn c·ªë $p$ v·ªõi KTC ƒë·ªß h·∫πp (¬±d).
* **Kh√¥ng d√πng khi:** mu·ªën ƒë·∫£m b·∫£o hi·ªáu nƒÉng m√¥ h√¨nh d·ª± b√°o.
* **ƒê·∫ßu v√†o:** $p$, ph∆∞∆°ng ph√°p KTC (Wilson khuy·∫øn ngh·ªã), m·ª©c tin c·∫≠y, n·ª≠a ƒë·ªô r·ªông $d$
* **ƒê·∫ßu ra:** $N$ t·ªëi thi·ªÉu ƒë·∫°t n·ª≠a ƒë·ªô r·ªông KTC $\\le d$
* **M·∫°nh:** minh b·∫°ch, tr·ª±c ti·∫øp theo m·ª•c ti√™u ƒë·ªô ch√≠nh x√°c
* **Y·∫øu:** ch·ªâ cho $p$, kh√¥ng n√≥i v·ªÅ AUC/slope

#### B. Prognostic factor (power) (t·∫≠p trung li√™n quan, kh√¥ng ph·∫£i sizing cho m√¥ h√¨nh d·ª± b√°o)

**B3 ‚Äî Logistic OR Power (Hsieh)**
* **D√πng khi:** c·∫ßn power ƒë·ªÉ ph√°t hi·ªán OR m·ª•c ti√™u c·ªßa m·ªôt y·∫øu t·ªë ti√™n l∆∞·ª£ng trong logistic regression.
* **Kh√¥ng d√πng khi:** m·ª•c ti√™u ch√≠nh l√† x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o.
* **ƒê·∫ßu v√†o:** $p_0$, OR m·ª•c ti√™u, alpha, power, t·ª∑ l·ªá ph∆°i nhi·ªÖm (n·∫øu nh·ªã ph√¢n) ho·∫∑c SD (n·∫øu li√™n t·ª•c), t√πy ch·ªçn $R^2$ v·ªõi ƒë·ªìng bi·∫øn
* **ƒê·∫ßu ra:** $N$ (v√† s·ªë bi·∫øn c·ªë k·ª≥ v·ªçng)
* **M·∫°nh:** khung power kinh ƒëi·ªÉn
* **Y·∫øu:** kh√¥ng nh·∫Øm calibration/discrimination

**B4 ‚Äî Cox HR Power (Schoenfeld)**
* **D√πng khi:** k·∫øt c·ª•c s·ªëng c√≤n, c·∫ßn ph√°t hi·ªán HR m·ª•c ti√™u theo Cox PH.
* **Kh√¥ng d√πng khi:** kh√≥ ∆∞·ªõc l∆∞·ª£ng t·ª∑ l·ªá bi·∫øn c·ªë theo d√µi ho·∫∑c PH kh√¥ng h·ª£p l√Ω.
* **ƒê·∫ßu v√†o:** HR, alpha, power, t·ª∑ l·ªá ph√¢n b·ªï (nh·ªã ph√¢n) ho·∫∑c SD (li√™n t·ª•c), t·ª∑ l·ªá bi·∫øn c·ªë k·ª≥ v·ªçng trong th·ªùi gian theo d√µi
* **ƒê·∫ßu ra:** s·ªë bi·∫øn c·ªë c·∫ßn thi·∫øt ‚Üí suy ra $N$
* **M·∫°nh:** ph·ªï bi·∫øn, tr·ª±c quan theo s·ªë bi·∫øn c·ªë
* **Y·∫øu:** ph·ª• thu·ªôc m·∫°nh v√†o gi·∫£ ƒë·ªãnh theo d√µi/censoring

#### C. Prediction model development (khuy·∫øn ngh·ªã cho x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o)

**C5 ‚Äî Riley et al. (ph√¢n t√≠ch; pmsampsize-like)**
* **D√πng khi:** ph√°t tri·ªÉn m√¥ h√¨nh d·ª± b√°o, c·∫ßn h·∫°n ch·∫ø overfitting v√† b·∫£o ƒë·∫£m ƒë·ªô ch√≠nh x√°c.
* **Kh√¥ng d√πng khi:** kh√¥ng c√≥ gi·∫£ ƒë·ªãnh h·ª£p l√Ω v·ªÅ $p$ v√† hi·ªáu nƒÉng d·ª± ki·∫øn (AUC ho·∫∑c $R^2$); khi ƒë√≥ d√πng ƒë·ªô nh·∫°y/m√¥ ph·ªèng.
* **ƒê·∫ßu v√†o:** $p$, $P$ (df), shrinkage m·ª•c ti√™u (v√≠ d·ª• 0,90), hi·ªáu nƒÉng d·ª± ki·∫øn (AUC ho·∫∑c Cox‚ÄìSnell $R^2$)
* **ƒê·∫ßu ra:** $N$ t·ªëi thi·ªÉu th·ªèa c√°c ti√™u ch√≠ (overfitting + precision)
* **M·∫°nh:** c√≥ c∆° s·ªü, d·ª±a tr√™n hi·ªáu nƒÉng
* **Y·∫øu:** ph·ª• thu·ªôc gi·∫£ ƒë·ªãnh; c·∫ßn ƒë·∫øm df chu·∫©n

**C6 ‚Äî Development Simulation (Frequentist; samplesizedev/custom DGM)**
* **D√πng khi:** mu·ªën m√¥ ph·ªèng theo ƒë√∫ng c√°ch b·∫°n d·ª± ki·∫øn x√¢y d·ª±ng m√¥ h√¨nh (phi tuy·∫øn/t∆∞∆°ng t√°c).
* **Kh√¥ng d√πng khi:** kh√¥ng m√¥ t·∫£ ƒë∆∞·ª£c DGM h·ª£p l√Ω ho·∫∑c c·∫ßn k·∫øt qu·∫£ t·ª©c th√¨.
* **ƒê·∫ßu v√†o:** danh s√°ch $N$, gi·∫£ ƒë·ªãnh DGM, ti√™u ch√≠ hi·ªáu nƒÉng, s·ªë m√¥ ph·ªèng, seed
* **ƒê·∫ßu ra:** $N$ nh·ªè nh·∫•t ƒë·∫°t ti√™u ch√≠
* **M·∫°nh:** linh ho·∫°t, ph√π h·ª£p m√¥ h√¨nh ph·ª©c t·∫°p
* **Y·∫øu:** t·ªën t√≠nh to√°n, nh·∫°y gi·∫£ ƒë·ªãnh

**C7 ‚Äî Bayesian Assurance (MCMC)**
* **D√πng khi:** m√¥ h√¨nh cu·ªëi c√πng ∆∞·ªõc l∆∞·ª£ng b·∫±ng Bayes/MCMC v√† mu·ªën sizing theo assurance.
* **Kh√¥ng d√πng khi:** kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c prior h·ª£p l√Ω ho·∫∑c h·∫°n ch·∫ø compute.
* **ƒê·∫ßu v√†o:** DGM, prior, $N$, ti√™u ch√≠ assurance, c√†i ƒë·∫∑t MCMC
* **ƒê·∫ßu ra:** $N$ nh·ªè nh·∫•t ƒë·∫°t assurance
* **M·∫°nh:** nh·∫•t qu√°n v·ªõi Bayes
* **Y·∫øu:** compute cao, c·∫ßn prior

#### D. Validation / Updating (cho m√¥ h√¨nh c√≥ s·∫µn)

**D8 ‚Äî ƒê·ªô ch√≠nh x√°c AUC (Hanley‚ÄìMcNeil / presize)**
* **D√πng khi:** m·ª•c ti√™u ngo·∫°i ki·ªÉm l√† KTC AUC ƒë·ªß h·∫πp.
* **Kh√¥ng d√πng khi:** calibration l√† tr·ªçng t√¢m.
* **ƒê·∫ßu v√†o:** AUC k·ª≥ v·ªçng, $p$ ho·∫∑c t·ª∑ l·ªá case-control, m·ª©c tin c·∫≠y, ƒë·ªô r·ªông KTC m·ª•c ti√™u
* **ƒê·∫ßu ra:** $N$ t·ªëi thi·ªÉu cho ƒë·ªô ch√≠nh x√°c AUC
* **M·∫°nh:** nhanh, d·ªÖ d√πng
* **Y·∫øu:** ch·ªâ AUC, x·∫•p x·ªâ

**D9 ‚Äî External Validation (Tailored; pmvalsampsize / sampsizeval)**
* **D√πng khi:** sizing ngo·∫°i ki·ªÉm theo nhi·ªÅu th∆∞·ªõc ƒëo (calibration + discrimination), th∆∞·ªùng c·∫ßn gi·∫£ ƒë·ªãnh ph√¢n b·ªë LP.
* **Kh√¥ng d√πng khi:** kh√¥ng bi·ªán minh ƒë∆∞·ª£c gi·∫£ ƒë·ªãnh LP/case-mix.
* **ƒê·∫ßu v√†o:** $p$, AUC k·ª≥ v·ªçng, m·ª•c ti√™u slope/CITL, ƒë·ªô r·ªông KTC/SE, gi·∫£ ƒë·ªãnh ph√¢n b·ªë LP
* **ƒê·∫ßu ra:** $N$ khuy·∫øn ngh·ªã
* **M·∫°nh:** "tailored", ch√∫ tr·ªçng calibration
* **Y·∫øu:** ph·ª©c t·∫°p, ph·ª• thu·ªôc gi·∫£ ƒë·ªãnh

**D10 ‚Äî External Validation (Simulation; LP-based)**
* **D√πng khi:** c√≥ th·ªÉ m√¥ t·∫£/∆∞·ªõc l∆∞·ª£ng ph√¢n b·ªë LP ·ªü qu·∫ßn th·ªÉ ngo·∫°i ki·ªÉm v√† mu·ªën m√¥ ph·ªèng ƒë·ªô ch√≠nh x√°c.
* **Kh√¥ng d√πng khi:** kh√¥ng ∆∞·ªõc l∆∞·ª£ng ƒë∆∞·ª£c LP distribution.
* **ƒê·∫ßu v√†o:** ph√¢n b·ªë LP, tham s·ªë miscalibration, m·ª•c ti√™u ƒë·ªô r·ªông KTC, s·ªë m√¥ ph·ªèng, seed
* **ƒê·∫ßu ra:** $N$ t·ªëi thi·ªÉu theo m√¥ ph·ªèng
* **M·∫°nh:** linh ho·∫°t
* **Y·∫øu:** t·ªën compute, nh·∫°y gi·∫£ ƒë·ªãnh

**D11 ‚Äî Updating / Recalibration (intercept/slope)**
* **D√πng khi:** c·∫ßn c·∫≠p nh·∫≠t intercept/slope khi tri·ªÉn khai ·ªü b·ªánh vi·ªán m·ªõi.
* **Kh√¥ng d√πng khi:** ph√°t tri·ªÉn m√¥ h√¨nh m·ªõi ho√†n to√†n.
* **ƒê·∫ßu v√†o:** ki·ªÉu c·∫≠p nh·∫≠t, $p$, m·ª•c ti√™u ƒë·ªô ch√≠nh x√°c
* **ƒê·∫ßu ra:** $N$ ƒë·ªß ·ªïn ƒë·ªãnh cho c·∫≠p nh·∫≠t
* **M·∫°nh:** th·ª±c d·ª•ng khi tri·ªÉn khai
* **Y·∫øu:** ph·ª• thu·ªôc case-mix v√† transportability

---

#### Disclaimer

No clinical warranty; users are responsible for validation and interpretation. Always document assumptions and run sensitivity analyses.

#### Contact

Author & Maintenance: Minh Nguyen (minhnt@ump.edu.vn)
""",

        "a2_content_md": """
### Nguy√™n t·∫Øc

Ch·ª©c nƒÉng n√†y t√≠nh **c·ª° m·∫´u t·ªëi thi·ªÉu (n)** ƒë·ªÉ ∆∞·ªõc t√≠nh **t·ª∑ l·ªá bi·∫øn c·ªë / nguy c∆° n·ªÅn** (p) (prevalence) v·ªõi **ƒë·ªô ch√≠nh x√°c mong mu·ªën**, bi·ªÉu di·ªÖn b·∫±ng **n·ª≠a ƒë·ªô r·ªông kho·∫£ng tin c·∫≠y (KTC)** (margin of error).

·ª®ng d·ª•ng:
* m√¥ t·∫£ t·ª∑ l·ªá bi·∫øn c·ªë trong ƒëo√†n h·ªá v·ªõi KTC ƒë·ªß h·∫πp,
* l·∫≠p k·∫ø ho·∫°ch kh·∫£ thi v√† b√°o c√°o d·ªãch t·ªÖ,
* h·ªó tr·ª£ c√°c ph√¢n t√≠ch li√™n quan calibration.

**H·∫°n ch·∫ø:** Ph∆∞∆°ng ph√°p n√†y **kh√¥ng ƒë·∫£m b·∫£o** hi·ªáu nƒÉng m√¥ h√¨nh d·ª± b√°o (AUC, calibration slope, optimism). N√≥ ch·ªâ ƒë·∫£m b·∫£o ƒë·ªô ch√≠nh x√°c khi **∆∞·ªõc t√≠nh (p)**.

---

### Ch√∫ gi·∫£i c√°c gi√° tr·ªã ƒë·∫ßu v√†o

1. **T·ª∑ l·ªá bi·∫øn c·ªë** (p)
   T·ª∑ l·ªá k·∫øt c·ª•c x·∫£y ra d·ª± ki·∫øn trong qu·∫ßn th·ªÉ nghi√™n c·ª©u (v√≠ d·ª• 0,10).
   * N·∫øu ch∆∞a r√µ, n√™n nh·∫≠p m·ªôt **kho·∫£ng gi√° tr·ªã** v√† ch·∫°y ph√¢n t√≠ch ƒë·ªô nh·∫°y.
   * N·∫øu c·∫ßn ‚Äúb·∫£o th·ªß‚Äù cho b√†i to√°n ∆∞·ªõc t√≠nh t·ª∑ l·ªá, d√πng $p=0.50$ (ph∆∞∆°ng sai l·ªõn nh·∫•t).

2. **N·ª≠a ƒë·ªô r·ªông KTC m·ª•c ti√™u** (d)
   M·ª•c ti√™u sao cho KTC x·∫•p x·ªâ: $p \pm d$
   V√≠ d·ª•: $d = 0.01, 0.02, 0.03$ t∆∞∆°ng ·ª©ng ¬±1%, ¬±2%, ¬±3%.

3. **M·ª©c tin c·∫≠y** (1-$\\alpha$)
   Th∆∞·ªùng d√πng 0,95 ho·∫∑c 0,99.

4. **Ph∆∞∆°ng ph√°p t√≠nh KTC**
* **Wilson score (khuy·∫øn ngh·ªã):** ƒë·ªô bao ph·ªß t·ªët h∆°n Wald, nh·∫•t l√† khi (p) g·∫ßn 0 ho·∫∑c 1 ho·∫∑c c·ª° m·∫´u v·ª´a/nh·ªè.
* **Wald (x·∫•p x·ªâ chu·∫©n):** c√¥ng th·ª©c ƒë√≥ng ƒë∆°n gi·∫£n nh∆∞ng c√≥ th·ªÉ k√©m ch√≠nh x√°c khi (n) nh·ªè ho·∫∑c (p) c·ª±c tr·ªã.
* **Clopper‚ÄìPearson (exact):** b·∫£o th·ªß (KTC th∆∞·ªùng r·ªông h∆°n ‚Üí c·∫ßn (n) l·ªõn h∆°n).

---

### C√°ch t√≠nh (c√¥ng th·ª©c v√† √Ω t∆∞·ªüng)

Gi·∫£ s·ª≠ $X \sim \\text{Binomial}(n,p)$, $\hat p = X/n$. M·ª•c ti√™u l√† t√¨m (n) nh·ªè nh·∫•t sao cho:
$$ \\frac{\\text{Upper}(n) - \\text{Lower}(n)}{2} \le d $$

#### A) Wald (x·∫•p x·ªâ)
$$ n \\approx \\frac{z^2 p(1-p)}{d^2} $$

#### B) Wilson score (khuy·∫øn ngh·ªã)
S·ª≠ d·ª•ng c√¥ng th·ª©c kho·∫£ng tin c·∫≠y Wilson.

#### C) Clopper‚ÄìPearson (exact)
D√πng ph√¢n v·ªã Beta. ƒê√¢y l√† ph∆∞∆°ng ph√°p b·∫£o th·ªß.

---

### N√™n ch·ªçn gi√° tr·ªã bao nhi√™u theo th√¥ng l·ªá?

* **M·ª©c tin c·∫≠y:** 95% l√† chu·∫©n.
* **N·ª≠a ƒë·ªô r·ªông (d):** ¬±0,01 ƒë·∫øn ¬±0,03 (1%‚Äì3%) l√† m·ª©c hay g·∫∑p.
* **Ph∆∞∆°ng ph√°p:** Wilson l√† l·ª±a ch·ªçn m·∫∑c ƒë·ªãnh h·ª£p l√Ω.

### T√†i li·ªáu tham kh·∫£o quan tr·ªçng
1. **Wilson EB.** Probable inference... *JASA.* 1927.
2. **Newcombe RG.** Two-sided confidence intervals... *Stat Med.* 1998.
""",

        "b3_content_md": """
### M·ª•c ƒë√≠ch (ph∆∞∆°ng ph√°p n√†y l√† g√¨)

Ch·ª©c nƒÉng n√†y ∆∞·ªõc t√≠nh **c·ª° m·∫´u t·ªëi thi·ªÉu** ƒë·ªÉ ph√°t hi·ªán m·ªëi li√™n quan gi·ªØa bi·∫øn d·ª± b√°o (X) v√† **k·∫øt c·ª•c nh·ªã ph√¢n** (Y) b·∫±ng **h·ªìi quy logistic**, v·ªõi **OR m·ª•c ti√™u**, **($\\alpha$) hai ph√≠a**, v√† **power** ƒë√£ ch·ªçn.

ƒê√¢y l√† ph∆∞∆°ng ph√°p **power cho nghi√™n c·ª©u y·∫øu t·ªë ti√™n l∆∞·ª£ng / ki·ªÉm ƒë·ªãnh li√™n quan** (ki·ªÉm ƒë·ªãnh h·ªá s·ªë h·ªìi quy), **kh√¥ng ph·∫£i** ph∆∞∆°ng ph√°p ƒë·∫£m b·∫£o hi·ªáu nƒÉng c·ªßa **m√¥ h√¨nh d·ª± b√°o**. N√≥ **kh√¥ng ƒë·∫£m b·∫£o** calibration/discrimination c·ªßa m√¥ h√¨nh ƒëa bi·∫øn.

---

### Khi n√†o n√™n d√πng

D√πng B3 khi:

* B·∫°n c·∫ßn power ƒë·ªÉ ph√°t hi·ªán **OR c√≥ √Ω nghƒ©a l√¢m s√†ng** cho **m·ªôt bi·∫øn** (nh·ªã ph√¢n ho·∫∑c li√™n t·ª•c) trong logistic regression.
* M·ª•c ti√™u l√† **ki·ªÉm ƒë·ªãnh gi·∫£ thuy·∫øt** (bi·∫øn c√≥ li√™n quan k·∫øt c·ª•c hay kh√¥ng), kh√¥ng ph·∫£i x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o nguy c∆°.

### Khi n√†o kh√¥ng n√™n d√πng

Kh√¥ng d√πng B3 l√†m ph∆∞∆°ng ph√°p ch√≠nh khi:

* M·ª•c ti√™u l√† **x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o** (n√™n d√πng Riley/pmsampsize ho·∫∑c m√¥ ph·ªèng/assurance).
* B·∫°n d·ª± ƒë·ªãnh **ch·ªçn bi·∫øn theo d·ªØ li·ªáu**, d√πng nhi·ªÅu spline/t∆∞∆°ng t√°c, ho·∫∑c tuning m√¥ h√¨nh ph·ª©c t·∫°p (power cho 1 h·ªá s·ªë kh√¥ng c√≤n l√† m·ª•c ti√™u ph√π h·ª£p).
* D·ªØ li·ªáu c√≥ **ph·ª• thu·ªôc/c·ª•m** (ƒëa trung t√¢m/khoa/ph√≤ng) m√† ch∆∞a t√≠nh design effect.
* Thi·∫øt k·∫ø **case‚Äìcontrol** v·ªõi s·ªë ca/ch·ª©ng c·ªë ƒë·ªãnh (gi√° tr·ªã ($p_0$) kh√¥ng ph·∫£n √°nh nguy c∆° n·ªÅn qu·∫ßn th·ªÉ).

---

## M√¥ h√¨nh v√† tham s·ªë

M√¥ h√¨nh logistic:
$$
\\text{logit}{P(Y=1\\mid X)}=\\beta_0+\\beta_1 X
$$

* N·∫øu ($X$) nh·ªã ph√¢n 0/1:
  $$
  \\mathrm{OR}=\\exp(\\beta_1)
  $$
* N·∫øu ($X$) li√™n t·ª•c: OR ph·∫£i g·∫Øn v·ªõi m·ªôt m·ª©c thay ƒë·ªïi c·ªßa ($X$) (th√¥ng d·ª•ng nh·∫•t: **tƒÉng 1 SD**).

Ki·ªÉm ƒë·ªãnh:
$$
H_0:\\beta_1=0 \\quad \\text{vs}\\quad H_1:\\beta_1\\neq 0
$$

---

## Ch√∫ gi·∫£i c√°c ƒë·∫ßu v√†o

1. **Alpha (2 ph√≠a)** ($\\alpha$): th∆∞·ªùng 0,05; 0,01 n·∫øu nghi√™m ng·∫∑t h∆°n.
2. **Power** ($1-\\beta$): th∆∞·ªùng 0,80; 0,90 n·∫øu c·∫ßn th·∫≠n tr·ªçng.
3. **T·ª∑ l·ªá bi·∫øn c·ªë n·ªÅn** ($p_0$)

   * V·ªõi ($X$) nh·ªã ph√¢n: ($p_0=P(Y=1\\mid X=0)$).
   * V·ªõi ($X$) li√™n t·ª•c: ($p_0$) th∆∞·ªùng hi·ªÉu l√† t·ª∑ l·ªá bi·∫øn c·ªë t·∫°i **gi√° tr·ªã trung b√¨nh** c·ªßa ($X$) (sau khi center).
4. **OR m·ª•c ti√™u**: m·ª©c OR nh·ªè nh·∫•t c√≥ √Ω nghƒ©a l√¢m s√†ng.
5. **Lo·∫°i bi·∫øn d·ª± b√°o**

   * Nh·ªã ph√¢n: c·∫ßn ($q=P(X=1)$).
   * Li√™n t·ª•c: c·∫ßn OR cho **tƒÉng 1 SD** (ho·∫∑c ph·∫£i quy ƒë·ªïi t·ª´ OR theo 1 ƒë∆°n v·ªã).
6. **($R^2$) v·ªõi c√°c ƒë·ªìng bi·∫øn kh√°c**

   * ($R^2$) l√† m·ª©c ƒë·ªô ($X$) ƒë∆∞·ª£c gi·∫£i th√≠ch b·ªüi c√°c ƒë·ªìng bi·∫øn kh√°c (khi h·ªìi quy ($X$) theo c√°c bi·∫øn kh√°c).
   * ($R^2$) c√†ng l·ªõn ‚Üí c·∫ßn c·ª° m·∫´u c√†ng l·ªõn (v√¨ th√¥ng tin ‚Äúƒë·ªôc l·∫≠p‚Äù c·ªßa ($X$) gi·∫£m).

---

# C√°ch t√≠nh (c√¥ng th·ª©c)

## B∆∞·ªõc 1 ‚Äî Quy ƒë·ªïi OR v√† ($p_0$) sang ($p_1$) (khi ($X$) nh·ªã ph√¢n)

$$
\\text{odds}_0=\\frac{p_0}{1-p_0},\\quad \\text{odds}_1=\\mathrm{OR}\\cdot \\text{odds}_0,\\quad
p_1=\\frac{\\text{odds}_1}{1+\\text{odds}_1}
$$

T·ª∑ l·ªá bi·∫øn c·ªë chung:
$$
p=(1-q)p_0+q p_1
$$

## B∆∞·ªõc 2 ‚Äî Z-score

$$
z_{\\alpha}=z_{1-\\alpha/2}, \\qquad z_{\\beta}=z_{1-\\beta}=z_{\\text{power}}
$$

## A) C·ª° m·∫´u v·ªõi bi·∫øn d·ª± b√°o nh·ªã ph√¢n

$$
n_0=
\\frac{
\\left[
z_{\\alpha}\\sqrt{\\frac{p(1-p)}{q(1-q)}}
+
z_{\\beta}\\sqrt{\\frac{p_1(1-p_1)}{q}+\\frac{p_0(1-p_0)}{1-q}}
\\right]^2
}
{(p_1-p_0)^2}
$$

### Hi·ªáu ch·ªânh khi c√≥ nhi·ªÅu ƒë·ªìng bi·∫øn (t∆∞∆°ng quan v·ªõi bi·∫øn kh√°c)

$$
n=\\frac{n_0}{1-R^2}
$$

### S·ªë bi·∫øn c·ªë k·ª≥ v·ªçng

$$
E \\approx n\\cdot p
$$

---

## B) C·ª° m·∫´u v·ªõi bi·∫øn d·ª± b√°o li√™n t·ª•c

Gi·∫£ ƒë·ªãnh OR ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a cho **tƒÉng 1 SD** c·ªßa ($X$) (k√Ω hi·ªáu ($\\mathrm{OR}_{SD}$)), v√† ($p_0$) l√† t·ª∑ l·ªá bi·∫øn c·ªë t·∫°i trung b√¨nh c·ªßa ($X$):

$$
n_0=\\frac{(z_{\\alpha}+z_{\\beta})^2}{p_0(1-p_0) [\\log(\\mathrm{OR}_{SD})]^2}
$$

N·∫øu OR nh·∫≠p theo **tƒÉng 1 ƒë∆°n v·ªã** l√† ($\\mathrm{OR}_{unit}$), v√† SD c·ªßa ($X$) l√† ($\\sigma_X$), th√¨:
$$
\\log(\\mathrm{OR}_{SD})=\\log(\\mathrm{OR}_{unit})\\cdot \\sigma_X
$$

Sau ƒë√≥ hi·ªáu ch·ªânh t∆∞∆°ng quan ƒë·ªìng bi·∫øn:
$$
n=\\frac{n_0}{1-R^2}
$$

---

## N√™n ch·ªçn gi√° tr·ªã bao nhi√™u theo th√¥ng l·ªá?

* **($\\alpha$)**: 0,05 (hai ph√≠a) l√† ph·ªï bi·∫øn; gi·∫£m ($\\alpha$) n·∫øu c√≥ nhi·ªÅu ki·ªÉm ƒë·ªãnh.
* **Power**: 0,80 (th∆∞·ªùng d√πng); 0,90 (th·∫≠n tr·ªçng h∆°n).
* **OR m·ª•c ti√™u**: ch·ªçn OR nh·ªè nh·∫•t c√≥ √Ω nghƒ©a l√¢m s√†ng (th∆∞·ªùng 1,2‚Äì2,0 t√πy b·ªëi c·∫£nh).
* **($p_0$)**: ∆∞u ti√™n d·ªØ li·ªáu b·ªánh vi·ªán; n·∫øu ch∆∞a c√≥, d√πng y vƒÉn v√† ch·∫°y ƒë·ªô nh·∫°y.
* **($q$)**: l·∫•y t·ª´ t·ª∑ l·ªá ph∆°i nhi·ªÖm th·ª±c t·∫ø; ($q$) g·∫ßn 0,5 th∆∞·ªùng cho c·ª° m·∫´u nh·ªè h∆°n; ($q$) r·∫•t th·∫•p/cao l√†m tƒÉng ($n$).
* **($R^2$)**: n·∫øu ch∆∞a ch·∫Øc, ch·∫°y ƒë·ªô nh·∫°y (0; 0,1; 0,25; 0,5).
* **Bi·∫øn li√™n t·ª•c**: n√™n chu·∫©n h√≥a ($X$) (mean 0, SD 1) ƒë·ªÉ OR theo 1 SD d·ªÖ hi·ªÉu.

---

## T√†i li·ªáu tham kh·∫£o

1. Hsieh FY, Bloch DA, Larsen MD. *A simple method of sample size calculation for linear and logistic regression.* Statistics in Medicine. 1998;17(14):1623‚Äì1634.
2. Hsieh FY. *Sample size tables for logistic regression.* Statistics in Medicine. 1989;8(7):795‚Äì802.
3. Whittemore AS. *Sample size for logistic regression with small response probability.* Journal of the American Statistical Association. 1981;76:27‚Äì32.
""",
        "c5_content_md": """
### C5: Riley et al. (Ph√¢n t√≠ch)

### Ph∆∞∆°ng ph√°p n√†y l√† g√¨?

C5 tri·ªÉn khai c√°c **ti√™u ch√≠ c·ª° m·∫´u t·ªëi thi·ªÉu c·ªßa Riley v√† c·ªông s·ª±** cho **x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o ƒëa bi·∫øn** v·ªõi **k·∫øt c·ª•c nh·ªã ph√¢n** (h·ªìi quy logistic). M·ª•c ti√™u l√† b·∫£o ƒë·∫£m c·ª° m·∫´u ƒë·ªß ƒë·ªÉ:

1. **H·∫°n ch·∫ø overfitting** (nh·∫Øm t·ªõi h·ªá s·ªë co r√∫t to√†n c·ª•c / calibration slope m·ª•c ti√™u),
2. B·∫£o ƒë·∫£m **ƒë·ªô ch√≠nh x√°c** c·ªßa hi·ªáu nƒÉng m√¥ h√¨nh (gi·ªõi h·∫°n m·ª©c ‚Äúl·∫°c quan‚Äù c·ªßa $R^2$), v√†
3. ∆Ø·ªõc t√≠nh **nguy c∆° n·ªÅn/t·ª∑ l·ªá bi·∫øn c·ªë chung** (intercept) ƒë·ªß ch√≠nh x√°c.

ƒê√¢y l√† ph∆∞∆°ng ph√°p cho **ph√°t tri·ªÉn m√¥ h√¨nh** (kh√¥ng ph·∫£i ngo·∫°i ki·ªÉm). ƒê·∫∑c bi·ªát ph√π h·ª£p khi b·∫°n x√¢y d·ª±ng m√¥ h√¨nh logistic v·ªõi **danh s√°ch bi·∫øn v√† c√°ch m√£ h√≥a ƒë∆∞·ª£c x√°c ƒë·ªãnh tr∆∞·ªõc**, v√† mu·ªën thay th·∫ø quy t·∫Øc EPV ƒë∆°n gi·∫£n b·∫±ng ph∆∞∆°ng ph√°p c√≥ c∆° s·ªü h∆°n.

---

### Khi n√†o n√™n d√πng

D√πng C5 khi:

* B·∫°n ƒëang **x√¢y d·ª±ng** m√¥ h√¨nh d·ª± b√°o cho **k·∫øt c·ª•c nh·ªã ph√¢n**.
* B·∫°n c√≥ th·ªÉ ∆∞·ªõc l∆∞·ª£ng (d√π g·∫ßn ƒë√∫ng) **t·ª∑ l·ªá bi·∫øn c·ªë** v√† **hi·ªáu nƒÉng d·ª± ki·∫øn** (Cox‚ÄìSnell $R^2$ ho·∫∑c AUC).
* B·∫°n mu·ªën nh·∫Øm t·ªõi **√≠t overfitting** (v√≠ d·ª• $S \\ge 0{,}90$) v√† ƒë·ªô ch√≠nh x√°c h·ª£p l√Ω.

### Khi n√†o kh√¥ng n√™n d√πng (ho·∫∑c c·∫ßn th·∫≠n tr·ªçng)

Kh√¥ng n√™n ch·ªâ d·ª±a v√†o C5 khi:

* B·∫°n d·ª± ƒë·ªãnh **ch·ªçn bi·∫øn theo d·ªØ li·ªáu**, d√πng nhi·ªÅu t∆∞∆°ng t√°c/spline/tinh ch·ªânh ph·ª©c t·∫°p m√† ch∆∞a quy ƒë·ªïi ƒë√∫ng **df hi·ªáu d·ª•ng**.
* D·ªØ li·ªáu c√≥ **c·ª•m/ƒëa trung t√¢m** m√† ch∆∞a t√≠nh design effect.
* Ph∆∞∆°ng ph√°p m√¥ h√¨nh h√≥a kh√°c xa logistic chu·∫©n (ML ph·ª©c t·∫°p) m√† kh√¥ng c√≥ c√°ch quy ƒë·ªïi ƒë·ªô ph·ª©c t·∫°p sang **df hi·ªáu d·ª•ng**; khi ƒë√≥ n√™n c√¢n nh·∫Øc m√¥ ph·ªèng.
* B·∫°n kh√¥ng th·ªÉ bi·ªán minh b·∫•t k·ª≥ gi·∫£ ƒë·ªãnh n√†o v·ªÅ AUC/$R^2$; khi ƒë√≥ n√™n ch·∫°y ƒë·ªô nh·∫°y r·ªông v√†/ho·∫∑c d√πng m√¥ ph·ªèng.

---

## Ch√∫ gi·∫£i c√°c ƒë·∫ßu v√†o

1. **T·ª∑ l·ªá bi·∫øn c·ªë** (p)
   T·ª∑ l·ªá (Y=1) d·ª± ki·∫øn trong b·ªô d·ªØ li·ªáu ph√°t tri·ªÉn m√¥ h√¨nh.

2. **S·ªë tham s·ªë m√¥ h√¨nh (df)** (P)
   T·ªïng b·∫≠c t·ª± do c·ªßa t·∫•t c·∫£ bi·∫øn d·ª± b√°o **kh√¥ng t√≠nh intercept**.
   Bao g·ªìm: dummy c·ªßa bi·∫øn ph√¢n lo·∫°i, basis spline, t∆∞∆°ng t√°c, v√† m·ªçi bi·∫øn ƒë·ªïi t·∫°o th√™m h·ªá s·ªë.

3. **Hi·ªáu nƒÉng d·ª± ki·∫øn** (ch·ªçn m·ªôt)

* **Cox‚ÄìSnell ($R^2_{CS}$)**: ∆∞u ti√™n n·∫øu c√≥ t·ª´ nghi√™n c·ª©u li√™n quan (l√Ω t∆∞·ªüng l√† ƒë√£ hi·ªáu ch·ªânh l·∫°c quan).
* **AUC (C-statistic)**: n·∫øu kh√¥ng c√≥ $R^2_{CS}$, c√≥ th·ªÉ x·∫•p x·ªâ $R^2_{CS}$ t·ª´ AUC v√† ($p$) theo ph∆∞∆°ng ph√°p ƒë√£ c√¥ng b·ªë.
* **B·∫£o th·ªß (15% c·ªßa $R^2$ t·ªëi ƒëa)**: d√πng khi kh√¥ng c√≥ AUC/$R^2$; ch·ªâ n√™n d√πng cho ∆∞·ªõc t√≠nh s∆° b·ªô v√† lu√¥n ch·∫°y ph√¢n t√≠ch ƒë·ªô nh·∫°y.

4. **M·ª•c ti√™u shrinkage to√†n c·ª•c** (S)
   Th∆∞·ªõc ƒëo ki·ªÉm so√°t overfitting (th∆∞·ªùng di·ªÖn gi·∫£i g·∫ßn v·ªõi calibration slope k·ª≥ v·ªçng sau n·ªôi ki·ªÉm).

* M·∫∑c ƒë·ªãnh hay d√πng: $S=0{,}90$ (t∆∞∆°ng ƒë∆∞∆°ng c·∫ßn shrink ~10%).
* B·∫£o th·ªß h∆°n: $S=0{,}95$.

---

## Kh√°i ni·ªám v√† c√¥ng th·ª©c

### Cox‚ÄìSnell ($R^2$) v√† gi√° tr·ªã t·ªëi ƒëa

$$
R^2_{CS} = 1-\\exp!\\left(\\frac{2}{n}(\\ell_0-\\ell_1)\\right),
$$
trong ƒë√≥ $\\ell_0$ l√† log-likelihood m√¥ h√¨nh ch·ªâ c√≥ intercept v√† $\\ell_1$ l√† log-likelihood m√¥ h√¨nh ƒë·∫ßy ƒë·ªß.

V·ªõi k·∫øt c·ª•c nh·ªã ph√¢n, $R^2_{CS}$ kh√¥ng ƒë·∫°t 1. Gi√° tr·ªã t·ªëi ƒëa ph·ª• thu·ªôc ($p$):
$$
\\ell_0 = n\\Big[p\\ln(p) + (1-p)\\ln(1-p)\\Big],
$$
$$
R^2_{CS,\\max}=1-\\exp!\\left(\\frac{2\\ell_0}{n}\\right)
=1-\\exp!\\Big(2[p\\ln(p) + (1-p)\\ln(1-p)]\\Big).
$$

Nagelkerke ($R^2$):
$$
R^2_{Nag}=\\frac{R^2_{CS}}{R^2_{CS,\\max}}.
$$

---

## Ba ti√™u ch√≠ Riley (k·∫øt c·ª•c nh·ªã ph√¢n)

### Ti√™u ch√≠ 1 ‚Äî Gi·ªõi h·∫°n overfitting b·∫±ng shrinkage m·ª•c ti√™u (S)

$$
n_1=\\left\\lceil
\\frac{P}{(S-1),\\ln!\\left(1-\\frac{R^2_{CS}}{S}\\right)}
\\right\\rceil.
$$

### Ti√™u ch√≠ 2 ‚Äî Gi·ªõi h·∫°n m·ª©c l·∫°c quan c·ªßa ($R^2$) (m·∫∑c ƒë·ªãnh 0,05)

Ti√™u ch√≠ n√†y nh·∫Øm t·ªõi ch√™nh l·ªách tuy·ªát ƒë·ªëi (m·∫∑c ƒë·ªãnh $\\delta=0{,}05$) gi·ªØa ($R^2$) bi·ªÉu ki·∫øn v√† ($R^2$) hi·ªáu ch·ªânh tr√™n thang **Nagelkerke**. Shrinkage t∆∞∆°ng ·ª©ng:
$$
S_{\\delta}=\\frac{R^2_{CS}}{R^2_{CS}+\\delta,R^2_{CS,\\max}}.
$$
Sau ƒë√≥:
$$
n_2=\\left\\lceil
\\frac{P}{(S_{\\delta}-1),\\ln!\\left(1-\\frac{R^2_{CS}}{S_{\\delta}}\\right)}
\\right\\rceil.
$$

### Ti√™u ch√≠ 3 ‚Äî ∆Ø·ªõc t√≠nh ch√≠nh x√°c nguy c∆° n·ªÅn (intercept)

Nh·∫Øm t·ªõi ∆∞·ªõc t√≠nh ($p$) trong kho·∫£ng ($\\pm d$) (m·∫∑c ƒë·ªãnh $d=0{,}05$ ·ªü m·ª©c 95%):
$$
n_3=\\left\\lceil
\\left(\\frac{z_{1-\\alpha/2}}{d}\\right)^2 p(1-p)
\\right\\rceil,
\\quad \\text{m·∫∑c ƒë·ªãnh } z_{0.975}=1.96,; d=0.05.
$$

### K·∫øt qu·∫£ cu·ªëi c√πng

$$
n_{\\min}=\\max(n_1,n_2,n_3),\\qquad
E = n_{\\min},p,\\qquad
EPP=\\frac{E}{P}.
$$

---

## G·ª£i √Ω ch·ªçn gi√° tr·ªã theo th√¥ng l·ªá

* **Shrinkage (S)**: th∆∞·ªùng ch·ªçn **0,90**; c√¢n nh·∫Øc **0,95** n·∫øu m√¥ h√¨nh ph·ª©c t·∫°p ho·∫∑c mu·ªën gi·∫£m overfitting m·∫°nh h∆°n.
* **$\\delta=0{,}05$** (Ti√™u ch√≠ 2): th∆∞·ªùng gi·ªØ m·∫∑c ƒë·ªãnh.
* **ƒê·ªô ch√≠nh x√°c intercept (d=0{,}05)**: m·∫∑c ƒë·ªãnh t∆∞∆°ng ·ª©ng ∆∞·ªõc t√≠nh nguy c∆° n·ªÅn trong ¬±5%. N·∫øu c·∫ßn ch√≠nh x√°c h∆°n (d nh·ªè h∆°n) th√¨ c·∫ßn (n) l·ªõn h∆°n.
* **$R^2_{CS}$ d·ª± ki·∫øn**:

  * ∆Øu ti√™n gi√° tr·ªã **ƒë√£ hi·ªáu ch·ªânh l·∫°c quan** t·ª´ nghi√™n c·ª©u ph√°t tri·ªÉn t∆∞∆°ng t·ª±, ho·∫∑c gi√° tr·ªã bi·ªÉu ki·∫øn t·ª´ ngo·∫°i ki·ªÉm.
  * N·∫øu ch·ªâ c√≥ AUC, d√πng ph∆∞∆°ng ph√°p x·∫•p x·ªâ AUC‚Üí$R^2_{CS}$ theo b√†i b√°o h∆∞·ªõng d·∫´n.
  * N·∫øu kh√¥ng c√≥ AUC/$R^2$, t√πy ch·ªçn **15% c·ªßa $R^2_{CS,\\max}$** ch·ªâ n√™n d√πng ƒë·ªÉ ∆∞·ªõc t√≠nh s∆° b·ªô v√† lu√¥n ch·∫°y ph√¢n t√≠ch ƒë·ªô nh·∫°y.

---

## T√†i li·ªáu tham kh·∫£o

1. Riley RD, Snell KIE, Ensor J, et al. *Minimum sample size required for developing a multivariable prediction model: PART II‚Äîbinary and time-to-event outcomes.* Statistics in Medicine. 2019.
2. Riley RD, Ensor J, Snell KIE, et al. *Calculating the sample size required for developing a clinical prediction model.* BMJ. 2020.
3. Riley RD, Van Calster B, Collins GS. *A note on estimating the Cox‚ÄìSnell ($R^2$) from a reported C statistic (AUROC) to inform sample size calculations for developing a prediction model with a binary outcome.* Statistics in Medicine. 2021.
4. Harrell FE Jr, Lee KL, Mark DB. *Multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors.* Statistics in Medicine. 1996.
""",
        "c6_content_md": """
## C6: M√¥ ph·ªèng ph√°t tri·ªÉn m√¥ h√¨nh (Frequentist; DGM t√πy bi·∫øn) 

### Ph∆∞∆°ng ph√°p n√†y l√† g√¨?

C6 l√† ph∆∞∆°ng ph√°p **∆∞·ªõc t√≠nh c·ª° m·∫´u b·∫±ng m√¥ ph·ªèng** cho **x√¢y d·ª±ng m√¥ h√¨nh d·ª± b√°o** (k·∫øt c·ª•c nh·ªã ph√¢n), theo tri·∫øt l√Ω g·∫ßn v·ªõi **samplesizedev** v√† c√°c h∆∞·ªõng d·∫´n m√¥ ph·ªèng trong prediction modeling.

Thay v√¨ m·ªôt c√¥ng th·ª©c ƒë√≥ng, C6 tr·∫£ l·ªùi c√¢u h·ªèi:

> ‚ÄúN·∫øu l·∫∑p l·∫°i nhi·ªÅu l·∫ßn qu√° tr√¨nh x√¢y d·ª±ng m√¥ h√¨nh tr√™n d·ªØ li·ªáu c·ª° m·∫´u (N), m√¥ h√¨nh c√≥ ƒë·∫°t ti√™u ch√≠ hi·ªáu nƒÉng mong mu·ªën tr√™n d·ªØ li·ªáu m·ªõi v·ªõi x√°c su·∫•t ƒë·ªß cao kh√¥ng?‚Äù

Do ƒë√≥ C6 nh·∫Øm t·ªõi **hi·ªáu nƒÉng k·ª≥ v·ªçng** (v√†/ho·∫∑c x√°c su·∫•t ƒë·∫°t hi·ªáu nƒÉng ch·∫•p nh·∫≠n ƒë∆∞·ª£c) d∆∞·ªõi m·ªôt **c∆° ch·∫ø sinh d·ªØ li·ªáu (DGM)** m√¥ t·∫£ qu·∫ßn th·ªÉ l√¢m s√†ng d·ª± ki·∫øn.

---

## Khi n√†o n√™n d√πng

D√πng C6 khi:

* Mu·ªën ‚Äú**m√¥ ph·ªèng ƒë√∫ng c√°ch b·∫°n s·∫Ω l√†m**‚Äù, ƒë·∫∑c bi·ªát khi:

  * bi·∫øn d·ª± b√°o t∆∞∆°ng quan,
  * c√≥ spline/phi tuy·∫øn, t∆∞∆°ng t√°c,
  * t·ª∑ l·ªá bi·∫øn c·ªë v·ª´a/kh√¥ng ch·∫Øc,
  * mu·ªën ti√™u ch√≠ d·ª±a tr√™n **calibration** v√† **discrimination**.
* C√≥ th·ªÉ m√¥ t·∫£ DGM h·ª£p l√Ω d·ª±a tr√™n d·ªØ li·ªáu b·ªánh vi·ªán ho·∫∑c y vƒÉn.
* Ch·∫•p nh·∫≠n ch·∫°y m√¥ ph·ªèng v√† c·∫ßn ph∆∞∆°ng ph√°p linh ho·∫°t h∆°n c√¥ng th·ª©c ph√¢n t√≠ch.

## Khi n√†o kh√¥ng n√™n d√πng (ho·∫∑c c·∫ßn th·∫≠n tr·ªçng)

Kh√¥ng n√™n ch·ªâ d·ª±a v√†o C6 khi:

* Kh√¥ng bi·ªán minh ƒë∆∞·ª£c DGM (ph√¢n b·ªë bi·∫øn, t∆∞∆°ng quan, hi·ªáu ·ª©ng).
* H·∫°n ch·∫ø t√†i nguy√™n t√≠nh to√°n.
* Pipeline ph√°t tri·ªÉn m√¥ h√¨nh mang t√≠nh ‚Äúdata-adaptive‚Äù ph·ª©c t·∫°p (ch·ªçn bi·∫øn/tuning) nh∆∞ng kh√¥ng m√¥ ph·ªèng ƒë·∫ßy ƒë·ªß pipeline ƒë√≥.
* Qu·∫ßn th·ªÉ ƒë√≠ch kh√°c bi·ªát m·∫°nh theo trung t√¢m/case-mix nh∆∞ng m√¥ ph·ªèng kh√¥ng ph·∫£n √°nh c·ª•m/kh√°c bi·ªát.

---

# Quy tr√¨nh m√¥ ph·ªèng (t·ªïng quan)

### B∆∞·ªõc 1 ‚Äî Ch·ªçn DGM

$$
Y \mid X \sim \\text{Bernoulli}(\\pi), \\qquad
\\pi = \\text{logit}^{-1}(\\eta),
$$
$$
\\eta = \\beta_0 + \\sum_{j=1}^{P}\\beta_j f_j(X_j),
$$
trong ƒë√≥ (P) l√† **df**, c√≤n (f_j(\\cdot)) l√† c√°ch m√£ h√≥a (tuy·∫øn t√≠nh, spline, dummy‚Ä¶).

Ch·ªçn (\\beta_0) ƒë·ªÉ ƒë·∫°t t·ª∑ l·ªá bi·∫øn c·ªë m·ª•c ti√™u (p):
$$
\\mathbb{E}[\\pi] = p.
$$
(Trong th·ª±c h√†nh d√πng root-finding d·ª±a tr√™n m√¥ ph·ªèng (X).)

### B∆∞·ªõc 2 ‚Äî Sinh d·ªØ li·ªáu ph√°t tri·ªÉn

V·ªõi m·ªói l·∫ßn m√¥ ph·ªèng (r):

* Sinh (X^{(r)}) k√≠ch th∆∞·ªõc (N),
* Sinh (Y^{(r)}) theo Bernoulli ·ªü tr√™n.

### B∆∞·ªõc 3 ‚Äî Fit m√¥ h√¨nh ph√°t tri·ªÉn

$$
\\widehat{\\eta} = \\widehat{\\beta}*0 + \\sum*{j=1}^{P}\\widehat{\\beta}_j f_j(X_j).
$$
N·∫øu x·∫£y ra separation/kh√¥ng h·ªôi t·ª•, th∆∞·ªùng d√πng ridge-penalized fallback v√† b√°o c√°o t·ª∑ l·ªá x·∫£y ra.

### B∆∞·ªõc 4 ‚Äî ƒê√°nh gi√° tr√™n d·ªØ li·ªáu m·ªõi

Sinh t·∫≠p test ƒë·ªôc l·∫≠p (th∆∞·ªùng (N_{\\text{test}}) l·ªõn 5000‚Äì10000) v√† t√≠nh:

**(a) AUC**
$$
\\mathrm{AUC}=\\Pr(\\widehat{\\eta}_1 > \\widehat{\\eta}_0).
$$

**(b) Calibration slope**
Fit m√¥ h√¨nh hi·ªáu ch·ªânh:
$$
\\text{logit}(Y) = a + b \\cdot \\text{logit}(\\widehat{p})
$$
ho·∫∑c:
$$
\\text{logit}(Y) = a + b \\cdot \\widehat{\\eta}.
$$
Trong ƒë√≥ (b\\approx 1) l√† t·ªët; (b<1) th∆∞·ªùng g·ª£i √Ω overfitting.

### B∆∞·ªõc 5 ‚Äî Ti√™u ch√≠ ƒë·∫°t/kh√¥ng ƒë·∫°t v√† ch·ªçn (N)

T√≥m t·∫Øt theo (R) l·∫ßn m√¥ ph·ªèng:

$$
\\overline{b} = \\frac{1}{R}\\sum_{r=1}^R b^{(r)},
\\quad
\\widehat{\\Pr}(b \\in [L,U]) = \\frac{1}{R}\\sum_{r=1}^R \\mathbf{1}{b^{(r)}\\in[L,U]},
$$
$$
\\overline{\\mathrm{AUC}}=\\frac{1}{R}\\sum_{r=1}^R \\mathrm{AUC}^{(r)}.
$$

M·ªôt (N) ƒë·∫°t y√™u c·∫ßu n·∫øu th·ªèa t·∫•t c·∫£ ti√™u ch√≠ ƒë√£ ch·ªçn (v√≠ d·ª•):

* (\\overline{b} \\ge 0.90)
* (\\widehat{\\Pr}(0.9 \\le b \\le 1.1) \\ge 0.80)
* (\\overline{\\mathrm{AUC}} \\ge \\mathrm{AUC}_{\\text{target}})

Ch·ªçn (N) nh·ªè nh·∫•t ƒë·∫°t.

---

# Ch√∫ gi·∫£i ƒë·∫ßu v√†o (t√¨m ·ªü ƒë√¢u, n√™n ch·ªçn bao nhi√™u)

### 1) T·ª∑ l·ªá bi·∫øn c·ªë (p)

**L·∫•y ·ªü ƒë√¢u:** s·ªë li·ªáu b·ªánh vi·ªán/ƒëo√†n h·ªá g·∫ßn nh·∫•t; n·∫øu thi·∫øu d√πng y vƒÉn.
**Kho·∫£ng hay d√πng khi l·∫≠p k·∫ø ho·∫°ch:** 5%‚Äì15% (t√πy b·ªánh).
**Khuy·∫øn ngh·ªã:** ch·∫°y ƒë·ªô nh·∫°y theo kho·∫£ng plausible.

### 2) S·ªë tham s·ªë (df) (P)

**L·∫•y ·ªü ƒë√¢u:** ƒë·∫∑c t·∫£ m√¥ h√¨nh d·ª± ki·∫øn (bao g·ªìm dummy, spline, t∆∞∆°ng t√°c).
**Th√¥ng l·ªá:** 10‚Äì30 df kh√° ph·ªï bi·∫øn; df c√†ng l·ªõn c√†ng c·∫ßn m·∫´u l·ªõn.

### 3) AUC m·ª•c ti√™u (Mode A)

**L·∫•y ·ªü ƒë√¢u:** m√¥ h√¨nh t∆∞∆°ng t·ª± ƒë√£ c√¥ng b·ªë (∆∞u ti√™n ngo·∫°i ki·ªÉm), pilot data.
**Th√¥ng l·ªá:** 0,70‚Äì0,85 th∆∞·ªùng g·∫∑p; >0,90 th∆∞·ªùng hi·∫øm v√† d·ªÖ l·∫°c quan.

### 4) Danh s√°ch (N) ·ª©ng vi√™n

Ch·ªçn d·∫£i ƒë·ªß r·ªông ƒë·ªÉ th·∫•y ng∆∞·ª°ng ƒë·∫°t/kh√¥ng ƒë·∫°t (v√≠ d·ª• 1000‚Äì5000).

### 5) S·ªë m√¥ ph·ªèng m·ªói (N) (R)

* Demo: (R \\approx 200)
* Final: (R \\ge 1000)
  Sai s·ªë Monte Carlo cho x√°c su·∫•t ƒë·∫°t:
  $$
  \\mathrm{MCSE}=\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{R}}.
  $$

### 6) Ti√™u ch√≠ Pass/Fail

* Mean calibration slope ‚â• 0.9
* Pr(0.9 ‚â§ slope ‚â§ 1.1) ‚â• 80%
* Mean AUC ‚â• target

**Th√¥ng l·ªá:** slope 0,90‚Äì1,10 v√† ng∆∞·ª°ng x√°c su·∫•t 0,80 hay d√πng cho planning; 0,90 n·∫øu mu·ªën ch·∫Øc ch·∫Øn h∆°n.

---

# ƒêi·ªÉm m·∫°nh v√† ƒëi·ªÉm y·∫øu

**ƒêi·ªÉm m·∫°nh**

* Linh ho·∫°t (t∆∞∆°ng quan, phi tuy·∫øn, t∆∞∆°ng t√°c).
* Nh·∫Øm tr·ª±c ti·∫øp hi·ªáu nƒÉng tr√™n d·ªØ li·ªáu m·ªõi, ƒë·∫∑c bi·ªát calibration.
* D·ªÖ l√†m ph√¢n t√≠ch ƒë·ªô nh·∫°y.

**ƒêi·ªÉm y·∫øu**

* Ph·ª• thu·ªôc m·∫°nh v√†o gi·∫£ ƒë·ªãnh DGM.
* T·ªën t√†i nguy√™n t√≠nh to√°n.
* Ph·∫£i m√¥ ph·ªèng ƒë√∫ng pipeline d·ª± ƒë·ªãnh; n·∫øu kh√¥ng d·ªÖ sai l·ªách.

---

## T√†i li·ªáu tham kh·∫£o

1. Pavlou M, Ambler G, Seaman SR, et al. *How to develop a more accurate risk prediction model when there are few events.* BMJ. 2015.
2. Riley RD, Snell KIE, Ensor J, et al. *Minimum sample size required for developing a multivariable prediction model: Part II‚Äîbinary and time-to-event outcomes.* Statistics in Medicine. 2019.
3. Pavlou M, et al. *Simulation-based sample size calculation for prediction model performance targets* (validation/development methodology). Statistics in Medicine. 2021.
4. Steyerberg EW. *Clinical Prediction Models: A Practical Approach to Development, Validation, and Updating.* 2nd ed. Springer. 2019.
""",
    "c7_content_md": """
## C7: Bayesian Assurance (MCMC) ‚Äî Ti·∫øng Vi·ªát

### Ph∆∞∆°ng ph√°p n√†y l√† g√¨?
**Bayesian assurance** l√† ph∆∞∆°ng ph√°p l·∫≠p k·∫ø ho·∫°ch c·ª° m·∫´u b·∫±ng m√¥ ph·ªèng cho **x√¢y d·ª±ng m√¥ h√¨nh Bayes** (·ªü ƒë√¢y: h·ªìi quy logistic Bayes cho k·∫øt c·ª•c nh·ªã ph√¢n).  
Kh√°c v·ªõi ‚Äúpower‚Äù (frequentist), assurance nh·∫Øm t·ªõi **x√°c su·∫•t v√¥ ƒëi·ªÅu ki·ªán** ƒë·ªÉ nghi√™n c·ª©u ƒë·∫°t **ti√™u ch√≠ th√†nh c√¥ng** ƒë√£ ƒë·ªãnh tr∆∞·ªõc (v√≠ d·ª•: ti√™u ch√≠ calibration, discrimination v√†/ho·∫∑c ƒë·ªô ch√≠nh x√°c h·∫≠u nghi·ªám).

N√≥i ƒë∆°n gi·∫£n:
> ‚ÄúN·∫øu l·∫∑p l·∫°i to√†n b·ªô nghi√™n c·ª©u nhi·ªÅu l·∫ßn (sinh d·ªØ li·ªáu + fit Bayes b·∫±ng MCMC), x√°c su·∫•t m√¥ h√¨nh ƒë·∫°t y√™u c·∫ßu l√† bao nhi√™u?‚Äù

---

### Khi n√†o n√™n d√πng
D√πng C7 khi:
- Ph√¢n t√≠ch cu·ªëi c√πng l√† **Bayes** v√† ∆∞·ªõc l∆∞·ª£ng b·∫±ng **MCMC**.
- B·∫°n mu·ªën ch·ªçn c·ª° m·∫´u sao cho ƒë·∫°t **x√°c su·∫•t th√†nh c√¥ng m·ª•c ti√™u** (v√≠ d·ª• ‚â•80% ho·∫∑c ‚â•90%).
- B·∫°n c√≥ th·ªÉ ƒë∆∞a ra gi·∫£ ƒë·ªãnh h·ª£p l√Ω v·ªÅ:
  - t·ª∑ l·ªá bi·∫øn c·ªë t·∫°i b·ªánh vi·ªán,
  - c·∫•u tr√∫c t∆∞∆°ng quan c·ªßa bi·∫øn d·ª± b√°o,
  - hi·ªáu ·ª©ng h·ª£p l√Ω (pilot/y vƒÉn),
  - prior cho c√°c h·ªá s·ªë h·ªìi quy.

### Khi n√†o kh√¥ng n√™n d√πng (ho·∫∑c c·∫ßn th·∫≠n tr·ªçng)
Kh√¥ng n√™n ch·ªâ d·ª±a v√†o C7 khi:
- Kh√¥ng th·ªÉ bi·ªán minh prior ho·∫∑c **c∆° ch·∫ø sinh d·ªØ li·ªáu (DGM)**.
- H·∫°n ch·∫ø t√†i nguy√™n t√≠nh to√°n (MCMC t·ªën th·ªùi gian; nh·∫°y v·ªõi c√†i ƒë·∫∑t).
- Pipeline th·ª±c t·∫ø c√≥ b∆∞·ªõc ‚Äúdata-adaptive‚Äù l·ªõn (ch·ªçn bi·∫øn/tuning) nh∆∞ng b·∫°n **kh√¥ng m√¥ ph·ªèng ƒë·∫ßy ƒë·ªß** pipeline ƒë√≥.
- D·ªØ li·ªáu c√≥ c·ª•m/ƒëa trung t√¢m nh∆∞ng DGM b·ªè qua clustering (d·ªÖ ƒë√°nh gi√° thi·∫øu c·ª° m·∫´u).

---

## M√¥ h√¨nh v√† DGM

### H·ªìi quy logistic Bayes (m√¥ h√¨nh ph√¢n t√≠ch)
\[
Y_i \sim \\text{Bernoulli}(\\pi_i), \\qquad
\\text{logit}(\\pi_i)=\\beta_0 + \\sum_{j=1}^{P}\\beta_j f_j(X_{ij})
\]
- \(P\) = s·ªë tham s·ªë/df (**kh√¥ng t√≠nh intercept**).
- \(f_j(\cdot)\): c√°ch m√£ h√≥a bi·∫øn (tuy·∫øn t√≠nh, dummy, spline, t∆∞∆°ng t√°c‚Ä¶).

**V√≠ d·ª• prior ‚Äúweakly informative‚Äù hay d√πng:**
\[
\\beta_j \sim \\mathcal{N}(0,\\sigma_\\beta^2),\\quad \\sigma_\\beta \\in [1, 2.5],
\\qquad \\beta_0 \sim \\mathcal{N}(0, 5^2)
\]
(Trong th·ª±c h√†nh c·∫ßn ch·∫°y ƒë·ªô nh·∫°y theo prior h·ª£p l√Ω.)

### DGM cho bi·∫øn d·ª± b√°o (v√≠ d·ª• equicorrelation)
N·∫øu app d√πng m·ªôt tham s·ªë t∆∞∆°ng quan \\(\\rho\\) (m·ªçi c·∫∑p bi·∫øn c√≥ c√πng t∆∞∆°ng quan):
\[
\\mathrm{Corr}(X_j, X_k)=\\rho \\quad (j\\neq k),
\\qquad
\\Sigma_{jk}=
\\begin{cases}
1,& j=k\\\\
\\rho,& j\\neq k
\\end{cases}
\]
Sau ƒë√≥ sinh d·ªØ li·ªáu d·ª± b√°o theo c∆° ch·∫ø t∆∞∆°ng quan (v√≠ d·ª• Gaussian copula), r·ªìi chuy·ªÉn th√†nh bi·∫øn li√™n t·ª•c/nh·ªã ph√¢n.

### Kh·ªõp t·ª∑ l·ªá bi·∫øn c·ªë m·ª•c ti√™u
Ch·ªçn intercept (ho·∫∑c h·∫±ng s·ªë hi·ªáu ch·ªânh) ƒë·ªÉ:
\[
\\mathbb{E}[\\pi_i]=p
\]
(th∆∞·ªùng gi·∫£i b·∫±ng root-finding d·ª±a tr√™n m√¥ ph·ªèng \\(X\\).)

---

## ‚ÄúAssurance‚Äù l√† g√¨ (c√¥ng th·ª©c ch√≠nh)
G·ªçi:
- \\(\\theta\\): tham s·ªë ‚Äúth·∫≠t‚Äù theo DGM,
- \\(y\\): d·ªØ li·ªáu quan s√°t c·ª° m·∫´u \\(N\\),
- \\(S(y)\\): bi·∫øn ch·ªâ b√°o th√†nh c√¥ng (1 n·∫øu ƒë·∫°t ti√™u ch√≠, 0 n·∫øu kh√¥ng).

**Assurance t·∫°i c·ª° m·∫´u \\(N\\):**
\[
\\mathcal{A}(N)=\\Pr(\\text{th√†nh c√¥ng t·∫°i }N)
=\\mathbb{E}_{\\theta}\\left[\\mathbb{E}_{y\\mid \\theta,N}\\left\\{S(y)\\right\\}\\right]
\]

**∆Ø·ªõc l∆∞·ª£ng Monte Carlo trong app (v·ªõi \\(R\\) m√¥ ph·ªèng cho m·ªói \\(N\\)):**
\[
\\widehat{\\mathcal{A}}(N)=\\frac{1}{R}\\sum_{r=1}^{R} S\\!\\left(y^{(r)}\\right)
\]

Sai s·ªë Monte Carlo:
\[
\\mathrm{MCSE}\\left(\\widehat{\\mathcal{A}}(N)\\right)
=\\sqrt{\\frac{\\widehat{\\mathcal{A}}(N)\\left[1-\\widehat{\\mathcal{A}}(N)\\right]}{R}}
\]

**Quy t·∫Øc ch·ªçn c·ª° m·∫´u:**
Ch·ªçn \\(N\\) nh·ªè nh·∫•t sao cho:
\[
\\widehat{\\mathcal{A}}(N)\\ge \\mathcal{A}_\\text{target}
\]
(v√≠ d·ª• 0,80 ho·∫∑c 0,90).

---

## Ti√™u ch√≠ th√†nh c√¥ng (v√≠ d·ª• th∆∞·ªùng d√πng)
T√πy c·∫•u h√¨nh app, c√≥ th·ªÉ ch·ªçn m·ªôt ho·∫∑c nhi·ªÅu ti√™u ch√≠:
- **Calibration slope** trong kho·∫£ng ch·∫•p nh·∫≠n:
  \[
  0.90 \le b \le 1.10
  \]
  v·ªõi \\(b\\) ∆∞·ªõc l∆∞·ª£ng t·ª´ m√¥ h√¨nh hi·ªáu ch·ªânh tr√™n d·ªØ li·ªáu test/validation:
  \[
  \\text{logit}(Y)=a + b\\cdot \\text{logit}(\\widehat{p})
  \]
- **Discrimination (AUC)**:
  \[
  \\mathrm{AUC} \\ge 0.75 \\;(\\text{ho·∫∑c ng∆∞·ª°ng do b·∫°n ch·ªçn})
  \]
- **ƒê·ªô ch√≠nh x√°c h·∫≠u nghi·ªám**, v√≠ d·ª• ƒë·ªô r·ªông CrI 95% c·ªßa slope:
  \[
  \\mathrm{Width}\\left(\\text{CrI}_{95\\%}(b)\\right) \\le w
  \\quad (\\text{v√≠ d·ª• } w=0.20)
  \]

---

## Ch√∫ gi·∫£i ƒë·∫ßu v√†o (t√¨m ·ªü ƒë√¢u; ch·ªçn bao nhi√™u)

### 1) T·ª∑ l·ªá bi·∫øn c·ªë \\(p\\)
**Ngu·ªìn:** d·ªØ li·ªáu h·ªìi c·ª©u/ƒëo√†n h·ªá g·∫ßn nh·∫•t t·∫°i b·ªánh vi·ªán; registry; y vƒÉn t∆∞∆°ng ƒë·ªìng.  
**Th√¥ng l·ªá khi l·∫≠p k·∫ø ho·∫°ch:** 0,05‚Äì0,15 th∆∞·ªùng g·∫∑p (t√πy b·ªánh).  
**Khuy·∫øn ngh·ªã:** ch·∫°y ƒë·ªô nh·∫°y theo kho·∫£ng plausible.

### 2) S·ªë tham s·ªë (df) \\(P\\)
**Ngu·ªìn:** ƒë·∫∑c t·∫£ m√¥ h√¨nh d·ª± ki·∫øn (ƒë·∫øm theo tham s·ªë, kh√¥ng ph·∫£i s·ªë bi·∫øn).  
Bao g·ªìm dummy, spline, t∆∞∆°ng t√°c; kh√¥ng t√≠nh intercept.  
**Th√¥ng l·ªá:** 10‚Äì30 df; df c√†ng cao c√†ng c·∫ßn m·∫´u l·ªõn v√† prior h·ª£p l√Ω.

### 3) T∆∞∆°ng quan bi·∫øn d·ª± b√°o \\(\\rho\\)
**Ngu·ªìn:** ∆∞·ªõc l∆∞·ª£ng t·ª´ d·ªØ li·ªáu b·ªánh vi·ªán (ma tr·∫≠n t∆∞∆°ng quan c·ªßa bi·∫øn ·ª©ng vi√™n).  
N·∫øu ch∆∞a bi·∫øt, ch·∫°y ƒë·ªô nh·∫°y (0; 0,1; 0,3).  
**Th√¥ng l·ªá:** 0‚Äì0,3 l√† m·ª©c nh·∫π‚Äìv·ª´a; t∆∞∆°ng quan cao l√†m tƒÉng b·∫•t ·ªïn v√† c√≥ th·ªÉ tƒÉng c·ª° m·∫´u.

### 4) Danh s√°ch \\(N\\) ·ª©ng vi√™n
Ch·ªçn d·∫£i ƒë·ªß r·ªông ƒë·ªÉ th·∫•y ng∆∞·ª°ng ƒë·∫°t/kh√¥ng ƒë·∫°t (500‚Äì2000 ho·∫∑c h∆°n t√πy kh·∫£ thi).

### 5) S·ªë m√¥ ph·ªèng m·ªói \\(N\\) (R)
- **Demo:** 50‚Äì200  
- **Final:** ‚â•500‚Äì1000  
D√πng MCSE ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô ·ªïn ƒë·ªãnh.

### 6) Ng∆∞·ª°ng assurance \\(\\mathcal{A}_\\text{target}\\)
- **0,80:** hay d√πng khi ∆∞u ti√™n kh·∫£ thi  
- **0,90:** khi mu·ªën ch·∫Øc ch·∫Øn cao h∆°n

---

## ∆Øu ƒëi·ªÉm v√† nh∆∞·ª£c ƒëi·ªÉm
**∆Øu ƒëi·ªÉm**
- Ph√π h·ª£p ‚Äúend-to-end‚Äù v·ªõi workflow Bayes; nh·∫Øm tr·ª±c ti·∫øp ti√™u ch√≠ h·∫≠u nghi·ªám.
- Linh ho·∫°t v·ªõi DGM, t∆∞∆°ng quan, ti√™u ch√≠ hi·ªáu nƒÉng v√† ƒë·ªô ch√≠nh x√°c.
- C√≥ th·ªÉ x·ª≠ l√Ω bi·∫øn c·ªë hi·∫øm t·ªët h∆°n khi d√πng prior co r√∫t (regularizing priors).

**Nh∆∞·ª£c ƒëi·ªÉm**
- T·ªën t√≠nh to√°n; nh·∫°y v·ªõi c√†i ƒë·∫∑t MCMC v√† h·ªôi t·ª•.
- Ph·ª• thu·ªôc gi·∫£ ƒë·ªãnh DGM v√† prior ‚Üí c·∫ßn ph√¢n t√≠ch ƒë·ªô nh·∫°y.
- Ph·∫£i m√¥ ph·ªèng ƒë√∫ng pipeline d·ª± ki·∫øn ƒë·ªÉ tr√°nh ∆∞·ªõc t√≠nh sai.

---

## T√†i li·ªáu tham kh·∫£o
1) O'Hagan A. Assurance in clinical trial design. *Pharmaceutical Statistics.* 2005.  
2) Pan J, Banerjee S. bayesassurance: An R Package for Calculating Sample Size and Bayesian Assurance. *The R Journal.* 2023.  
3) Gelman A, Jakulin A, Pittau MG, Su Y-S. A weakly informative default prior distribution for logistic and other regression models. *The Annals of Applied Statistics.* 2008.  
4) Sahu SK, Smith TMF. Bayesian methods of sample size determination. *Statistical Methodology / related Bayesian SSD literature.* 2006.
""",
        # Email & Reporting
        "report_header": "B√°o c√°o & T·∫£i xu·ªëng",
        "btn_download_report": "T·∫£i B√°o c√°o (VƒÉn b·∫£n)",
        "btn_download_html": "T·∫£i B√°o c√°o (ƒê·ªãnh d·∫°ng HTML)",
        "btn_download_csv": "T·∫£i K·∫øt qu·∫£ (CSV)",
        "report_title": "B√°o c√°o T√≠nh to√°n C·ª° m·∫´u",
        "footer_text": "T√°c gi·∫£ & Qu·∫£n tr·ªã: Minh Nguy·ªÖn (minhnt@ump.edu.vn) B·ªô m√¥n D·ªãch t·ªÖ h·ªçc, Khoa Y t·∫ø C√¥ng c·ªông, ƒê·∫°i h·ªçc Y D∆∞·ª£c TP. H·ªì Ch√≠ Minh, Vi·ªát Nam",
        "btn_refresh": "L√†m m·ªõi / ƒê·∫∑t l·∫°i",
        "email_header": "G·ª≠i K·∫øt qu·∫£ qua Email",
        "email_to": "Email Ng∆∞·ªùi nh·∫≠n",
        "email_send_btn": "G·ª≠i Email",
        "email_success": "ƒê√£ g·ª≠i email th√†nh c√¥ng!",
        "email_error": "L·ªói khi g·ª≠i email:",
        "email_settings": "C√†i ƒë·∫∑t Email (SMTP)",
        "email_sender": "Email C·ªßa B·∫°n",
        "email_password": "M·∫≠t kh·∫©u ·ª®ng d·ª•ng",
        "email_subject_default": "K·∫øt qu·∫£ T√≠nh to√°n C·ª° m·∫´u",
}
