KO = {
        "title": "ì˜ˆí›„ ì—°êµ¬ í‘œë³¸ í¬ê¸° ë„êµ¬",
        "sidebar_title": "ì„¤ì •",
        "language": "ì–¸ì–´ / Language",
        "mode": "ë°©ë²• ì„ íƒ",
        "mode_riley": "ë°©ë²• 1: Riley ë“± (ë¶„ì„ì )",
        "mode_bayes": "ë°©ë²• 2: ë² ì´ì§€ì•ˆ ë³´ì¦ (ì‹œë®¬ë ˆì´ì…˜)",
        "mode_single": "ë‹¨ì¼ ì‹œë‚˜ë¦¬ì˜¤",
        "mode_batch": "ë¯¼ê°ë„ ë¶„ì„ (ë²”ìœ„)",
        "method1_tab": "ë°©ë²• 1 (Riley)",
        "method2_tab": "ë°©ë²• 2 (Bayesian)",
        "nav_title": "íƒìƒ‰",
        "nav_readme": "ìƒì„¸ ë¬¸ì„œ (README)",
        "nav_intro": "ì†Œê°œ ë° ê³µì‹",
        "nav_calc": "í‘œë³¸ í¬ê¸° ê³„ì‚°ê¸°",
        "intro_heading": "í™˜ì˜í•©ë‹ˆë‹¤",
        "intro_text": "ì´ ë„êµ¬ëŠ” ì´ë¶„í˜• ê²°ê³¼ê°€ ìˆëŠ” ì„ìƒ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œì— í•„ìš”í•œ ìµœì†Œ í‘œë³¸ í¬ê¸°ë¥¼ ê³„ì‚°í•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤.",
        "formula_heading": "ìˆ˜í•™ì  í”„ë ˆì„ì›Œí¬ (ë°©ë²• 1)",
        "formula_intro": "ë°©ë²• 1ì€ Riley ë“±ì´ ì œê³µí•œ íì‡„í˜• ì†”ë£¨ì…˜ì„ ì‚¬ìš©í•˜ê³ , ë°©ë²• 2ëŠ” ë² ì´ì§€ì•ˆ MCMC ì‹œë®¬ë ˆì´ì…˜ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.",
        "sens_guide_title": "ğŸ’¡ ë¯¼ê°ë„ ë¶„ì„(ë°°ì¹˜ ëª¨ë“œ) ì‚¬ìš©ë²•",
        "sens_guide_text": """
        - **ë²”ìœ„**: `min-max` í˜•ì‹ìœ¼ë¡œ ì…ë ¥ (ì˜ˆ: `0.05-0.10`). ë‹¨ê³„ê°€ ìë™ìœ¼ë¡œ ìƒì„±ë©ë‹ˆë‹¤.
        - **íŠ¹ì • ê°’**: ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ëª©ë¡ ì…ë ¥ (ì˜ˆ: `0.05, 0.10, 0.15`).
        """,
        "detail_view": "ì‹œë‚˜ë¦¬ì˜¤ë³„ ìƒì„¸ ê³„ì‚° ë³´ê¸°",
        "footer_refs": "ì°¸ê³ ë¬¸í—Œ: Riley et al. (2018, 2020), BayesAssurance.",
        "calc_btn": "ê³„ì‚°í•˜ê¸°",
        "results": "ê²°ê³¼",
        "sanity": "ê±´ì „ì„± ì‹¬ì‚¬ (EPV ê·œì¹™)",
        "download_csv": "CSV ë‹¤ìš´ë¡œë“œ",
        "download_report": "ì „ì²´ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ",
        "error_p": "ìœ ë³‘ë¥ ì€ 0ê³¼ 1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.",
        "error_auc": "AUCëŠ” 0.5ì™€ 1 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.",
        "error_parse": "ì…ë ¥ì„ êµ¬ë¬¸ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "riley_inputs": "ì…ë ¥ íŒŒë¼ë¯¸í„° (Riley)",
        "prevalence": "ê²°ê³¼ ìœ ë³‘ë¥  (ì´ë²¤íŠ¸ ë°œìƒë¥ )",
        "prevalence_help": "ì´ë²¤íŠ¸ê°€ ë°œìƒí•œ ì°¸ê°€ìì˜ ë¹„ìœ¨ (0 < p < 1).",
        "parameters": "ì˜ˆì¸¡ ë³€ìˆ˜ íŒŒë¼ë¯¸í„° ìˆ˜ (df)",
        "parameters_help": "ì´ ììœ ë„ (ì ˆí¸ ì œì™¸).",
        "shrinkage": "ëª©í‘œ ê¸€ë¡œë²Œ ìˆ˜ì¶• (S)",
        "shrinkage_help": "í¬ë§í•˜ëŠ” ìˆ˜ì¶• ê³„ìˆ˜ (ê¸°ë³¸ê°’ 0.9).",
        "perf_measure": "ì˜ˆìƒ ì„±ëŠ¥",
        "perf_auc": "AUC (C-í†µê³„ëŸ‰)",
        "perf_r2": "Cox-Snell R-ì œê³±",
        "perf_cons": "ë³´ìˆ˜ì  ì ìˆ˜ (ìµœëŒ€ R2ì˜ 15%)",
        "bayes_inputs": "ì‹œë®¬ë ˆì´ì…˜ ì„¤ì • (ë² ì´ì§€ì•ˆ ë³´ì¦)",
        "dgm_settings": "ë°ì´í„° ìƒì„± ë§¤ì»¤ë‹ˆì¦˜",
        "sim_settings": "ì‹œë®¬ë ˆì´ì…˜ ë° MCMC",
        "eval_settings": "í‰ê°€ ê¸°ì¤€",
        "n_candidates": "í›„ë³´ í‘œë³¸ í¬ê¸° (ì‰¼í‘œë¡œ êµ¬ë¶„)",
        "n_candidates_help": "í…ŒìŠ¤íŠ¸í•  N ê°’ ëª©ë¡, ì˜ˆ: 500, 1000, 1500.",
        "correlation": "ì˜ˆì¸¡ ë³€ìˆ˜ ìƒê´€ê´€ê³„ (rho)",
        "n_sims": "Në‹¹ ì‹œë®¬ë ˆì´ì…˜ íšŸìˆ˜",
        "assurance_threshold": "ë³´ì¦ ì„ê³„ê°’ (ëª©í‘œ í™•ë¥ )",
        "run_simulation": "ë² ì´ì§€ì•ˆ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰",
        "simulation_running": "ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰ ì¤‘... ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        "assurance_result": "ë³´ì¦ ë¶„ì„",
        "mode_dev_sim": "ë°©ë²• 6: ê°œë°œ ì‹œë®¬ë ˆì´ì…˜ (ë¹ˆë„ì£¼ì˜)",
        "method6_tab": "ë°©ë²• 6 (ì‹œë®¬ë ˆì´ì…˜)",
        "dev_sim_intro": "ëª¨ë¸ ê°œë°œì„ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ í‘œë³¸ í¬ê¸° (samplesizedevì™€ ìœ ì‚¬í•œ ë¹ˆë„ì£¼ì˜ ì ‘ê·¼ë²•).",
        "dev_mode_simple": "ëª¨ë“œ A: ë‹¨ìˆœ (AUC ê¸°ë°˜)",
        "dev_mode_custom": "ëª¨ë“œ B: ì‚¬ìš©ì ì •ì˜ DGM",
        "target_auc": "ëª©í‘œ í‰ê·  AUC (C-í†µê³„ëŸ‰)",
        "target_auc_help": "ì•Œê³ ë¦¬ì¦˜ì´ ì´ AUCë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ ë² íƒ€ ê³„ìˆ˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.",
        "criteria_settings": "ì„±ëŠ¥ ê¸°ì¤€ (í†µê³¼/ì‹¤íŒ¨)",
        "crit_slope_mean": "í‰ê·  êµì • ê¸°ìš¸ê¸° >= 0.9",
        "crit_slope_ci": "Pr(0.9 <= ê¸°ìš¸ê¸° <= 1.1) >= 80%",
        "crit_auc": "í‰ê·  AUC >= ëª©í‘œ",
        "audit_trail": "RNG ê°ì‚¬ ì¶”ì  (JSON)",
        "future_methods": "í–¥í›„ ë²„ì „ì—ì„œ ì œê³µ ì˜ˆì •...",
        "method_quick_tab": "A. ì‹ ì† / ê¸°ë³¸",
        "quick_mode_epv": "A1: EPV / EPP ê·œì¹™ (ê²½í—˜ì )",
        "quick_mode_risk": "A2: ê¸°ë³¸ ìœ„í—˜ ì •ë°€ë„ (CI ë„ˆë¹„)",
        "target_epv": "ëª©í‘œ íŒŒë¼ë¯¸í„°ë‹¹ ì´ë²¤íŠ¸ ìˆ˜ (EPP)",
        "target_epv_help": "ì¼ë°˜ì ì¸ ê²½í—˜ì  ìˆ˜ì¹˜ëŠ” 10, 15, 20ì…ë‹ˆë‹¤. EPPê°€ EPVë³´ë‹¤ ì„ í˜¸ë©ë‹ˆë‹¤.",
        "epv_warning_title": "âš ï¸ ì¤‘ìš” ê²½ê³ ",
        "epv_warning_text": "EPV/EPPëŠ” ëŒ€ëµì ì¸ ê²½í—˜ì  ê·œì¹™ì…ë‹ˆë‹¤. êµì •, íŒë³„ì„ ë³´ì¥í•˜ê±°ë‚˜ ë‚™ê´€ì£¼ì˜ë¥¼ ë°©ì§€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë³€ìˆ˜ ì„ íƒ ë° ë¹„ì„ í˜• í•­ì— ë¯¼ê°í•©ë‹ˆë‹¤.",
        "ci_level": "ì‹ ë¢° ìˆ˜ì¤€",
        "ci_half_width": "ëª©í‘œ ë°˜-ë„ˆë¹„ (ì˜¤ì°¨ í•œê³„)",
        "ci_method": "CI ë°©ë²•",
        "ci_method_wilson": "Wilson Score (ê¶Œì¥)",
        "ci_method_wald": "Wald (ë‹¨ìˆœ)",
        "ci_method_cp": "Clopper-Pearson (ë³´ìˆ˜ì )",
        "risk_help": "íŠ¹ì • ì •ë°€ë„ë¡œ ì´ë²¤íŠ¸ ë°œìƒë¥  pë¥¼ ì¶”ì •í•˜ê¸° ìœ„í•œ Nì„ ê³„ì‚°í•©ë‹ˆë‹¤. ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
        "title_b3": "B3: ë¡œì§€ìŠ¤í‹± ê²€ì •ë ¥ (Hsieh)",
        "title_b4": "B4: Cox ê²€ì •ë ¥ (Schoenfeld)",
        "interpretation": "ê²°ê³¼ í•´ì„",
        "d8_assumptions": "**ê°€ì •**: Hanley & McNeil (1982) ë¶„ì‚° ê·¼ì‚¬ì¹˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. AUCì— ëŒ€í•´ ëŒ€ì¹­ì  ì •ê·œ ë¶„í¬ë¥¼ ê°€ì •í•©ë‹ˆë‹¤.",
        "d8_mode_n_to_width": "Nìœ¼ë¡œë¶€í„° CI ë„ˆë¹„ ê³„ì‚°",
        "d8_mode_width_to_n": "CI ë„ˆë¹„ë¡œë¶€í„° í•„ìš”í•œ N ê³„ì‚°",
        "d8_opt_settings": "ê³ ê¸‰ ìµœì í™” ì„¤ì •",
        "d8_practical_rounding": "ì‹¤ìš©ì ì¸ ì •ìˆ˜ ë°˜ì˜¬ë¦¼ í‘œì‹œ",
        "d8_n_input": "í‘œë³¸ í¬ê¸° (N)",
        "d8_width_input": "CI ë„ˆë¹„ (í•©ê³„)",
        "d8_opt_bound": "íƒìƒ‰ ìƒí•œì„ ",
        "d8_opt_tol": "í—ˆìš© ì˜¤ì°¨",
        "title_d8": "D8: AUC ì •ë°€ë„ (Hanley-McNeil)",
        "d8_desc": "í¬ë§í•˜ëŠ” ì •ë°€ë„(CI ë„ˆë¹„)ë¡œ AUCë¥¼ ì¶”ì •í•˜ê¸° ìœ„í•œ í‘œë³¸ í¬ê¸°ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.",
        "auc_expected": "ì˜ˆìƒ AUC (C-í†µê³„ëŸ‰)",
        "formulas_header": "ğŸ“š ê³µì‹ ë° ê¸°ìˆ ì  ì„¸ë¶€ ì‚¬í•­",
        "title_d9": "D9: ì™¸ë¶€ ê²€ì¦ (ë§ì¶¤í˜•)",
        "common_inputs": "ê³µí†µ íŒŒë¼ë¯¸í„°",
        "search_placeholder": "ë°©ë²• ê²€ìƒ‰...",
        "settings": "ì„¤ì •",
        "footer_copyright": "Â© 2026 Prognostic Research Sample Size Tool. í•™ìˆ /ì—°êµ¬ìš© ì „ìš©.",
        "footer_author": "ì €ì ë° ìœ ì§€ê´€ë¦¬: Minh Nguyen (minhnt@ump.edu.vn)",
        "footer_disclaimer": "ë©´ì±… ì¡°í•­: ì„ìƒì  ë³´ì¦ ì—†ìŒ. ì‚¬ìš©ìëŠ” ê²°ê³¼ ê²€ì¦ ë° í•´ì„ì— ëŒ€í•œ ì±…ì„ì´ ìˆìŠµë‹ˆë‹¤.",

        "intro_complete_md": """
### í™˜ì˜í•©ë‹ˆë‹¤

ì´ ì•±ì€ ì„ìƒì˜ì™€ ì—°êµ¬ìê°€ ì˜ˆí›„ ì—°êµ¬ë¥¼ ìœ„í•œ ìµœì†Œ í‘œë³¸ í¬ê¸°ë¥¼ ê³„íší•˜ëŠ” ë° ë„ì›€ì„ ì¤ë‹ˆë‹¤:
* ì˜ˆí›„ ì¸ì ì—°êµ¬ (ì—°ê´€ì„± ê²€ì¶œì„ ìœ„í•œ ê²€ì •ë ¥),
* ì„ìƒ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ (ìœ„í—˜ ì˜ˆì¸¡), ë°
* ëª¨ë¸ ê²€ì¦ / ì—…ë°ì´íŠ¸ (ì™¸ë¶€ ê²€ì¦, ì¬ë³´ì •).

ì´ ë„êµ¬ëŠ” ì´ë¶„í˜• ê²°ê³¼ (ì˜ˆ: ì‚¬ê±´ ë°œìƒ vs ë¯¸ë°œìƒ) ë° ì¼ë¶€ ëª¨ë“ˆì—ì„œëŠ” ìƒì¡´ ì‹œê°„ ê²°ê³¼ (Cox ë¹„ë¡€ìœ„í—˜)ë¥¼ ìœ„í•´ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

ì†ŒìŠ¤ ì½”ë“œ (ë‹¤ìš´ë¡œë“œ): [https://gitlab.com/minhthiennguyen/pmsample/](https://gitlab.com/minhthiennguyen/pmsample/)

### ì‹œì‘ ê°€ì´ë“œ (ì‹ ê·œ ì‚¬ìš©ììš©)

#### 1. ì—°êµ¬ ëª©í‘œ ëª…í™•í™”
* ë‹¨ì¼ ì˜ˆí›„ ì¸ì (ì—°ê´€ì„±)ë¥¼ ê²€ì •í•˜ì‹œë‚˜ìš”?
* ì˜ˆì¸¡ ëª¨ë¸ì„ ê°œë°œí•˜ì‹œë‚˜ìš”?
* ìƒˆë¡œìš´ ì§‘ë‹¨ì—ì„œ ê¸°ì¡´ ëª¨ë¸ì„ ê²€ì¦í•˜ì‹œë‚˜ìš”?

#### 2. ì‚¬ê±´ ë°œìƒë¥  $p$ ì¶”ì • (ë˜ëŠ” ìƒì¡´ë¶„ì„ì„ ìœ„í•œ ì‚¬ê±´ ë¶„ìœ¨)
* ê°€ëŠ¥í•˜ë©´ ì§€ì—­ ë³‘ì› ë°ì´í„°ë¥¼ ìš°ì„  ì‚¬ìš©í•˜ì„¸ìš” (ê°€ì¥ ì¢‹ìŒ).
* ë¶ˆí™•ì‹¤í•œ ê²½ìš°, ë²”ìœ„ë¥¼ ì…ë ¥í•˜ê³  ë¯¼ê°ë„ ë¶„ì„ì„ ì‹¤í–‰í•˜ì„¸ìš”.

#### 3. ëª¨ë¸ ë³µì¡ë„ ì •í™•íˆ ê³„ì‚° (íŒŒë¼ë¯¸í„° / ììœ ë„)
"ë³€ìˆ˜ ìˆ˜"ê°€ ì•„ë‹Œ íŒŒë¼ë¯¸í„° (ììœ ë„)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
* ì´ë¶„í˜• ì˜ˆì¸¡ë³€ìˆ˜: 1 df
* $L$ ìˆ˜ì¤€ ë²”ì£¼í˜•: $L-1$ df
* ìŠ¤í”Œë¼ì¸ (RCS, $K$ ë§¤ë“­): $K-1$ df
* ìƒí˜¸ì‘ìš©: $df(A \\times B) = df(A) \\cdot df(B)$

#### 4. ì•„ë˜ ì¹´íƒˆë¡œê·¸ì—ì„œ ë°©ë²• ì„ íƒ
* **"ë¹ ë¥¸ ë„êµ¬"**ëŠ” ëŒ€ëµì ì¸ ê³„íšì—ë§Œ ì‚¬ìš©í•˜ì„¸ìš”.
* ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ ì‹œ **Riley / ì‹œë®¬ë ˆì´ì…˜ / ë³´ì¦** ë°©ë²•ì„ ì‚¬ìš©í•˜ì„¸ìš”.

---

### ì´ ì•±ì„ ì‚¬ìš©í•´ì•¼ í•  ë•Œ (ê·¸ë¦¬ê³  ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ë•Œ)

**ë‹¤ìŒ ê²½ìš°ì— ì´ ì•±ì„ ì‚¬ìš©í•˜ì„¸ìš”:**
* ì˜ˆí›„/ì˜ˆì¸¡ ë¶„ì•¼ì—ì„œ í›„í–¥ì  ë˜ëŠ” ì „í–¥ì  ì½”í˜¸íŠ¸ ì—°êµ¬ ê³„íš
* ìœ„í—˜ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ ë˜ëŠ” ê²€ì¦
* ìœ ë³‘ë¥  ë˜ëŠ” AUCì˜ ì •ë°€ë„ (ì‹ ë¢°êµ¬ê°„ ë„ˆë¹„)ì— ë”°ë¥¸ í‘œë³¸ í¬ê¸° ì¶”ì •
* ë³´ì • ë° íŒë³„ë ¥ ëª©í‘œë¥¼ ê°€ì§„ ì™¸ë¶€ ê²€ì¦ ì„¤ê³„

**ë‹¤ìŒ ê²½ìš°ì—ëŠ” ì£¼ìš” ë„êµ¬ë¡œ ì´ ì•±ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”:**
* ë¬´ì‘ìœ„ ëŒ€ì¡° ì‹œí—˜ (RCT) ì„¤ê³„ (RCT ì „ìš© ê²€ì •ë ¥/í‘œë³¸ í¬ê¸° ë°©ë²• ì‚¬ìš©)
* ì˜ˆì¸¡ ëª¨ë¸ë§ ì—†ì´ ë¯¼ê°ë„/íŠ¹ì´ë„ì— ëŒ€í•œ ì§„ë‹¨ ì •í™•ë„ ì—°êµ¬ ê³„íš
* ë‹¨ì¼ "ì •í™•í•œ" ìˆ«ìë¥¼ ê¸°ëŒ€í•˜ëŠ” ê²½ìš°: í‘œë³¸ í¬ê¸° ê³„íšì€ ê°€ì •ì— ì˜ì¡´í•˜ë©° ë¯¼ê°ë„ ë¶„ì„ì„ í¬í•¨í•´ì•¼ í•¨

---

### ì´ìš© ê°€ëŠ¥í•œ ë°©ë²• (ê°œìš”)

#### A. ë¹ ë¥¸ / ê¸°ë³¸ (ì‹ ì†, ê·¼ì‚¬)

**A1 â€” ê²½í—˜ì  ê·œì¹™ (EPV/EPP) (íœ´ë¦¬ìŠ¤í‹±)**
* **ì‚¬ìš© ì‹œì :** ê³„íšëœ ëª¨ë¸ í¬ê¸°ì— ëŒ€í•´ ì‚¬ê±´ ìˆ˜ê°€ "ëŒ€ëµ ì¶©ë¶„í•œì§€" ë¹ ë¥´ê²Œ í™•ì¸í•  ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** ëª¨ë¸ì— ìŠ¤í”Œë¼ì¸/ìƒí˜¸ì‘ìš©/ë³€ìˆ˜ ì„ íƒì´ í¬í•¨ë˜ê±°ë‚˜ ì‚¬ê±´ ë°œìƒë¥ ì´ ë‚®ì€ ê²½ìš°â€”EPV/EPPëŠ” ì¢‹ì€ ë³´ì • ë˜ëŠ” ë‚®ì€ ë‚™ê´€ì£¼ì˜ë¥¼ ë³´ì¥í•˜ì§€ ì•ŠìŒ.
* **ì£¼ìš” ì…ë ¥:** ì‚¬ê±´ ë°œìƒë¥  $p$, íŒŒë¼ë¯¸í„° ìˆ˜ $P$ (df), ëª©í‘œ EPP (ì˜ˆ: 10/15/20)
* **í•µì‹¬ ì¶œë ¥:** í•„ìš” ì‚¬ê±´ ìˆ˜ $E=t \\cdot P$, í•„ìš” í‘œë³¸ í¬ê¸° $N=\\lceil E/p \\rceil$
* **ì¥ì :** ë§¤ìš° ê°„ë‹¨í•¨; ì´ˆê¸° íƒ€ë‹¹ì„± ê²€í† ì— ì í•©
* **ë‹¨ì :** ì˜¤í•´ì˜ ì†Œì§€ê°€ ìˆìŒ; ì„±ëŠ¥ ê¸°ë°˜ì´ ì•„ë‹˜

**A2 â€” ê¸°ì¤€ ìœ„í—˜ ì •ë°€ë„ (ìœ ë³‘ë¥ ì— ëŒ€í•œ CI ë„ˆë¹„)**
* **ì‚¬ìš© ì‹œì :** ëª©í‘œê°€ ì›í•˜ëŠ” CI ë°˜í­ (ì˜ˆ: Â±2%)ìœ¼ë¡œ ì‚¬ê±´ ë°œìƒë¥  $p$ë¥¼ ì¶”ì •í•˜ëŠ” ê²ƒì¼ ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ ë³´ì¥ (AUC/ë³´ì • ê¸°ìš¸ê¸°)ì„ ì›í•  ë•Œ.
* **ì£¼ìš” ì…ë ¥:** ì˜ˆìƒ $p$, CI ë°©ë²• (Wilson ê¶Œì¥), ì‹ ë¢° ìˆ˜ì¤€, ëª©í‘œ ë°˜í­ $d$
* **í•µì‹¬ ì¶œë ¥:** CI ë°˜í­ $\\le d$ë¥¼ ì¶©ì¡±í•˜ëŠ” ìµœì†Œ $N$
* **ì¥ì :** ì§ì ‘ì ì¸ ì •ë°€ë„ ëª©í‘œ; íˆ¬ëª…í•œ ê°€ì •
* **ë‹¨ì :** ìœ ë³‘ë¥ ì—ë§Œ í•´ë‹¹, ëª¨ë¸ ì„±ëŠ¥ì€ ì•„ë‹˜

#### B. ì˜ˆí›„ ì¸ì (ê²€ì •ë ¥) (ì—°ê´€ì„± ì¤‘ì‹¬, ì˜ˆì¸¡ ëª¨ë¸ í¬ê¸° ê²°ì • ì•„ë‹˜)

**B3 â€” ë¡œì§€ìŠ¤í‹± OR ê²€ì •ë ¥ (Hsieh)**
* **ì‚¬ìš© ì‹œì :** ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œ ì˜ˆí›„ ì¸ìì— ëŒ€í•œ ëª©í‘œ ì˜¤ì¦ˆë¹„ (OR) ê²€ì¶œ ê²€ì •ë ¥ì´ í•„ìš”í•  ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** ì£¼ìš” ëª©í‘œê°€ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ (ë³´ì •/íŒë³„ë ¥)ì¼ ë•Œ, ê°€ì„¤ ê²€ì •ì´ ì•„ë‹ ë•Œ.
* **ì£¼ìš” ì…ë ¥:** ê¸°ì¤€ ìœ„í—˜ $p_0$, ëª©í‘œ OR, ì•ŒíŒŒ, ê²€ì •ë ¥, ë…¸ì¶œ ìœ ë³‘ë¥  (ì´ë¶„í˜•) ë˜ëŠ” SD (ì—°ì†í˜•), ì„ íƒì  ê³µë³€ëŸ‰ê³¼ì˜ $R^2$
* **í•µì‹¬ ì¶œë ¥:** OR ê²€ì¶œì— í•„ìš”í•œ $N$ (ë° ì•”ì‹œëœ ì‚¬ê±´ ìˆ˜)
* **ì¥ì :** ì—°ê´€ì„±ì— ëŒ€í•œ ê³ ì „ì  ê²€ì •ë ¥ í”„ë ˆì„ì›Œí¬
* **ë‹¨ì :** ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥ì„ ë‹¤ë£¨ì§€ ì•ŠìŒ; ì…ë ¥ ê°€ì •ì— ë¯¼ê°

**B4 â€” Cox HR ê²€ì •ë ¥ (Schoenfeld)**
* **ì‚¬ìš© ì‹œì :** ìƒì¡´ ì‹œê°„ ê²°ê³¼; Cox ë¹„ë¡€ìœ„í—˜ í•˜ì—ì„œ ìœ„í—˜ë¹„ (HR) ê²€ì¶œ ê²€ì •ë ¥ì´ í•„ìš”í•  ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** ë¹„ë¡€ìœ„í—˜ ê°€ì •ì´ ìœ„ë°˜ë  ê°€ëŠ¥ì„±ì´ ë†’ê±°ë‚˜, ì‚¬ê±´ ë¶„ìœ¨ì´ ë§¤ìš° ë¶ˆí™•ì‹¤í•˜ì—¬ í•©ë¦¬ì ìœ¼ë¡œ ì¶”ì •í•  ìˆ˜ ì—†ì„ ë•Œ.
* **ì£¼ìš” ì…ë ¥:** HR, ì•ŒíŒŒ, ê²€ì •ë ¥, ë°°ë¶„ ë¹„ìœ¨ (ì´ë¶„í˜•) ë˜ëŠ” SD (ì—°ì†í˜•), ì¶”ì  ê¸°ê°„ ë™ì•ˆ ì˜ˆìƒ ì‚¬ê±´ ë¶„ìœ¨
* **í•µì‹¬ ì¶œë ¥:** í•„ìš” ì‚¬ê±´ ìˆ˜; ì‚¬ê±´ ë¶„ìœ¨ì„ ì‚¬ìš©í•˜ì—¬ $N$ìœ¼ë¡œ ë³€í™˜
* **ì¥ì :** ë„ë¦¬ ì¸ì •ë¨; ì‚¬ê±´ ê¸°ë°˜ ê³„íšì´ ì§ê´€ì 
* **ë‹¨ì :** ì‚¬ê±´ ë¶„ìœ¨ ë° ì¶”ì /ì¤‘ë„ì ˆë‹¨ ê°€ì •ì— ê°•í•˜ê²Œ ì˜ì¡´

#### C. ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ (ìœ„í—˜ ëª¨ë¸ êµ¬ì¶•ì— ê¶Œì¥)

**C5 â€” Riley ë“± (ë¶„ì„ì ; pmsampsize ìœ ì‚¬)**
* **ì‚¬ìš© ì‹œì :** ë‹¤ë³€ëŸ‰ ì˜ˆì¸¡ ëª¨ë¸ ê°œë°œ; ê³¼ì í•© ì œì–´ ë° ì ì ˆí•œ ì •ë°€ë„ ë³´ì¥ì´ í•„ìš”í•  ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** ìœ ë³‘ë¥  ë° ì˜ˆìƒ ëª¨ë¸ ì„±ëŠ¥ (AUC ë˜ëŠ” $R^2$)ì— ëŒ€í•œ í•©ë¦¬ì ì¸ ê°€ì •ì„ ì œê³µí•  ìˆ˜ ì—†ì„ ë•Œ; ì´ ê²½ìš° ë¯¼ê°ë„ ë¶„ì„ ë˜ëŠ” ì‹œë®¬ë ˆì´ì…˜ ì‚¬ìš©.
* **ì£¼ìš” ì…ë ¥:** ì‚¬ê±´ ë°œìƒë¥  $p$, íŒŒë¼ë¯¸í„° $P$ (df), ëª©í‘œ ìˆ˜ì¶• (ì˜ˆ: 0.90), ì˜ˆìƒ ëª¨ë¸ ì„±ëŠ¥ (AUC ë˜ëŠ” Coxâ€“Snell $R^2$)
* **í•µì‹¬ ì¶œë ¥:** ì—¬ëŸ¬ ê¸°ì¤€ ì¶©ì¡± ìµœì†Œ $N$ (ê³¼ì í•© ì œì–´ + ì •ë°€ë„)
* **ì¥ì :** ì›ì¹™ì— ê¸°ë°˜, ì„±ëŠ¥ ì¸ì‹, ë„ë¦¬ ì¸ìš©ë¨
* **ë‹¨ì :** ì„±ëŠ¥ ê°€ì •ì— ì˜ì¡´; ì‹ ì¤‘í•œ ììœ ë„ ê³„ì‚° í•„ìš”

**C6 â€” ê°œë°œ ì‹œë®¬ë ˆì´ì…˜ (ë¹ˆë„ì£¼ì˜; samplesizedev/ì‚¬ìš©ì ì •ì˜ DGM)**
* **ì‚¬ìš© ì‹œì :** "ìˆ˜í–‰í•  ê²ƒì„ ì‹œë®¬ë ˆì´ì…˜"í•˜ëŠ” ê²ƒì„ ì„ í˜¸, íŠ¹íˆ ë¹„ì„ í˜•ì„±/ìƒí˜¸ì‘ìš© ë° ì‚¬ìš©ì ì •ì˜ ë°ì´í„° êµ¬ì¡°ê°€ ìˆì„ ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** ê·¸ëŸ´ë“¯í•œ ë°ì´í„° ìƒì„± ë©”ì»¤ë‹ˆì¦˜ì„ ì§€ì •í•  ìˆ˜ ì—†ê±°ë‚˜ ì¦‰ê°ì ì¸ ê²°ê³¼ê°€ í•„ìš”í•  ë•Œ.
* **ì£¼ìš” ì…ë ¥:** í›„ë³´ $N$ ê·¸ë¦¬ë“œ, DGM ê°€ì •, ì„±ëŠ¥ ëª©í‘œ (ì˜ˆ: ë³´ì • ê¸°ìš¸ê¸° ë²”ìœ„, AUC ì„ê³„ê°’), ì‹œë®¬ë ˆì´ì…˜ ë°˜ë³µ, ì‹œë“œ
* **í•µì‹¬ ì¶œë ¥:** í—ˆìš© ê°€ëŠ¥í•œ í™•ë¥ /ì •ë°€ë„ë¡œ ëª©í‘œ ë‹¬ì„±í•˜ëŠ” ìµœì†Œ $N$
* **ì¥ì :** ìœ ì—°í•¨; ë³µì¡í•œ ëª¨ë¸ë§ê³¼ ì¼ì¹˜
* **ë‹¨ì :** ê°€ì •ì— í¬ê²Œ ì˜ì¡´; ê³„ì‚° ë¹„ìš©

**C7 â€” ë² ì´ì§€ì•ˆ ë³´ì¦ (MCMC)**
* **ì‚¬ìš© ì‹œì :** ìµœì¢… ëª¨ë¸ì´ ë² ì´ì§€ì•ˆ MCMCë¡œ ì¶”ì •ë˜ê³ , ë³´ì¦ ê¸°ë°˜ í‘œë³¸ í¬ê¸°ê°€ í•„ìš”í•  ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** ì‚¬ì „ë¶„í¬ë¥¼ ì •ë‹¹í™”í•  ìˆ˜ ì—†ê±°ë‚˜ ê³„ì‚° ì˜ˆì‚°ì´ ì œí•œì ì¼ ë•Œ.
* **ì£¼ìš” ì…ë ¥:** DGM, ì‚¬ì „ë¶„í¬, í›„ë³´ $N$, MCMC ì„¤ì •, ë³´ì¦ ì„ê³„ê°’ (ì˜ˆ: 80%/90%), ì„±ëŠ¥/ì •ë°€ë„ ëª©í‘œ
* **í•µì‹¬ ì¶œë ¥:** ë³´ì¦ ì„ê³„ê°’ ì¶©ì¡± ìµœì†Œ $N$
* **ì¥ì :** ë² ì´ì§€ì•ˆ ì›Œí¬í”Œë¡œìš°ì™€ ì¼ê´€ë¨; ì‚¬í›„ ê¸°ì¤€ ì§ì ‘ ëª©í‘œ
* **ë‹¨ì :** ê³„ì‚° ì§‘ì•½ì ; ì‚¬ì „ë¶„í¬ ì‚¬ì–‘ í•„ìš”

#### D. ê²€ì¦ / ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ëª¨ë¸ìš©)

**D8 â€” AUC ì •ë°€ë„ (Hanleyâ€“McNeil / presize)**
* **ì‚¬ìš© ì‹œì :** ê²€ì¦ ëª©í‘œê°€ AUCì˜ ì •ë°€ë„ (CI ë„ˆë¹„)ì¼ ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** ë³´ì • (ê¸°ìš¸ê¸°/CITL)ì´ ì£¼ìš” ê´€ì‹¬ì‚¬ì¼ ë•Œâ€”ì´ ë°©ë²•ì€ AUCë§Œ ëª©í‘œ.
* **ì£¼ìš” ì…ë ¥:** ì˜ˆìƒ AUC, ìœ ë³‘ë¥  ë˜ëŠ” í™˜ì-ëŒ€ì¡°êµ° ë¹„ìœ¨, ì‹ ë¢° ìˆ˜ì¤€, ëª©í‘œ CI ë„ˆë¹„
* **í•µì‹¬ ì¶œë ¥:** ì›í•˜ëŠ” AUC CI ë„ˆë¹„ ë‹¬ì„±ì„ ìœ„í•œ ìµœì†Œ $N$
* **ì¥ì :** ê°„ë‹¨í•¨; íŒë³„ë ¥ ì •ë°€ë„ì— ëŒ€í•œ ë¹ ë¥¸ ê³„íš
* **ë‹¨ì :** ê·¼ì‚¬ ë¶„ì‚°; ë³´ì • ë¬´ì‹œ

**D9 â€” ì™¸ë¶€ ê²€ì¦ (ë§ì¶¤í˜•; pmvalsampsize / sampsizeval)**
* **ì‚¬ìš© ì‹œì :** ì—¬ëŸ¬ ì„±ëŠ¥ ì¸¡ì •ì„ ëª©í‘œë¡œ í•˜ëŠ” ê²€ì¦ í¬ê¸° ê²°ì •, ì¢…ì¢… LP ë¶„í¬ ê°€ì • í•„ìš”.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** LP ë¶„í¬ ê°€ì •ì„ ì •ë‹¹í™”í•  ìˆ˜ ì—†ì„ ë•Œ.
* **ì£¼ìš” ì…ë ¥:** ìœ ë³‘ë¥ , ì˜ˆìƒ AUC, ë³´ì • ê¸°ìš¸ê¸°/CITL ëª©í‘œ, CI ë„ˆë¹„ ë˜ëŠ” SE ëª©í‘œ, LP ë¶„í¬ ê°€ì •
* **í•µì‹¬ ì¶œë ¥:** ì—¬ëŸ¬ ì¸¡ì •ì— ëŒ€í•œ ì •ë°€ë„ ê¸°ì¤€ ì¶©ì¡± ê¶Œì¥ $N$
* **ì¥ì :** ë§ì¶¤í˜•; ë³´ì • ì¸ì‹
* **ë‹¨ì :** ì¶”ê°€ ê°€ì • í•„ìš”; ë” ë³µì¡í•¨

**D10 â€” ì™¸ë¶€ ê²€ì¦ (ì‹œë®¬ë ˆì´ì…˜; LP ê¸°ë°˜)**
* **ì‚¬ìš© ì‹œì :** ëª©í‘œ ê²€ì¦ ì§‘ë‹¨ì—ì„œ LP ë¶„í¬ë¥¼ ì§€ì •/ì¶”ì •í•  ìˆ˜ ìˆê³  ì‹œë®¬ë ˆì´ì…˜ ê¸°ë°˜ ì •ë°€ë„ ê³„íšì„ ì›í•  ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** LP ë¶„í¬ê°€ ì•Œë ¤ì§€ì§€ ì•Šê³  ê·¼ì‚¬í•  ìˆ˜ ì—†ì„ ë•Œ.
* **ì£¼ìš” ì…ë ¥:** LP ë¶„í¬ (ì •ê·œ/ë² íƒ€/ê²½í—˜ì ), ì˜¤ë³´ì • íŒŒë¼ë¯¸í„°, ì¸¡ì •ê°’ì— ëŒ€í•œ CI ë„ˆë¹„ ëª©í‘œ, ë°˜ë³µ, ì‹œë“œ
* **í•µì‹¬ ì¶œë ¥:** ì‹œë®¬ë ˆì´ì…˜ í•˜ì— ì •ë°€ë„ ëª©í‘œ ë‹¬ì„± ìµœì†Œ $N$
* **ì¥ì :** ë§¤ìš° ìœ ì—°í•¨; "ì˜ˆìƒí•˜ëŠ” ê²ƒì„ ì‹œë®¬ë ˆì´ì…˜"ê³¼ ì¼ì¹˜
* **ë‹¨ì :** ê°€ì •ì— í¬ê²Œ ì˜ì¡´; ê³„ì‚° ë¹„ìš©

**D11 â€” ì—…ë°ì´íŠ¸ / ì¬ë³´ì • (ì ˆí¸/ê¸°ìš¸ê¸°)**
* **ì‚¬ìš© ì‹œì :** ê¸°ì¡´ ëª¨ë¸ì„ ì¬ë³´ì •í•˜ê³  ì ì ˆí•œ ì •ë°€ë„ê°€ í•„ìš”í•  ë•Œ.
* **ì‚¬ìš©í•˜ì§€ ë§ì•„ì•¼ í•  ê²½ìš°:** ì™„ì „íˆ ìƒˆë¡œìš´ ëª¨ë¸ì„ ê°œë°œí•  ë•Œ (C5â€“C7 ì‚¬ìš©).
* **ì£¼ìš” ì…ë ¥:** ì—…ë°ì´íŠ¸ ìœ í˜•, ì‚¬ê±´ ë°œìƒë¥ , ì •ë°€ë„ ëª©í‘œ
* **í•µì‹¬ ì¶œë ¥:** ì•ˆì •ì ì¸ ì—…ë°ì´íŠ¸ì— ì¶©ë¶„í•œ $N$
* **ì¥ì :** ì‹¤ì œ ë°°í¬ì— ì‹¤ìš©ì 
* **ë‹¨ì :** ì§€ì—­ ì¼€ì´ìŠ¤ ë¯¹ìŠ¤ ë° ëª¨ë¸ ì´ë™ì„± ê°€ì •ì— ì˜ì¡´

---

#### ë©´ì±… ì¡°í•­

ì„ìƒì  ë³´ì¦ ì—†ìŒ; ì‚¬ìš©ìëŠ” ê²€ì¦ ë° í•´ì„ì— ì±…ì„ì´ ìˆìŠµë‹ˆë‹¤. í•­ìƒ ê°€ì •ì„ ë¬¸ì„œí™”í•˜ê³  ë¯¼ê°ë„ ë¶„ì„ì„ ìˆ˜í–‰í•˜ì„¸ìš”.

#### ì—°ë½ì²˜

ì €ì ë° ìœ ì§€ê´€ë¦¬: Minh Nguyen (minhnt@ump.edu.vn)
""",

        "a2_content_md": """
### ì´ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ

ì´ ëª¨ë“ˆì€ **ì›í•˜ëŠ” ì •ë°€ë„**(ì‹ ë¢° êµ¬ê°„(CI) ë°˜í­ ë˜ëŠ” ì˜¤ì°¨ í•œê³„ë¡œ í‘œí˜„ë¨)ë¡œ **ê¸°ë³¸ ìœ„í—˜ / ì‚¬ê±´ ë°œìƒë¥ **(p)(ì¦‰, ê²°ê³¼ì˜ ìœ ë³‘ë¥ )ì„ ì¶”ì •í•˜ëŠ” ë° í•„ìš”í•œ **ìµœì†Œ í‘œë³¸ í¬ê¸°(n)**ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤.

ë‹¤ìŒê³¼ ê°™ì€ ê²½ìš°ì— ìœ ìš©í•©ë‹ˆë‹¤:
* ì§€ì •ëœ ì •ë°€ë„ë¡œ ì½”í˜¸íŠ¸ ë‚´ ê²°ê³¼ ìœ ë³‘ë¥  ì„¤ëª…,
* íƒ€ë‹¹ì„± ê³„íš ë° ê¸°ë³¸ ìœ„í—˜ ë³´ê³ ,
* êµì • ê´€ë ¨ ê³„íš ì§€ì› (ì˜ˆ: calibration-in-the-largeëŠ” ì‚¬ê±´ ë°œìƒë¥ ì— ì˜ì¡´).

**ì¤‘ìš”í•œ ì œí•œ ì‚¬í•­:** ì´ ê³„ì‚°ì€ ì˜ˆì¸¡ ëª¨ë¸ ì„±ëŠ¥(AUC, êµì • ê¸°ìš¸ê¸°, ë‚™ê´€ì£¼ì˜)ì„ **ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤**. ì˜¤ì§ (p) ì¶”ì •ì˜ ì •ë°€ë„ë§Œì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

---

### ì…ë ¥ ê°’ (ì˜ë¯¸)

1. **ê²°ê³¼ ìœ ë³‘ë¥  / ì‚¬ê±´ ë°œìƒë¥ ** (p)
   ëŒ€ìƒ ëª¨ì§‘ë‹¨ì—ì„œ ì˜ˆìƒë˜ëŠ” ì‚¬ê±´ ë¹„ìœ¨ (ì˜ˆ: 0.10).
   * ì•Œ ìˆ˜ ì—†ëŠ” ê²½ìš°, íƒ€ë‹¹í•œ ë²”ìœ„ë¥¼ ê³ ë ¤í•˜ì—¬ ë¯¼ê°ë„ ë¶„ì„ì„ ì‹¤í–‰í•˜ì‹­ì‹œì˜¤.
   * ìœ ë³‘ë¥  ì •ë°€ë„ì— ëŒ€í•´ ë³´ìˆ˜ì ì¸ "ìµœì•…ì˜ ê²½ìš°"ë¥¼ ì›í•œë‹¤ë©´ (p=0.50)ì„ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤ (ë¶„ì‚° ìµœëŒ€í™”).

2. **ëª©í‘œ ë°˜í­ (ì˜¤ì°¨ í•œê³„)** (d)
   CIê°€ ëŒ€ëµ ë‹¤ìŒê³¼ ê°™ë„ë¡ í•˜ëŠ” ì›í•˜ëŠ” ì •ë°€ë„:
   $p \pm d$
   ì˜ˆ: (d = 0.01, 0.02, 0.03) (ì¦‰, Â±1%, Â±2%, Â±3%).

3. **ì‹ ë¢° ìˆ˜ì¤€** (1-$\\alpha$)
   ì¼ë°˜ì ì¸ ê°’: 0.95 ë˜ëŠ” 0.99.

4. **CI ë°©ë²•**
* **Wilson score (ê¶Œì¥):** Waldë³´ë‹¤ ì»¤ë²„ë¦¬ì§€ê°€ ì¢‹ìœ¼ë©°, íŠ¹íˆ (p)ê°€ 0ì´ë‚˜ 1ì— ê°€ê¹ê±°ë‚˜ í‘œë³¸ í¬ê¸°ê°€ ì ë‹¹í•  ë•Œ ì¢‹ìŠµë‹ˆë‹¤.
* **Wald (ì •ê·œ ê·¼ì‚¬):** ê°„ë‹¨í•œ íì‡„í˜•ì´ì§€ë§Œ (n)ì´ ì‘ê±°ë‚˜ (p)ê°€ ê·¹ë‹¨ì ì¼ ë•Œ ì„±ëŠ¥ì´ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
* **Clopperâ€“Pearson (ì •í™•):** ë³´ìˆ˜ì ì…ë‹ˆë‹¤ (ì¢…ì¢… ë” ë„“ì€ CIë¥¼ ì‚°ì¶œí•˜ë¯€ë¡œ ë” í° (n)ì´ í•„ìš”í•¨).

---

### í•µì‹¬ ê³„ì‚° (ì›ë¦¬)

$X \sim \\text{Binomial}(n,p)$, $\hat p = X/n$ì´ë¼ê³  í•©ì‹œë‹¤. ëª©í‘œëŠ” ì„ íƒí•œ CI ë°©ë²•ì´ ë‹¤ìŒì„ ì‚°ì¶œí•˜ë„ë¡ í•˜ëŠ” ê°€ì¥ ì‘ì€ (n)ì„ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤:
$$
\\frac{\\text{Upper}(n) - \\text{Lower}(n)}{2} \le d
$$

#### A) Wald (íì‡„í˜• ê·¼ì‚¬)
$$ n \\approx \\frac{z^2 p(1-p)}{d^2} $$
**ì°¸ê³ :** ë¹ ë¥´ì§€ë§Œ (n)ì´ ì‘ê±°ë‚˜ (p)ê°€ ê·¹ë‹¨ì ì¼ ë•ŒëŠ” ê¶Œì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

#### B) Wilson score êµ¬ê°„ (ê¶Œì¥)
Wilson score êµ¬ê°„ ê³µì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

#### C) Clopperâ€“Pearson â€œì •í™•â€ êµ¬ê°„
Beta ë¶„ìœ„ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ë³´ìˆ˜ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤.

---

### ì‹¤ìš©ì ì¸ ê¸°ë³¸ê°’

* **ì‹ ë¢° ìˆ˜ì¤€:** 95%ê°€ í‘œì¤€ì…ë‹ˆë‹¤.
* **ë°˜í­ (d):** Â±0.01 ~ Â±0.03 (1%â€“3%)ì´ ì¼ë°˜ì ì¸ ëª©í‘œì…ë‹ˆë‹¤.
* **ë°©ë²•:** Wilsonì´ ê°•ë ¥í•œ ê¸°ë³¸ê°’ì…ë‹ˆë‹¤.

### ì£¼ìš” ì°¸ê³  ë¬¸í—Œ
1. **Wilson EB.** Probable inference... *JASA.* 1927.
2. **Newcombe RG.** Two-sided confidence intervals... *Stat Med.* 1998.
""",

        "b3_content_md": """
### Purpose (what this method is)

This module estimates the **minimum sample size** needed to detect an association between a predictor (X) and a **binary outcome** (Y) using **logistic regression**, targeting a specified **odds ratio (OR)**, **two-sided ($\\alpha$)**, and **power**.

This is a **prognostic factor / association-focused** power calculation (testing a regression coefficient), **not** a prediction-model performance method. It does **not** guarantee good calibration or discrimination of a multivariable prediction model.

---

### When to use

Use B3 when:

* You want power to detect a **clinically meaningful OR** for a **single predictor** (binary or continuous) in logistic regression.
* Your primary goal is **hypothesis testing** (is the predictor associated with the outcome?), not building a risk prediction model.

### When NOT to use

Do not use B3 as your main approach when:

* Your goal is **prediction model development** (use Riley/pmsampsize or simulation/assurance methods).
* You plan **data-driven variable selection**, many interactions/splines, or complex machine-learning tuning (power for a single coefficient is not the right target).
* Data are **clustered** (multicenter/ward-level correlation) or strongly dependent without adjusting the design effect.
* You have a **caseâ€“control** design with fixed case/control sampling (baseline risks ($p_0$) may not represent the source population).

---

## Statistical model and parameters

Logistic regression model:
$$
\\text{logit}{P(Y=1\\mid X)}=\\beta_0+\\beta_1 X
$$

* For **binary** ($X\\in\\{0,1\\}$):
  $$
  \\mathrm{OR}=\\exp(\\beta_1)
  $$
* For **continuous** ($X$): OR must be defined for a specific change in ($X$), commonly **1 SD increase**.

Hypothesis test:
$$
H_0:\\beta_1=0 \\quad \\text{vs}\\quad H_1:\\beta_1\\neq 0
$$

---

## Inputs (what each value means)

1. **Alpha (two-sided)** ($\\alpha$)
   Common choices: 0.05 (standard), 0.01 (more stringent).

2. **Power** ($1-\\beta$)
   Common choices: 0.80 (standard), 0.90 (more conservative).

3. **Baseline event rate** ($p_0$)

   * For **binary predictor**: ($p_0 = P(Y=1\\mid X=0)$) (event rate in the reference group).
   * For **continuous predictor**: ($p_0$) is typically interpreted as the event rate at the **mean** of ($X$) (after centering).

4. **Target odds ratio** ($\\mathrm{OR}$)
   The smallest OR that is clinically meaningful and worth detecting.

5. **Predictor type**

* **Binary predictor**: requires **prevalence of (X=1)**, denoted ($q=P(X=1)$).
* **Continuous predictor**: typically requires the OR for a **1 SD increase** (or you must convert using SD).

6. **($R^2$) with other covariates**
   ($R^2$) is the squared multiple correlation from regressing ($X$) on other covariates in a multivariable model.

   * If ($X$) is correlated with other predictors, the effective information about ($\\beta_1$) decreases, so the required sample size increases.

---

# Calculation

## Step 1 â€” Convert OR and baseline risk to ($p_1$) (binary ($X$))

If ($X$) is binary, compute the event rate in the exposed group ($p_1=P(Y=1\\mid X=1)$) from ($p_0$) and OR:

$$
\\text{odds}_0=\\frac{p_0}{1-p_0},\\quad \\text{odds}_1=\\mathrm{OR}\\cdot \\text{odds}_0,\\quad
p_1=\\frac{\\text{odds}_1}{1+\\text{odds}_1}
$$

Overall event rate:
$$
p=(1-q)p_0+q p_1
$$

## Step 2 â€” Z-scores

Let:
$$
z_{\\alpha}=z_{1-\\alpha/2}, \\qquad z_{\\beta}=z_{1-\\beta}=z_{\\text{power}}
$$

## A) Binary predictor sample size (Hsieh approach)

With ($q=P(X=1)$), ($p_0=P(Y=1\\mid X=0)$), ($p_1=P(Y=1\\mid X=1)$), and ($p$) as above:

$$
n_0=
\\frac{
\\left[
z_{\\alpha}\\sqrt{\\frac{p(1-p)}{q(1-q)}}
+
z_{\\beta}\\sqrt{\\frac{p_1(1-p_1)}{q}+\\frac{p_0(1-p_0)}{1-q}}
\\right]^2
}
{(p_1-p_0)^2}
$$

### Adjustment for correlation with other covariates

If you plan a multivariable model and the predictor of interest ($X$) correlates with other covariates, inflate the sample size using:

$$
n=\\frac{n_0}{1-R^2}
$$

### Expected number of events

$$
E \\approx n\\cdot p
$$

---

## B) Continuous predictor sample size (Hsieh approach)

Assume a logistic model with a continuous predictor ($X$) and define OR for a **1 SD increase** in ($X$), denoted ($\\mathrm{OR}_{SD}$). Let ($p_0$) be the event rate at the mean of ($X$):

$$
n_0=\\frac{(z_{\\alpha}+z_{\\beta})^2}{p_0(1-p_0) [\\log(\\mathrm{OR}_{SD})]^2}
$$

If the user has an OR per 1-unit increase, ($\\mathrm{OR}_{unit}$), and SD of ($X$) is ($\\sigma_X$), convert:
$$
\\log(\\mathrm{OR}_{SD})=\\log(\\mathrm{OR}_{unit})\\cdot \\sigma_X
$$

Then apply the same multivariable correlation inflation:
$$
n=\\frac{n_0}{1-R^2}
$$

---

## Practical guidance: what values to choose (common conventions)

* **($\\alpha$)**: 0.05 (two-sided) is typical; use smaller ($\\alpha$) if multiple testing is expected.
* **Power**: 0.80 is common; 0.90 is preferred when missing the effect would be costly.
* **OR**: choose the **minimum clinically meaningful** OR (often in the 1.2â€“2.0 range depending on context).
* **Baseline risk ($p_0$)**: use local hospital/cohort data if available; otherwise use literature estimates and run sensitivity analyses.
* **Binary predictor prevalence ($q$)**: use local prevalence; note ($q$) near 0.5 gives the **largest information** (smaller ($n$)); very small/large ($q$) increases required ($n$).
* **($R^2$)**: if uncertain, run a sensitivity range (e.g., 0, 0.1, 0.25, 0.5). Even moderate correlation can inflate ($n$) substantially via ($1/(1-R^2)$).
* **Continuous predictors**: consider standardizing ($X$) to mean 0, SD 1 so ($\\mathrm{OR}_{SD}$) is easy to interpret.

---

## Key references (2â€“5)

1. Hsieh FY, Bloch DA, Larsen MD. *A simple method of sample size calculation for linear and logistic regression.* Statistics in Medicine. 1998;17(14):1623â€“1634.
2. Hsieh FY. *Sample size tables for logistic regression.* Statistics in Medicine. 1989;8(7):795â€“802.
3. Whittemore AS. *Sample size for logistic regression with small response probability.* Journal of the American Statistical Association. 1981;76:27â€“32.
""",
        "c5_content_md": """
### What this method is

C5 implements the **Riley et al. analytical minimum sample size criteria** for **developing a multivariable clinical prediction model** with a **binary outcome** (logistic regression). The goal is to ensure the development dataset is large enough to:

1. **Limit overfitting** (via a target global shrinkage / calibration slope),
2. Achieve **adequate precision** for model performance (via a bound on optimism in $R^2$), and
3. Estimate the **overall outcome risk** (intercept/baseline risk) with acceptable precision.

This is a **model development** method (not external validation). It is particularly suitable when you plan a **pre-specified model form** (predictors and coding defined in advance) and want a **principled alternative to EPV rules**.

---

### When to use

Use C5 when:

* You are **developing** a new prediction model for a **binary outcome**.
* You can specify (even approximately) the **event rate** and an anticipated **overall model performance** (Coxâ€“Snell $R^2$ or AUC).
* You want to target **low overfitting** (e.g., shrinkage $S \\ge 0.90$) and reasonable precision.

### When NOT to use (or use with caution)

Do not rely on C5 alone when:

* You will do extensive **data-driven variable selection**, multiple interactions/splines, or heavy ML tuning without adjusting the **effective number of parameters (df)**.
* Your data are strongly **clustered** (multicenter) without accounting for design effects.
* The intended modeling approach is not standard logistic regression (e.g., complex ML) unless you map complexity to an appropriate **effective df** or switch to simulation-based sizing.
* You cannot justify any plausible performance input (AUC/$R^2$); in that case run wide sensitivity analyses and consider simulation-based methods.

---

## Key inputs (what each means)

1. **Outcome prevalence / event rate** (p)
   Expected proportion with (Y=1) in the development dataset.

2. **Number of predictor parameters (df)** (P)
   Total degrees of freedom for all candidate predictors **excluding the intercept**.
   Include: dummy variables, spline bases, interactions (and any other basis expansions).

3. **Anticipated performance** (choose one)

* **Coxâ€“Snell ($R^2_{CS}$)**: preferred if available from related prior studies (ideally optimism-adjusted).
* **AUC (C-statistic)**: if $R^2_{CS}$ is unavailable, the tool can approximate $R^2_{CS}$ from AUC and ($p$) using a published approach.
* **Conservative (15% of max $R^2$)**: a fallback when neither AUC nor $R^2$ is available; use with caution.

4. **Target global shrinkage** (S)
   A target for **overall overfitting control** (often interpreted similarly to an expected calibration slope after internal validation).

* Common default: $S = 0.90$ ($\\approx$ 10% shrinkage of predictor effects).
* More conservative: $S = 0.95$ (requires larger sample size).

---

## Core concepts and formulas

### Coxâ€“Snell ($R^2$) and its maximum

Coxâ€“Snell ($R^2$) for a fitted logistic model can be written as:
$$
R^2_{CS} = 1-\\exp\\left(\\frac{2}{n}(\\ell_0-\\ell_1)\\right),
$$
where $\\ell_0$ is the intercept-only log-likelihood and $\\ell_1$ is the model log-likelihood.

For binary outcomes, $R^2_{CS}$ cannot reach 1. Its maximum depends on the outcome prevalence:
$$
\\ell_0 = n\\Big[p\\ln(p) + (1-p)\\ln(1-p)\\Big],
$$
$$
R^2_{CS,\\max}=1-\\exp\\left(\\frac{2\\ell_0}{n}\\right)
=1-\\exp\\Big(2[p\\ln(p) + (1-p)\\ln(1-p)]\\Big).
$$

Nagelkerke ($R^2$) rescales Coxâ€“Snell ($R^2$) to ([0,1]):
$$
R^2_{Nag}=\\frac{R^2_{CS}}{R^2_{CS,\\max}}.
$$

---

## The three Riley criteria (binary outcome)

### Criterion 1 â€” Control overfitting via target shrinkage (S)

Minimum sample size to target global shrinkage (S):
$$
n_1=\\left\\lceil
\\frac{P}{(S-1)\\ln\\left(1-\\frac{R^2_{CS}}{S}\\right)}
\\right\\rceil.
$$

### Criterion 2 â€” Limit optimism in ($R^2$) (default absolute difference 0.05)

This criterion targets a small absolute difference (default $\\delta=0.05$) between apparent and adjusted **Nagelkerke** ($R^2$). The required shrinkage implied by this constraint is:
$$
S_{\\delta}=\\frac{R^2_{CS}}{R^2_{CS}+\\delta R^2_{CS,\\max}}.
$$
Then:
$$
n_2=\\left\\lceil
\\frac{P}{(S_{\\delta}-1)\\ln\\left(1-\\frac{R^2_{CS}}{S_{\\delta}}\\right)}
\\right\\rceil.
$$

### Criterion 3 â€” Precise estimation of the overall outcome risk (intercept)

This targets precision of the **average outcome risk** ($p$) (baseline risk) within ($\\pm d$) on the probability scale (default $d=0.05$ at 95% CI):
$$
n_3=\\left\\lceil
\\left(\\frac{z_{1-\\alpha/2}}{d}\\right)^2 p(1-p)
\\right\\rceil,
\\quad \\text{default } z_{0.975}=1.96,; d=0.05.
$$

### Final recommendation

$$
n_{\\min}=\\max(n_1,n_2,n_3),\\qquad
E = n_{\\min}p,\\qquad
EPP=\\frac{E}{P}.
$$

---

## Practical guidance (typical choices)

* **Shrinkage (S)**: use **0.90** as a standard target; consider **0.95** if you want stronger overfitting control or if the model is complex.
* **$\\delta=0.05$** for Criterion 2: commonly kept at the default.
* **Intercept precision (d=0.05)**: default corresponds to estimating baseline risk within Â±5%. If baseline risk must be estimated more precisely, you would need a smaller ($d$) (larger ($n$)).
* **Anticipated ($R^2_{CS}$)**:

  * Prefer **optimism-adjusted** values from related studies (or apparent values from external validation data).
  * If only AUC is available, use the published AUCâ†’$R^2_{CS}$ approximation method.
  * If neither is available, the **15% of $R^2_{CS,\\max}$** option is a conservative fallback for exploratory planningâ€”always run sensitivity analyses.

---

## Key references (2â€“5)

1. Riley RD, Snell KIE, Ensor J, et al. *Minimum sample size required for developing a multivariable prediction model: PART IIâ€”binary and time-to-event outcomes.* Statistics in Medicine. 2019.
2. Riley RD, Ensor J, Snell KIE, et al. *Calculating the sample size required for developing a clinical prediction model.* BMJ. 2020.
3. Riley RD, Van Calster B, Collins GS. *A note on estimating the Coxâ€“Snell ($R^2$) from a reported C statistic (AUROC) to inform sample size calculations for developing a prediction model with a binary outcome.* Statistics in Medicine. 2021.
4. Harrell FE Jr, Lee KL, Mark DB. *Multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors.* Statistics in Medicine. 1996.
""",
        "c6_content_md": """
## C6: Development Simulation (Frequentist; custom DGM)

### What this method is

C6 is a **simulation-based sample size planning** approach for **prediction model development** (binary outcome), inspired by the philosophy of **samplesizedev** and broader simulation-based design principles.

Instead of relying on a single analytical formula, C6 asks:

> â€œIf we repeatedly develop the model using the planned approach on datasets of size (N), how often will the model meet pre-specified performance criteria on new data?â€

It therefore targets **expected performance** (and/or probability of acceptable performance) under a **data-generating mechanism (DGM)** that represents your anticipated clinical population.

---

## When to use

Use C6 when:

* You want a planning method aligned with â€œ**simulate what you will do**,â€ especially when:

  * predictors may be correlated,
  * you include non-linear terms or interactions,
  * event rates are modest or uncertain,
  * you want criteria based on **calibration** and **discrimination**.
* You can specify a reasonable DGM using local data or the literature.
* You are comfortable with simulation and want a more flexible alternative to purely analytical sizing.

## When NOT to use (or use with caution)

Avoid relying on C6 alone when:

* You cannot justify a plausible DGM (predictor distribution, correlations, effect sizes).
* You do not have computational budget (simulation can be expensive).
* You plan highly data-adaptive ML pipelines (feature selection, complex tuning) without explicitly simulating the full pipeline (C6 must reflect the actual pipeline to be valid).
* The target population is heterogeneous across hospitals/centers and you are not simulating clustering/case-mix shifts.

---

# Overview of the algorithm

For each candidate sample size (N), simulate (R) development datasets, fit the planned model, evaluate it on â€œnew data,â€ and summarize performance.

### Step 1 â€” Choose a DGM

Define how predictors (X) and outcomes (Y) are generated.

Typical binary-outcome DGM:
[
Y \mid X \sim \\text{Bernoulli}(\\pi), \\qquad
\\pi = \\text{logit}^{-1}(\\eta),
]
[
\\eta = \\beta_0 + \\sum_{j=1}^{P}\\beta_j f_j(X_j),
]
where:

* (P) is the **number of parameters/df** used in the fitted model,
* (f_j(\\cdot)) represent coding choices (linear term, spline basis, dummy coding, etc.).

To achieve a target event rate (p), choose (\\beta_0) so that:
[
\\mathbb{E}[\\pi] = p.
]
In practice, (\\beta_0) is found by numerical root-finding using Monte Carlo draws from (X).

### Step 2 â€” Generate a development dataset

For replicate (r):

* Simulate (X^{(r)}) of size (N) from the chosen predictor distribution (with specified correlations).
* Simulate (Y^{(r)}) from the Bernoulli model above.

### Step 3 â€” Fit the development model

Fit the planned logistic regression model:
[
\\widehat{\\eta} = \\widehat{\\beta}*0 + \\sum*{j=1}^{P}\\widehat{\\beta}_j f_j(X_j).
]
**Important:** Simulation must match your intended development strategy (e.g., penalization, pre-specified terms). If separation/non-convergence occurs, a ridge-penalized fallback is often used (and should be counted and reported).

### Step 4 â€” Evaluate on new data

Generate an independent test set (size (N_{\\text{test}}), often large such as 5000â€“10000) from the same DGM and compute:

**(a) Discrimination (AUC / C-statistic)**
[
\\mathrm{AUC}=\\Pr(\\widehat{\\eta}_1 > \\widehat{\\eta}_0),
]
the probability that a randomly selected case has a higher predicted risk than a non-case.

**(b) Calibration slope**
Estimate (b) from a calibration model on the test set:
[
\\text{logit}(Y) = a + b \\cdot \\text{logit}(\\widehat{p}),
]
or equivalently using the linear predictor:
[
\\text{logit}(Y) = a + b \\cdot \\widehat{\\eta}.
]
Here, (b\\approx 1) indicates good calibration; (b<1) suggests overfitting (predictions too extreme).

### Step 5 â€” Define pass/fail criteria and compute success rates

Across (R) simulations for each (N), compute:

* Mean calibration slope:
  [
  \\overline{b} = \\frac{1}{R}\\sum_{r=1}^R b^{(r)}.
  ]
* Probability slope is within an acceptable range:
  [
  \\widehat{\\Pr}(b \\in [L,U]) = \\frac{1}{R}\\sum_{r=1}^R \\mathbf{1}{b^{(r)}\\in[L,U]}.
  ]
* Mean AUC:
  [
  \\overline{\\mathrm{AUC}}=\\frac{1}{R}\\sum_{r=1}^R \\mathrm{AUC}^{(r)}.
  ]

A candidate (N) is â€œacceptableâ€ if all selected criteria are met, e.g.:

* (\\overline{b} \\ge 0.90)
* (\\widehat{\\Pr}(0.9 \\le b \\le 1.1) \\ge 0.80)
* (\\overline{\\mathrm{AUC}} \\ge \\mathrm{AUC}_{\\text{target}})

Choose the **smallest** (N) that passes.

---

# Inputs in the app (where to find them, typical values)

### 1) Outcome prevalence / event rate (p)

**What it is:** expected proportion of events in the development cohort.
**Where to get it:** local hospital incidence/prevalence (best), registry data, or prior studies in similar settings.
**Typical planning ranges:** 5%â€“15% are common in many clinical contexts (but vary widely).
**Tip:** If uncertain, run **sensitivity analysis** over a plausible range.

### 2) Number of predictor parameters (df) (P)

**What it is:** total degrees of freedom (excluding intercept), including:

* categorical dummies,
* spline bases,
* interactions,
* any additional engineered terms.
  **Where to get it:** your *final* planned model specification (TRIPOD-style pre-specification).
  **Typical values:** 10â€“30 df are common; higher requires stronger evidence and larger samples.

### 3) Target mean AUC (Mode A)

**What it is:** expected discrimination on new data (optimism-adjusted).
**Where to get it:** prior models in similar populations, pilot data, or published AUCs (prefer externally validated AUC).
**Typical values:** 0.70â€“0.85 are common; >0.90 is unusual and often optimistic.

### 4) Candidate sample sizes (N)

Provide a grid (e.g., 1000, 1500, 2000, 3000, 5000).
**Tip:** include a smaller and larger value to ensure the pass/fail threshold is crossed.

### 5) Number of simulations per (N): (R)

**Interpretation:** Monte Carlo replications.

* Demo: (R \\approx 200) (fast, higher Monte Carlo error)
* Final: (R \\ge 1000) (more stable)
  Monte Carlo standard error for a pass probability (\\hat{p}) is:
  [
  \\mathrm{MCSE}=\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{R}}.
  ]
  Example: if (\\hat{p}=0.8) and (R=200), MCSE â‰ˆ 0.028.

### 6) Performance criteria (Pass/Fail)

* **Mean calibration slope â‰¥ 0.9**
  (typical overfitting control threshold)
* **Pr(0.9 â‰¤ slope â‰¤ 1.1) â‰¥ 80%**
  (typical â€œacceptable calibrationâ€ probability threshold)
* **Mean AUC â‰¥ target**
  (discrimination target)

**Where to get thresholds:** practice guidelines, prior studies, and what is clinically acceptable.
**Common conventions:** slope range 0.90â€“1.10 and assurance 0.80 are frequently used for planning; use 0.90 assurance for higher certainty.

---

# Strengths and weaknesses

**Strengths**

* Flexible: accommodates correlations, non-linear terms, and realistic modeling choices.
* Directly targets new-data performance and calibration behavior.
* Naturally supports sensitivity analyses.

**Weaknesses**

* Results depend on DGM assumptions (garbage in â†’ garbage out).
* Computationally intensive.
* Must simulate the full intended modeling pipeline; otherwise results can be misleading.

---

## Key references (2â€“5)

1. Pavlou M, Ambler G, Seaman SR, et al. *How to develop a more accurate risk prediction model when there are few events.* BMJ. 2015.
2. Riley RD, Snell KIE, Ensor J, et al. *Minimum sample size required for developing a multivariable prediction model: Part IIâ€”binary and time-to-event outcomes.* Statistics in Medicine. 2019.
3. Pavlou M, et al. *Methodology and software for simulation-based sample size calculation in prediction modeling* (sampsize development/related work). Statistics in Medicine. 2021.
4. Steyerberg EW. *Clinical Prediction Models: A Practical Approach to Development, Validation, and Updating.* 2nd ed. Springer. 2019.
""",
    "c7_content_md": """
## C7: Bayesian Assurance (MCMC)

### What this method is
**Bayesian assurance** is a simulation-based approach to sample size planning for **Bayesian model development** (here: Bayesian logistic regression for a binary outcome).  
Instead of targeting "power" (frequentist), assurance targets the **unconditional probability** that your study will meet **pre-specified success criteria** (e.g., calibration and discrimination thresholds, and/or posterior precision).

In plain terms:
> "If we repeat the whole study many times (data generation + Bayesian MCMC fitting), what is the probability that the fitted model will be good enough?"

---

### When to use
Use C7 when:
- Your final analysis is **Bayesian** and will be estimated by **MCMC**.
- You want sample size chosen to achieve **a target probability of success** (e.g., â‰¥80% or â‰¥90%).
- You can specify reasonable assumptions for:
  - event rate in your hospital cohort,
  - predictor correlation structure and distributions,
  - plausible effect sizes (from local pilot data or literature),
  - priors for regression coefficients.

### When NOT to use (or use with caution)
Avoid relying on C7 alone when:
- You cannot justify priors or a plausible **data-generating mechanism (DGM)**.
- You do not have the compute budget (MCMC is slow; results can be sensitive to MCMC settings).
- Your real development pipeline includes substantial data-adaptive steps (feature selection, heavy tuning) that you are **not** simulating.
- Data are clustered/multicenter but the DGM ignores clustering (may underestimate required N).

---

## Core model and DGM

### Bayesian logistic regression (analysis model)
\[
Y_i \sim \\text{Bernoulli}(\\pi_i), \\qquad
\\text{logit}(\\pi_i)=\\beta_0 + \\sum_{j=1}^{P}\\beta_j f_j(X_{ij})
\]
- \(P\) = number of predictor parameters (degrees of freedom; **exclude intercept**).
- \(f_j(\\cdot)\) represents your coding choices (linear term, dummies, spline bases, interactions).

**Example priors (typical weakly informative defaults):**
\[
\\beta_j \sim \\mathcal{N}(0,\\sigma_\\beta^2),\\quad \\sigma_\\beta \\in [1, 2.5],
\\qquad \\beta_0 \sim \\mathcal{N}(0, 5^2)
\]
(Your app may use fixed priors; users should run sensitivity analyses over plausible priors.)

### DGM for predictors (example equicorrelation)
If the app uses a single correlation parameter \\(\\rho\\) (equicorrelation):
\[
\\mathrm{Corr}(X_j, X_k)=\\rho \\quad (j\\neq k),
\\qquad
\\Sigma_{jk}=
\\begin{cases}
1,& j=k\\\\
\\rho,& j\\neq k
\\end{cases}
\]
Predictors are then generated from a correlated mechanism (e.g., Gaussian copula / multivariate normal core), and transformed into continuous/binary predictors as needed.

### Setting the event rate
The intercept (or a calibration constant) is chosen so that the marginal event rate matches the target prevalence:
\[
\\mathbb{E}[\\pi_i]=p
\]
This is typically solved numerically using Monte Carlo draws of \(X\).

---

## What "assurance" means (key formula)
Let:
- \\(\\theta\\) denote the "true" parameters under the DGM (effect sizes, correlation structure, etc.).
- \\(y\\) denote the observed dataset of size \\(N\\).
- \\(S(y)\\) be a **success indicator** that equals 1 if performance/precision criteria are met.

**Assurance at sample size \\(N\\):**
\[
\\mathcal{A}(N)=\\Pr(\\text{Success at }N)
=\\mathbb{E}_{\\theta}\\left[\\mathbb{E}_{y\\mid \\theta,N}\\left\\{S(y)\\right\\}\\right]
\]

**Monte Carlo estimate used in the app (for each candidate \\(N\\)):**
\[
\\widehat{\\mathcal{A}}(N)=\\frac{1}{R}\\sum_{r=1}^{R} S\\!\\left(y^{(r)}\right)
\]
where each replicate \\(r\\) simulates a dataset, fits the Bayesian model with MCMC, and evaluates success criteria.

Monte Carlo standard error (helpful for interpreting stability):
\[
\\mathrm{MCSE}\\left(\\widehat{\\mathcal{A}}(N)\\right)
=\\sqrt{\\frac{\\widehat{\\mathcal{A}}(N)\\left[1-\\widehat{\\mathcal{A}}(N)\\right]}{R}}
\]

**Decision rule:**
Choose the smallest \\(N\\) such that:
\[
\\widehat{\\mathcal{A}}(N)\\ge \\mathcal{A}_\\text{target}
\]
(e.g., 0.80 or 0.90).

---

## Success criteria (typical examples)
Your app may implement one or more of the following (user-selectable):
- **Calibration slope** in an acceptable range:
  \[
  0.90 \le b \le 1.10
  \]
  where \\(b\\) is estimated from a calibration model on validation/test data:
  \[
  \\text{logit}(Y)=a + b\\cdot \\text{logit}(\\widehat{p})
  \]
- **Discrimination** threshold:
  \[
  \\mathrm{AUC} \\ge 0.75 \\;(\\text{or your chosen target})
  \]
- **Posterior precision** target, e.g. 95% credible interval width for calibration slope:
  \[
  \\mathrm{Width}\\left(\\text{CrI}_{95\\%}(b)\\right) \\le w
  \\quad (\\text{e.g., } w=0.20)
  \]

---

## Input guide (where to find values; typical choices)

### 1) Outcome prevalence (event rate) \\(p\\)
**Where to get it:** local hospital cohort/registry; recent retrospective data.  
**Typical planning ranges:** 0.05â€“0.15 are common in many clinical settings, but use your disease context.  
**Tip:** If uncertain, run a sensitivity analysis over a plausible range.

### 2) Number of predictor parameters (df) \\(P\\)
**Where to get it:** your finalized model specification (count **parameters**, not variables).  
Include dummies, spline bases, interactions. Exclude intercept.  
**Typical range:** 10â€“30 df is common; larger df demands much larger \\(N\\) and stronger prior justification.

### 3) Predictor correlation \\(\\rho\\)
**Where to get it:** estimate from pilot/hospital data (correlation matrix of candidate predictors).  
If unknown, use sensitivity analysis (e.g., \\(\\rho=0, 0.1, 0.3\\)).  
**Typical:** mild-to-moderate correlations (0â€“0.3) are common; higher correlations increase instability and may increase required \\(N\\).

### 4) Candidate sample sizes \\(N\\)
Choose a grid wide enough to cross the pass/fail boundary (e.g., 500, 1000, 1500, 2000, â€¦).  
Start from feasibility constraints (available charts/records) and expand upward.

### 5) Number of simulations per \\(N\\) (replicates) \\(R\\)
- **Demo:** 50â€“200 (fast; higher MC error)  
- **Final planning:** â‰¥500â€“1000 (more stable assurance estimate)  
Use MCSE to judge stability.

### 6) Assurance threshold \\(\\mathcal{A}_\\text{target}\\)
- **0.80**: common for feasibility-driven planning  
- **0.90**: preferred when you want higher confidence in meeting criteria

---

## Strengths and weaknesses
**Strengths**
- Fully aligned with Bayesian workflows; directly targets **posterior** success/precision.
- Flexible: accommodates complex DGM, correlations, and performance-based criteria.
- Can incorporate prior knowledge and realistically handle rare events with regularizing priors.

**Weaknesses**
- Computationally intensive; results can depend on MCMC settings and convergence.
- Sensitive to DGM and prior assumptions â†’ requires sensitivity analyses.
- Must simulate the actual planned pipeline to avoid under/over-estimation.

---

## Key references (2â€“5)
1) O'Hagan A. Assurance in clinical trial design. *Pharmaceutical Statistics.* 2005.  
2) Pan J, Banerjee S. bayesassurance: An R Package for Calculating Sample Size and Bayesian Assurance. *The R Journal.* 2023.  
3) Gelman A, Jakulin A, Pittau MG, Su Y-S. A weakly informative default prior distribution for logistic and other regression models. *The Annals of Applied Statistics.* 2008.  
4) Sahu SK, Smith TMF. Bayesian methods of sample size determination. *Statistical Methodology / related Bayesian SSD literature.* 2006.
""",
}
