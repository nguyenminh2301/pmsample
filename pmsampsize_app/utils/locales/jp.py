
JP = {
    "title": "äºˆå¾Œç ”ç©¶ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãƒ„ãƒ¼ãƒ« (Prognostic Research Sample Size Tool)",
    "sidebar_title": "è¨­å®š (Configuration)",
    "language": "è¨€èª / Language",
    "mode": "æ‰‹æ³•ã®é¸æŠ (Method Selection)",
    "mode_riley": "æ‰‹æ³• C5: Riley ç­‰ (è§£æçš„)",
    "mode_bayes": "æ‰‹æ³• C6: ãƒ™ã‚¤ã‚ºä¸»å° (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)",
    "mode_single": "å˜ä¸€ã‚·ãƒŠãƒªã‚ª (Single Scenario)",
    "mode_batch": "æ„Ÿåº¦åˆ†æ (Sensitivity Analysis)",
    "method1_tab": "æ‰‹æ³• C5 (Riley)",
    "method2_tab": "æ‰‹æ³• C6 (Bayesian)",
    "nav_title": "ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³ (Navigation)",
    "nav_readme": "è©³ç´°ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ (README)",
    "nav_intro": "æ¦‚è¦ã¨æ•°å¼ (Introduction & Formulas)",
    "nav_calc": "ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—æ©Ÿ (Calculator)",
    "intro_heading": "ã‚ˆã†ã“ã (Welcome)",
    "intro_text": "ã“ã®ãƒ„ãƒ¼ãƒ«ã¯ã€äºŒå€¤ã‚¢ã‚¦ãƒˆã‚«ãƒ ã®è‡¨åºŠäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã«å¿…è¦ãªæœ€å°ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ã€‚",
    "formula_heading": "æ•°å­¦çš„æ çµ„ã¿ (æ‰‹æ³• C5)",
    "formula_intro": "æ‰‹æ³• C5 ã¯ Riley ç­‰ã«ã‚ˆã‚‹è§£æè§£ã‚’ä½¿ç”¨ã—ã€æ‰‹æ³• C6 ã¯ãƒ™ã‚¤ã‚º MCMC ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚",
    "sens_guide_title": "ğŸ’¡ æ„Ÿåº¦åˆ†æã®ä½¿ã„æ–¹ (ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰)",
    "sens_guide_text": """
    - **ç¯„å›²**: `min-max` ã‚’å…¥åŠ› (ä¾‹: `0.05-0.10`)ã€‚ã‚¹ãƒ†ãƒƒãƒ—ã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã™ã€‚
    - **ç‰¹å®šã®å€¤**: ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã®ãƒªã‚¹ãƒˆã‚’å…¥åŠ› (ä¾‹: `0.05, 0.10, 0.15`)ã€‚
    """,
    "detail_view": "ã‚·ãƒŠãƒªã‚ªã®è©³ç´°è¨ˆç®—ã‚’è¡¨ç¤º",
    "footer_refs": "å‚è€ƒæ–‡çŒ®: Riley et al. (2018, 2020), BayesAssurance.",
    "calc_btn": "è¨ˆç®— (Calculate)",
    "results": "çµæœ (Results)",
    "sanity": "å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ (Sanity Check - EPV Rules)",
    "download_csv": "CSV ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    "download_report": "å®Œå…¨ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
    "error_p": "æœ‰ç—…ç‡ã¯ 0 ã¨ 1 ã®é–“ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚",
    "error_auc": "AUC ã¯ 0.5 ã¨ 1 ã®é–“ã§ãªã‘ã‚Œã°ãªã‚Šã¾ã›ã‚“ã€‚",
    "error_parse": "å…¥åŠ›ã‚’è§£æã§ãã¾ã›ã‚“ã§ã—ãŸã€‚",
    
    # Riley specific
    "riley_inputs": "å…¥åŠ›ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (Riley)",
    "prevalence": "ã‚¢ã‚¦ãƒˆã‚«ãƒ æœ‰ç—…ç‡ / ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç‡ (Outcome Prevalence / Event Rate)",
    "prevalence_help": "ã‚¤ãƒ™ãƒ³ãƒˆãŒç™ºç”Ÿã™ã‚‹å‚åŠ è€…ã®å‰²åˆ (0 < p < 1)ã€‚",
    "parameters": "äºˆæ¸¬ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° (Number of Predictor Parameters/df)",
    "parameters_help": "ç·è‡ªç”±åº¦ (åˆ‡ç‰‡ã‚’é™¤ã)ã€‚",
    "shrinkage": "ç›®æ¨™ã‚°ãƒ­ãƒ¼ãƒãƒ«åç¸®ç‡ (Target Global Shrinkage, S)",
    "shrinkage_help": "å¸Œæœ›ã™ã‚‹åç¸®ä¿‚æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ 0.9)ã€‚",
    "perf_measure": "äºˆæƒ³ã•ã‚Œã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ (Anticipated Performance)",
    "perf_auc": "AUC (Cçµ±è¨ˆé‡)",
    "perf_r2": "Cox-Snell RäºŒä¹—",
    "perf_cons": "ä¿å®ˆçš„ (æœ€å¤§ R2 ã® 15%)",
    
    # Bayesian specific 
    "perf_cons_help": "ä¿å®ˆçš„ (æœ€å¤§ R2 ã® 15%)",
    "perf_auc_help": "äºˆæƒ³ã•ã‚Œã‚‹ AUC (Cçµ±è¨ˆé‡)",
    "perf_r2_help": "äºˆæƒ³ã•ã‚Œã‚‹ Cox-Snell RäºŒä¹—",
    
    # Bayesian specific
    "bayes_inputs": "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š (ãƒ™ã‚¤ã‚ºä¿è¨¼)",
    "dgm_settings": "ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¡ã‚«ãƒ‹ã‚ºãƒ  (Data Generating Mechanism)",
    "sim_settings": "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ MCMC (Simulation & MCMC)",
    "eval_settings": "è©•ä¾¡åŸºæº– (Evaluation Criteria)",
    "n_candidates": "å€™è£œã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)",
    "n_candidates_help": "ãƒ†ã‚¹ãƒˆã™ã‚‹ N ã®ãƒªã‚¹ãƒˆã€‚ä¾‹: 500, 1000, 1500ã€‚",
    "correlation": "äºˆæ¸¬å› å­ã®ç›¸é–¢ (rho)",
    "n_sims": "N ã”ã¨ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å›æ•°",
    "assurance_threshold": "ä¿è¨¼ã—ãã„å€¤ (ç›®æ¨™ç¢ºç‡, Assurance Threshold)",
    "run_simulation": "ãƒ™ã‚¤ã‚ºã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ",
    "simulation_running": "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œä¸­... æ™‚é–“ãŒã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ã€‚",
    "assurance_result": "ä¿è¨¼åˆ†æ (Assurance Analysis)",
    
    # Method 6 (Dev Sim)
    "mode_dev_sim": "æ‰‹æ³• 6: é–‹ç™ºã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (é »åº¦è«–)",
    "method6_tab": "æ‰‹æ³• 6 (Simulation)",
    "dev_sim_intro": "ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«åŸºã¥ããƒ¢ãƒ‡ãƒ«é–‹ç™ºã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®— (é »åº¦è«–çš„æ‰‹æ³•, `samplesizedev` ã«é¡ä¼¼)ã€‚",
    "dev_mode_simple": "ãƒ¢ãƒ¼ãƒ‰ A: ã‚·ãƒ³ãƒ—ãƒ« (AUC é§†å‹•)",
    "dev_mode_custom": "ãƒ¢ãƒ¼ãƒ‰ B: ã‚«ã‚¹ã‚¿ãƒ  DGM",
    "target_auc": "ç›®æ¨™å¹³å‡ AUC (Cçµ±è¨ˆé‡)",
    "target_auc_help": "ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¯ã“ã® AUC ã‚’é”æˆã™ã‚‹ãŸã‚ã® Beta ä¿‚æ•°ã‚’æ¤œç´¢ã—ã¾ã™ã€‚",
    "criteria_settings": "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŸºæº– (åˆæ ¼/ä¸åˆæ ¼)",
    "crit_slope_mean": "å¹³å‡ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹¾é… (Calibration Slope) >= 0.9",
    "crit_slope_ci": "Pr(0.9 <= Slope <= 1.1) >= 80%",
    "crit_auc": "å¹³å‡ AUC >= ç›®æ¨™å€¤",
    "audit_trail": "RNG ç›£æŸ»è¨¼è·¡ (JSON)",
    "future_methods": "ä»Šå¾Œã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã§å…¬é–‹äºˆå®š...",
    
    # Quick Methods
    "method_quick_tab": "A. ã‚¯ã‚¤ãƒƒã‚¯ / åŸºæœ¬ (Quick / Basic)",
    "quick_mode_epv": "A1: EPV / EPP ãƒ«ãƒ¼ãƒ« (ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯)",
    "quick_mode_risk": "A2: ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒªã‚¹ã‚¯ç²¾åº¦ (CI å¹…)",
    "target_epv": "ç›®æ¨™ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚ãŸã‚Šã‚¤ãƒ™ãƒ³ãƒˆæ•° (EPP)",
    "target_epv_help": "ä¸€èˆ¬çš„ãªãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯å€¤ã¯ 10, 15, 20 ã§ã™ã€‚EPV ã‚ˆã‚Šã‚‚ EPP ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚",
    "epv_warning_title": "âš ï¸ é‡è¦ãªè­¦å‘Š",
    "epv_warning_text": "EPV/EPP ã¯å˜ãªã‚‹å¤§ã¾ã‹ãªãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒ«ãƒ¼ãƒ«ã§ã™ã€‚ã“ã‚Œã¯ã€è‰¯å¥½ãªã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„è­˜åˆ¥èƒ½ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ãªãã€æ¥½è¦³çš„ãƒã‚¤ã‚¢ã‚¹ã‚’é˜²ãã‚‚ã®ã§ã‚‚ã‚ã‚Šã¾ã›ã‚“ã€‚å¤‰æ•°é¸æŠã‚„éç·šå½¢é …ã«å¯¾ã—ã¦æ•æ„Ÿã§ã™ã€‚",
    "ci_level": "ä¿¡é ¼æ°´æº– (Confidence Level)",
    "ci_half_width": "ç›®æ¨™åŠå€¤å¹… (è¨±å®¹èª¤å·®, Margin of Error)",
    "ci_method": "CI æ‰‹æ³•",
    "ci_method_wilson": "Wilson Score (æ¨å¥¨)",
    "ci_method_wald": "Wald (å˜ç´”)",
    "ci_method_cp": "Clopper-Pearson (ä¿å®ˆçš„)",
    "risk_help": "ç‰¹å®šã®ç²¾åº¦ã§ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç‡ p ã‚’æ¨å®šã™ã‚‹ãŸã‚ã«å¿…è¦ãª N ã‚’è¨ˆç®—ã—ã¾ã™ã€‚äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¯ä¿è¨¼ã—ã¾ã›ã‚“ã€‚",
    
    # Power Methods (B)
    "title_b3": "B3: Logistic æ¤œå‡ºåŠ› (Hsieh)",
    "title_b4": "B4: Cox æ¤œå‡ºåŠ› (Schoenfeld)",
    "interpretation": "è§£é‡ˆ (Interpretation)",
    
    # UI Basics
    "d8_assumptions": "**ä»®å®š**: Hanley & McNeil (1982) ã®åˆ†æ•£è¿‘ä¼¼ã‚’ä½¿ç”¨ã€‚AUC ã®å¯¾ç§°æ­£è¦æ€§ã‚’ä»®å®šã€‚N ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®æ•°å€¤æœ€é©åŒ–ã€‚",
    "d8_mode_n_to_width": "N ã‹ã‚‰ CI å¹…ã‚’è¨ˆç®—",
    "d8_mode_width_to_n": "CI å¹…ã‹ã‚‰å¿…è¦ãª N ã‚’è¨ˆç®—",
    "d8_opt_settings": "é«˜åº¦ãªã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶è¨­å®š",
    "d8_practical_rounding": "å®Ÿéš›ã®ä¸¸ã‚ã‚’è¡¨ç¤º",
    "d8_n_input": "ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º (N)",
    "d8_width_input": "CI å¹… (åˆè¨ˆ)",
    "d8_opt_bound": "æ¤œç´¢ä¸Šé™",
    "d8_opt_tol": "è¨±å®¹èª¤å·®",
    
    # Validations (D)
    "title_d8": "D8: AUC ç²¾åº¦ (Hanley-McNeil)",
    "d8_desc": "AUC ã‚’æ‰€æœ›ã®ç²¾åº¦ (CI å¹…) ã§æ¨å®šã™ã‚‹ãŸã‚ã®ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã—ã¾ã™ã€‚",
    "auc_expected": "äºˆæƒ³ã•ã‚Œã‚‹ AUC (Cçµ±è¨ˆé‡)",
    "formulas_header": "ğŸ“š æ•°å¼ã¨æŠ€è¡“è©³ç´° (Formulas & Technical Details)",
    "d8_assumptions": "**ä»®å®š**: Hanley & McNeil (1982) ã®åˆ†æ•£è¿‘ä¼¼ã‚’ä½¿ç”¨ã€‚AUC ã®å¯¾ç§°æ­£è¦æ€§ã‚’ä»®å®šã€‚N ã‚’è¦‹ã¤ã‘ã‚‹ãŸã‚ã®æ•°å€¤æœ€é©åŒ–ã€‚",
    "d8_mode_n_to_width": "N ã‹ã‚‰ CI å¹…ã‚’è¨ˆç®—",
    "d8_mode_width_to_n": "CI å¹…ã‹ã‚‰ N ã‚’è¨ˆç®—",
    "d8_opt_settings": "é«˜åº¦ãªã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶è¨­å®š",
    "d8_practical_rounding": "å®Ÿéš›ã®ä¸¸ã‚ã‚’è¡¨ç¤º",
    "d8_n_input": "ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º (N)",
    "d8_width_input": "CI å¹… (åˆè¨ˆ)",
    "d8_opt_bound": "æ¤œç´¢ä¸Šé™",
    "d8_opt_tol": "è¨±å®¹èª¤å·®",
    
    # D9
    "title_d9": "D9: å¤–éƒ¨æ¤œè¨¼ (Tailored)",
    "common_inputs": "å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿",
    
    # UI Basics
    "search_placeholder": "æ‰‹æ³•ã‚’æ¤œç´¢...",
    "settings": "è¨­å®š (Settings)",
    
    # Footer
    "footer_copyright": "Â© 2026 äºˆå¾Œç ”ç©¶ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºãƒ„ãƒ¼ãƒ«ã€‚å­¦è¡“/ç ”ç©¶åˆ©ç”¨ã®ã¿ã€‚",
    "footer_author": "ä½œæˆè€…ã¨ç®¡ç†è€…: Minh Nguyen (minhnt@ump.edu.vn) - Dept. of Epidemiology, Faculty of Public Health, UMP Ho Chi Minh City",
    "footer_disclaimer": "å…è²¬äº‹é …: è‡¨åºŠçš„ãªä¿è¨¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ¤œè¨¼ã¨è§£é‡ˆã«è²¬ä»»ã‚’è² ã„ã¾ã™ã€‚",

    "intro_complete_md": """
### ã‚ˆã†ã“ã (Welcome)

ã“ã®ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€è‡¨åºŠåŒ»ã‚„ç ”ç©¶è€…ãŒä»¥ä¸‹ã‚’å«ã‚€äºˆå¾Œç ”ç©¶ã®æœ€å°ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’è¨ˆç”»ã™ã‚‹ã®ã«å½¹ç«‹ã¡ã¾ã™ï¼š
* äºˆå¾Œå› å­ç ”ç©¶ (é–¢é€£æ€§ã®æ¤œå‡ºåŠ›)ã€
* è‡¨åºŠäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º (ãƒªã‚¹ã‚¯äºˆæ¸¬)ã€ãŠã‚ˆã³
* ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ / æ›´æ–° (å¤–éƒ¨æ¤œè¨¼ã€å†ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³)ã€‚

ã“ã‚Œã¯äºŒå€¤ã‚¢ã‚¦ãƒˆã‚«ãƒ  (ä¾‹ï¼šã‚¤ãƒ™ãƒ³ãƒˆ vs ã‚¤ãƒ™ãƒ³ãƒˆãªã—) ç”¨ã«è¨­è¨ˆã•ã‚Œã¦ãŠã‚Šã€ä¸€éƒ¨ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¯ç”Ÿå­˜æ™‚é–“ã‚¢ã‚¦ãƒˆã‚«ãƒ  (Cox PH) ã«ã‚‚é©å¿œã—ã¾ã™ã€‚

ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ (ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰): [https://gitlab.com/minhthiennguyen/pmsample/](https://gitlab.com/minhthiennguyen/pmsample/)
ã¾ãŸã¯ [https://github.com/nguyenminh2301/pmsample.git](https://github.com/nguyenminh2301/pmsample.git)    

### ã¯ã˜ã‚ã« (æ–°è¦ãƒ¦ãƒ¼ã‚¶ãƒ¼)

#### 1. ç ”ç©¶ã®ç›®çš„ã‚’æ˜ç¢ºã«ã™ã‚‹
* å˜ä¸€ã®äºˆå¾Œå› å­ (é–¢é€£æ€§) ã‚’ãƒ†ã‚¹ãƒˆã—ã¦ã„ã¾ã™ã‹ï¼Ÿ
* äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ
* æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’æ–°ã—ã„é›†å›£ã§æ¤œè¨¼ã—ã¦ã„ã¾ã™ã‹ï¼Ÿ

#### 2. ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç‡ $p$ (ã¾ãŸã¯ç”Ÿå­˜åˆ†æã®ã‚¤ãƒ™ãƒ³ãƒˆå‰²åˆ) ã‚’æ¨å®šã™ã‚‹
* åœ°å…ƒã®ç—…é™¢ã®ãƒ‡ãƒ¼ã‚¿ãŒæœ›ã¾ã—ã„ã§ã™ (ãƒ™ã‚¹ãƒˆ)ã€‚
* ä¸ç¢ºã‹ãªå ´åˆã¯ã€ç¯„å›²ã‚’å…¥åŠ›ã—ã¦æ„Ÿåº¦åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

#### 3. ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã• (ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ / è‡ªç”±åº¦) ã‚’æ­£ã—ãæ•°ãˆã‚‹
å˜ãªã‚‹ã€Œå¤‰æ•°ã®æ•°ã€ã§ã¯ãªãã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ (è‡ªç”±åº¦) ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
* äºŒå€¤äºˆæ¸¬å­: 1 df
* $L$ ãƒ¬ãƒ™ãƒ«ã®ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°: $L-1$ df
* ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³ ($K$ ãƒãƒƒãƒˆã® RCS): $K-1$ df
* äº¤äº’ä½œç”¨: $df(A \\times B) = df(A) \\cdot df(B)$

#### 4. ä¸‹è¨˜ã®ã‚«ã‚¿ãƒ­ã‚°ã‹ã‚‰æ‰‹æ³•ã‚’é¸æŠã™ã‚‹
* **"ã‚¯ã‚¤ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«" (Quick tools)** ã¯å¤§ã¾ã‹ãªè¨ˆç”»ã«ã®ã¿ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
* äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã«ã¯ **Riley / ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ / ä¿è¨¼ (Assurance)** æ‰‹æ³•ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚

---

### ã“ã®ã‚¢ãƒ—ãƒªã‚’ä½¿ç”¨ã™ã‚‹å ´é¢ (ãŠã‚ˆã³ä½¿ç”¨ã—ãªã„å ´é¢)

**ä»¥ä¸‹ã®å ´åˆã«ä½¿ç”¨ã—ã¦ãã ã•ã„:**
* äºˆå¾Œ/äºˆæ¸¬ã«é–¢ã™ã‚‹å¾Œã‚å‘ãã¾ãŸã¯å‰å‘ãã‚³ãƒ›ãƒ¼ãƒˆç ”ç©¶ã‚’è¨ˆç”»ã™ã‚‹å ´åˆ
* ãƒªã‚¹ã‚¯äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™ºã¾ãŸã¯æ¤œè¨¼
* æœ‰ç—…ç‡ã¾ãŸã¯ AUC ã®ç²¾åº¦ (CI å¹…) ã«åŸºã¥ãã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã®æ¨å®š
* ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨è­˜åˆ¥èƒ½ã®ç›®æ¨™ã‚’æŒã¤å¤–éƒ¨æ¤œè¨¼ã®è¨­è¨ˆ

**ä»¥ä¸‹ã®å ´åˆã€ã“ã®ã‚¢ãƒ—ãƒªã‚’ä¸»è¦ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„:**
* ãƒ©ãƒ³ãƒ€ãƒ åŒ–æ¯”è¼ƒè©¦é¨“ã®è¨­è¨ˆ (RCT å›ºæœ‰ã®æ¤œå‡ºåŠ›/ã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºæ‰‹æ³•ã‚’ä½¿ç”¨)
* äºˆæ¸¬ãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã‚’ä¼´ã‚ãªã„æ„Ÿåº¦/ç‰¹ç•°åº¦ã®è¨ºæ–­ç²¾åº¦ç ”ç©¶ã®è¨ˆç”»
* å˜ä¸€ã®ã€Œæ­£ã—ã„ã€æ•°å€¤ã‚’æœŸå¾…ã™ã‚‹å ´åˆï¼šã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºè¨ˆç”»ã«ã¯ä»®å®šãŒå¿…è¦ã§ã‚ã‚Šã€æ„Ÿåº¦åˆ†æã‚’å«ã‚ã‚‹ã¹ãã§ã™

---

### åˆ©ç”¨å¯èƒ½ãªæ‰‹æ³• (æ¦‚è¦)

#### A. ã‚¯ã‚¤ãƒƒã‚¯ / åŸºæœ¬ (é«˜é€Ÿã€è¿‘ä¼¼)

**A1 â€” çµŒé¨“å‰‡ (EPV/EPP) (ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯)**
* **é©ç”¨:** è¨ˆç”»ã—ã¦ã„ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¯¾ã—ã¦ã‚¤ãƒ™ãƒ³ãƒˆãŒã€Œå¤§ã¾ã‹ã«ååˆ†ã€ã‹ã©ã†ã‹ã‚’ç´ æ—©ãç¢ºèªã™ã‚‹å¿…è¦ãŒã‚ã‚‹å ´åˆã€‚
* **ä¸é©ç”¨:** ãƒ¢ãƒ‡ãƒ«ã«ã‚¹ãƒ—ãƒ©ã‚¤ãƒ³/äº¤äº’ä½œç”¨/å¤‰æ•°é¸æŠãŒå«ã¾ã‚Œã‚‹å ´åˆã€ã¾ãŸã¯ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç‡ãŒä½ã„å ´åˆâ€”â€”EPV/EPP ã¯è‰¯å¥½ãªã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚„ä½ã„æ¥½è¦³çš„ãƒã‚¤ã‚¢ã‚¹ã‚’ä¿è¨¼ã—ã¾ã›ã‚“ã€‚
* **ä¸»ãªå…¥åŠ›:** ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç‡ $p$, ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ•° $P$ (df), ç›®æ¨™ EPP (ä¾‹: 10/15/20)
* **ä¸»ãªå‡ºåŠ›:** å¿…è¦ãªã‚¤ãƒ™ãƒ³ãƒˆæ•° $E=t \\cdot P$, å¿…è¦ãªã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚º $N=\\lceil E/p \\rceil$
* **é•·æ‰€:** éå¸¸ã«ã‚·ãƒ³ãƒ—ãƒ«ã€‚åˆæœŸã®å®Ÿç¾å¯èƒ½æ€§èª¿æŸ»ã«é©ã—ã¦ã„ã‚‹
* **çŸ­æ‰€:** èª¤è§£ã‚’æ‹›ãå¯èƒ½æ€§ãŒã‚ã‚‹ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«åŸºã¥ã„ã¦ã„ãªã„

**A2 â€” ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒªã‚¹ã‚¯ç²¾åº¦ (æœ‰ç—…ç‡ã® CI å¹…)**
* **é©ç”¨:** æ‰€æœ›ã® CI åŠå€¤å¹… (ä¾‹: Â±2%) ã§ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç‡ $p$ ã‚’æ¨å®šã™ã‚‹ã“ã¨ã‚’ç›®çš„ã¨ã™ã‚‹å ´åˆã€‚
* **ä¸é©ç”¨:** äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ä¿è¨¼ (AUC/ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹¾é…) ã‚’æ±‚ã‚ã‚‹å ´åˆã€‚
* **ä¸»ãªå…¥åŠ›:** äºˆæƒ³ã•ã‚Œã‚‹ $p$, CI æ‰‹æ³• (Wilson æ¨å¥¨), ä¿¡é ¼æ°´æº–, ç›®æ¨™åŠå€¤å¹… $d$
* **ä¸»ãªå‡ºåŠ›:** CI åŠå€¤å¹… $\\le d$ ã‚’æº€ãŸã™æœ€å° $N$
* **é•·æ‰€:** ç›´æ¥çš„ãªç²¾åº¦ã®ç›®æ¨™ã€‚é€æ˜ãªä»®å®š
* **çŸ­æ‰€:** æœ‰ç—…ç‡ã®ã¿ã«é–¢ä¿‚ã—ã€ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã§ã¯ãªã„

#### B. äºˆå¾Œå› å­ (æ¤œå‡ºåŠ›) (äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã§ã¯ãªãé–¢é€£æ€§ã«ç„¦ç‚¹)

**B3 â€” Logistic OR æ¤œå‡ºåŠ› (Hsieh)**
* **é©ç”¨:** Logistic å›å¸°ã«ãŠã‘ã‚‹äºˆå¾Œå› å­ã®ç›®æ¨™ã‚ªãƒƒã‚ºæ¯” (OR) ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®æ¤œå‡ºåŠ›ã‚’å¸Œæœ›ã™ã‚‹å ´åˆã€‚
* **ä¸é©ç”¨:** ä¸»ãªç›®çš„ãŒä»®èª¬æ¤œå®šã§ã¯ãªãã€äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º (ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³/è­˜åˆ¥èƒ½) ã§ã‚ã‚‹å ´åˆã€‚
* **ä¸»ãªå…¥åŠ›:** ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒªã‚¹ã‚¯ $p_0$, ç›®æ¨™ OR, Alpha, æ¤œå‡ºåŠ›, æš´éœ²æœ‰ç—…ç‡ (äºŒå€¤) ã¾ãŸã¯ SD (é€£ç¶š), å…±å¤‰é‡ã¨ã® $R^2$ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³)
* **ä¸»ãªå‡ºåŠ›:** OR ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã«å¿…è¦ãª $N$ (ãŠã‚ˆã³æš—é»™ã®ã‚¤ãƒ™ãƒ³ãƒˆæ•°)
* **é•·æ‰€:** é–¢é€£æ€§ã®ãŸã‚ã®å¤å…¸çš„ãªæ¤œå‡ºåŠ›ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
* **çŸ­æ‰€:** äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ‰±ã‚ãªã„ã€‚å…¥åŠ›ã®ä»®å®šã«æ•æ„Ÿ

**B4 â€” Cox HR æ¤œå‡ºåŠ› (Schoenfeld)**
* **é©ç”¨:** ç”Ÿå­˜æ™‚é–“ã‚¢ã‚¦ãƒˆã‚«ãƒ ; Cox PH ä¸‹ã§ãƒã‚¶ãƒ¼ãƒ‰æ¯” (HR) ã‚’æ¤œå‡ºã™ã‚‹ãŸã‚ã®æ¤œå‡ºåŠ›ã‚’å¸Œæœ›ã™ã‚‹å ´åˆã€‚
* **ä¸é©ç”¨:** PH ã®ä»®å®šãŒæº€ãŸã•ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚‹å ´åˆã€ã¾ãŸã¯ã‚¤ãƒ™ãƒ³ãƒˆå‰²åˆãŒéå¸¸ã«ä¸ç¢ºå®Ÿã§åˆç†çš„ã«æ¨å®šã§ããªã„å ´åˆã€‚
* **ä¸»ãªå…¥åŠ›:** HR, Alpha, æ¤œå‡ºåŠ›, å‰²ã‚Šå½“ã¦æ¯”ç‡ (äºŒå€¤) ã¾ãŸã¯ SD (é€£ç¶š), è¿½è·¡æœŸé–“ä¸­ã®äºˆæƒ³ã‚¤ãƒ™ãƒ³ãƒˆå‰²åˆ
* **ä¸»ãªå‡ºåŠ›:** å¿…è¦ãªã‚¤ãƒ™ãƒ³ãƒˆæ•°; ã‚¤ãƒ™ãƒ³ãƒˆå‰²åˆã‚’ä½¿ç”¨ã—ã¦ $N$ ã«å¤‰æ›
* **é•·æ‰€:** åºƒãå—ã‘å…¥ã‚Œã‚‰ã‚Œã¦ã„ã‚‹ã€‚ã‚¤ãƒ™ãƒ³ãƒˆãƒ™ãƒ¼ã‚¹ã®è¨ˆç”»ã¯ç›´æ„Ÿçš„
* **çŸ­æ‰€:** ã‚¤ãƒ™ãƒ³ãƒˆå‰²åˆã¨è¿½è·¡/æ‰“ã¡åˆ‡ã‚Šã®ä»®å®šã«å¼·ãä¾å­˜ã™ã‚‹

#### C. äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«é–‹ç™º (ãƒªã‚¹ã‚¯ãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰ã«æ¨å¥¨)

**C5 â€” Riley ç­‰ (è§£ææ³•; pmsampsize ã«é¡ä¼¼)**
* **é©ç”¨:** å¤šå¤‰é‡äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®é–‹ç™º; éå­¦ç¿’ã‚’åˆ¶å¾¡ã—ã€ååˆ†ãªç²¾åº¦ã‚’ç¢ºä¿ã—ãŸã„å ´åˆã€‚
* **ä¸é©ç”¨:** æœ‰ç—…ç‡ã¨äºˆæƒ³ã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ (AUC ã¾ãŸã¯ $R^2$) ã®åˆç†çš„ãªä»®å®šã‚’æä¾›ã§ããªã„å ´åˆã€‚ã“ã®å ´åˆã¯æ„Ÿåº¦åˆ†æã¾ãŸã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
* **ä¸»ãªå…¥åŠ›:** ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç‡ $p$, ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ $P$ (df), ç›®æ¨™åç¸®ç‡ (ä¾‹: 0.90), äºˆæƒ³ã•ã‚Œã‚‹ãƒ¢ãƒ‡ãƒ«ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ (AUC ã¾ãŸã¯ Coxâ€“Snell $R^2$)
* **ä¸»ãªå‡ºåŠ›:** è¤‡æ•°ã®åŸºæº– (éå­¦ç¿’åˆ¶å¾¡ + ç²¾åº¦) ã‚’æº€ãŸã™æœ€å° $N$
* **é•·æ‰€:** åŸå‰‡ã«åŸºã¥ã„ã¦ã„ã‚‹ã€‚ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹ã€‚åºƒãå¼•ç”¨ã•ã‚Œã¦ã„ã‚‹
* **çŸ­æ‰€:** ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã®ä»®å®šã«ä¾å­˜ã™ã‚‹ã€‚æ…é‡ãª df ã®ã‚«ã‚¦ãƒ³ãƒˆãŒå¿…è¦

**C6 â€” é–‹ç™ºã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (é »åº¦è«–; samplesizedev/ã‚«ã‚¹ã‚¿ãƒ  DGM)**
* **é©ç”¨:** ç‰¹ã«éç·šå½¢æ€§/äº¤äº’ä½œç”¨ã‚„ã‚«ã‚¹ã‚¿ãƒ ãƒ‡ãƒ¼ã‚¿æ§‹é€ ãŒã‚ã‚‹å ´åˆã«ã€ã€Œå®Ÿéš›ã«è¡Œã†ã“ã¨ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã€ã“ã¨ã‚’å¥½ã‚€å ´åˆã€‚
* **ä¸é©ç”¨:** åˆç†çš„ãªãƒ‡ãƒ¼ã‚¿ç”Ÿæˆãƒ¡ã‚«ãƒ‹ã‚ºãƒ  (DGM) ã‚’æŒ‡å®šã§ããªã„å ´åˆã€ã¾ãŸã¯å³æ™‚ã®çµæœãŒå¿…è¦ãªå ´åˆ (è¨ˆç®—é›†ç´„çš„)ã€‚
* **ä¸»ãªå…¥åŠ›:** å€™è£œ $N$ ã‚°ãƒªãƒƒãƒ‰, DGM ã®ä»®å®š (äºˆæ¸¬å› å­ã®åˆ†å¸ƒ/ç›¸é–¢/åŠ¹æœ), ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®æ¨™ (ä¾‹: ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹¾é…ã®ç¯„å›², AUC ã—ãã„å€¤), ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç¹°ã‚Šè¿”ã—å›æ•°, ã‚·ãƒ¼ãƒ‰
* **ä¸»ãªå‡ºåŠ›:** è¨±å®¹å¯èƒ½ãªç¢ºç‡/ç²¾åº¦ã§ç›®æ¨™ã‚’é”æˆã™ã‚‹æœ€å° $N$
* **é•·æ‰€:** æŸ”è»Ÿã€‚è¤‡é›‘ãªãƒ¢ãƒ‡ãƒªãƒ³ã‚°ã¨æ•´åˆã™ã‚‹
* **çŸ­æ‰€:** ä»®å®šãŒé‡ã„ã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„

**C7 â€” ãƒ™ã‚¤ã‚ºä¿è¨¼ (MCMC)**
* **é©ç”¨:** æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ãŒãƒ™ã‚¤ã‚º MCMC ã§æ¨å®šã•ã‚Œã‚‹äºˆå®šã§ã‚ã‚Šã€ä¿è¨¼ (äº‹å¾Œãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹/ç²¾åº¦ç›®æ¨™ã‚’æº€ãŸã™ç¢ºç‡) ã«åŸºã¥ãã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºã‚’å¸Œæœ›ã™ã‚‹å ´åˆã€‚
* **ä¸é©ç”¨:** äº‹å‰åˆ†å¸ƒã‚’æ­£å½“åŒ–ã§ããªã„ã€ã¾ãŸã¯è¨ˆç®—äºˆç®—ãŒé™ã‚‰ã‚Œã¦ã„ã‚‹å ´åˆã€‚
* **ä¸»ãªå…¥åŠ›:** DGM, äº‹å‰åˆ†å¸ƒ, å€™è£œ $N$, MCMC è¨­å®š, ä¿è¨¼ã—ãã„å€¤ (ä¾‹: 80%/90%), ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹/ç²¾åº¦ç›®æ¨™
* **ä¸»ãªå‡ºåŠ›:** ä¿è¨¼ã—ãã„å€¤ã‚’æº€ãŸã™æœ€å° $N$
* **é•·æ‰€:** ãƒ™ã‚¤ã‚ºãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã¨æ•´åˆã™ã‚‹ã€‚äº‹å¾ŒåŸºæº–ã‚’ç›´æ¥ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã«ã™ã‚‹
* **çŸ­æ‰€:** è¨ˆç®—é›†ç´„çš„ã€‚äº‹å‰åˆ†å¸ƒã®æŒ‡å®šãŒå¿…è¦

#### D. æ¤œè¨¼ / æ›´æ–° (æ—¢å­˜ãƒ¢ãƒ‡ãƒ«ç”¨)

**D8 â€” AUC ç²¾åº¦ (Hanleyâ€“McNeil / presize)**
* **é©ç”¨:** æ¤œè¨¼ã®ç›®æ¨™ãŒ AUC ã®ç²¾åº¦ (CI å¹…) ã§ã‚ã‚‹å ´åˆã€‚
* **ä¸é©ç”¨:** ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (å‹¾é…/CITL) ãŒä¸»ãªé–¢å¿ƒäº‹ã§ã‚ã‚‹å ´åˆâ€”â€”ã“ã®æ–¹æ³•ã¯ AUC ã®ã¿ã‚’å¯¾è±¡ã¨ã—ã¾ã™ã€‚
* **ä¸»ãªå…¥åŠ›:** äºˆæƒ³ã•ã‚Œã‚‹ AUC, æœ‰ç—…ç‡ã¾ãŸã¯ã‚±ãƒ¼ã‚¹ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«æ¯”, ä¿¡é ¼æ°´æº–, ç›®æ¨™ CI å¹…
* **ä¸»ãªå‡ºåŠ›:** æ‰€æœ›ã® AUC CI å¹…ã‚’é”æˆã™ã‚‹æœ€å° $N$
* **é•·æ‰€:** ã‚·ãƒ³ãƒ—ãƒ«ã€‚è­˜åˆ¥èƒ½ç²¾åº¦ã®ãŸã‚ã®è¿…é€Ÿãªè¨ˆç”»
* **çŸ­æ‰€:** è¿‘ä¼¼åˆ†æ•£ã€‚ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ç„¡è¦–ã™ã‚‹

**D9 â€” å¤–éƒ¨æ¤œè¨¼ (Tailored; pmvalsampsize / sampsizeval)**
* **é©ç”¨:** è¤‡æ•°ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ (ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ + è­˜åˆ¥èƒ½) ã«å¯¾ã—ã¦æ¤œè¨¼è¦æ¨¡ã‚’æ±ºå®šã—ãŸã„å ´åˆã§ã€é€šå¸¸ã¯ LP åˆ†å¸ƒã«é–¢ã™ã‚‹ä»®å®šãŒå¿…è¦ã§ã™ã€‚
* **ä¸é©ç”¨:** LP åˆ†å¸ƒã®ä»®å®šã‚„äºˆæƒ³ã•ã‚Œã‚‹ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’æ­£å½“åŒ–ã§ããªã„å ´åˆã€‚
* **ä¸»ãªå…¥åŠ›:** æœ‰ç—…ç‡, äºˆæƒ³ã•ã‚Œã‚‹ AUC, ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å‹¾é…/CITL ç›®æ¨™, CI å¹…ã¾ãŸã¯ SE ç›®æ¨™, LP åˆ†å¸ƒã®ä»®å®š
* **ä¸»ãªå‡ºåŠ›:** å„æŒ‡æ¨™ã®ç²¾åº¦åŸºæº–ã‚’æº€ãŸã™æ¨å¥¨ $N$
* **é•·æ‰€:** ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºã•ã‚Œã¦ã„ã‚‹ã€‚ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«ç„¦ç‚¹ã‚’å½“ã¦ã¦ã„ã‚‹
* **çŸ­æ‰€:** è¿½åŠ ã®ä»®å®šãŒå¿…è¦ã€‚ã‚ˆã‚Šè¤‡é›‘

**D10 â€” å¤–éƒ¨æ¤œè¨¼ (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³; LP ãƒ™ãƒ¼ã‚¹)**
* **é©ç”¨:** ç›®æ¨™æ¤œè¨¼é›†å›£ã«ãŠã‘ã‚‹ç·šå½¢äºˆæ¸¬å­ (LP) ã®åˆ†å¸ƒã‚’æŒ‡å®š/æ¨å®šã§ãã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã«åŸºã¥ãç²¾åº¦è¨ˆç”»ã‚’å¸Œæœ›ã™ã‚‹å ´åˆã€‚
* **ä¸é©ç”¨:** LP åˆ†å¸ƒãŒä¸æ˜ã§è¿‘ä¼¼ã§ããªã„å ´åˆã€‚
* **ä¸»ãªå…¥åŠ›:** LP åˆ†å¸ƒ (æ­£è¦/Beta/çµŒé¨“çš„), èª¤ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿, æŒ‡æ¨™ã® CI å¹…ç›®æ¨™, ç¹°ã‚Šè¿”ã—å›æ•°, ã‚·ãƒ¼ãƒ‰
* **ä¸»ãªå‡ºåŠ›:** ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸‹ã§ç²¾åº¦ç›®æ¨™ã‚’é”æˆã™ã‚‹æœ€å° $N$
* **é•·æ‰€:** éå¸¸ã«æŸ”è»Ÿã€‚ã€Œäºˆæƒ³ã•ã‚Œã‚‹çŠ¶æ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã™ã‚‹ã€ã“ã¨ã«ä¸€è‡´ã™ã‚‹
* **çŸ­æ‰€:** ä»®å®šãŒé‡ã„ã€‚è¨ˆç®—ã‚³ã‚¹ãƒˆãŒé«˜ã„

**D11 â€” æ›´æ–° / å†ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (Intercept/Slope)**
* **é©ç”¨:** æ—¢å­˜ã®ãƒ¢ãƒ‡ãƒ«ã‚’å†ã‚­ãƒ£ãƒªãƒ–ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (åˆ‡ç‰‡ãŠã‚ˆã³/ã¾ãŸã¯å‹¾é…ã®æ›´æ–°) ã—ã€ååˆ†ãªç²¾åº¦ã‚’å¿…è¦ã¨ã™ã‚‹å ´åˆã€‚
* **ä¸é©ç”¨:** å®Œå…¨ã«æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’é–‹ç™ºã—ã¦ã„ã‚‹å ´åˆ (C5â€“C7 ã‚’ä½¿ç”¨)ã€‚
* **ä¸»ãªå…¥åŠ›:** æ›´æ–°ã‚¿ã‚¤ãƒ— (åˆ‡ç‰‡ã®ã¿ vs åˆ‡ç‰‡+å‹¾é…), ã‚¤ãƒ™ãƒ³ãƒˆç™ºç”Ÿç‡, ç²¾åº¦ç›®æ¨™
* **ä¸»ãªå‡ºåŠ›:** å®‰å®šã—ãŸæ›´æ–°ã‚’è¡Œã†ã®ã«ååˆ†ãª $N$
* **é•·æ‰€:** å®Ÿéš›ã®å±•é–‹ã«å®Ÿç”¨çš„
* **çŸ­æ‰€:** åœ°åŸŸã®ã‚±ãƒ¼ã‚¹ãƒŸãƒƒã‚¯ã‚¹ã¨ãƒ¢ãƒ‡ãƒ«ã®ç§»æ¤æ€§ã®ä»®å®šã«ä¾å­˜ã™ã‚‹

---

#### å…è²¬äº‹é …

è‡¨åºŠçš„ãªä¿è¨¼ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¯æ¤œè¨¼ã¨è§£é‡ˆã«è²¬ä»»ã‚’è² ã„ã¾ã™ã€‚å¸¸ã«ä»®å®šã‚’è¨˜éŒ²ã—ã€æ„Ÿåº¦åˆ†æã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

#### é€£çµ¡å…ˆ

ä½œæˆè€…ã¨ç®¡ç†è€…: Minh Nguyen (minhnt@ump.edu.vn)
""",

    "a2_content_md": """
### What this is (English - Technical Details)

This module estimates the **minimum sample size (n)** needed to estimate the **baseline risk / event rate** (p) (i.e., prevalence of the outcome) with a **desired precision**, expressed as a **confidence interval (CI) half-width** (margin of error).

It is useful for:
* describing the outcome prevalence in a cohort with a specified precision,
* planning feasibility and reporting baseline risk,
* supporting calibration-related planning (e.g., calibration-in-the-large relies on the event rate).

**Important limitation:** This calculation **does not** ensure prediction model performance (AUC, calibration slope, optimism). It only targets precision for estimating (p).

---

### Inputs (what they mean)

1. **Outcome prevalence / event rate** (p)
   Expected proportion of events in the target population (e.g., 0.10).
   * If unknown, consider a plausible range and run a sensitivity analysis.
   * If you want a conservative â€œworst-caseâ€ for prevalence precision, use (p=0.50) (maximizes variance).

2. **Target half-width (margin of error)** (d)
   Desired precision such that the CI is approximately:
   $p \pm d$
   Examples: (d = 0.01, 0.02, 0.03) (i.e., Â±1%, Â±2%, Â±3%).

3. **Confidence level** (1-$\\alpha$)
   Typical values: 0.95 or 0.99.

4. **CI Method**
* **Wilson score (recommended):** better coverage than Wald, especially when (p) is near 0 or 1 or sample size is modest.
* **Wald (normal approximation):** simple closed form but can perform poorly for small (n) or extreme (p).
* **Clopperâ€“Pearson (exact):** conservative (often yields wider CIs; thus larger (n)).

---

### Core calculation

Let $X \sim \\text{Binomial}(n,p)$, $\hat p = X/n$. The goal is to find the smallest (n) such that the chosen CI method yields:
$$
\\frac{\\text{Upper}(n) - \\text{Lower}(n)}{2} \le d
$$

#### A) Wald (closed-form approximation)
$$ n \\approx \\frac{z^2 p(1-p)}{d^2} $$
**Note:** Fast but not recommended for small n or extreme p.

#### B) Wilson score interval (recommended)
Uses the Wilson score interval formula to find n. Since the interval depends on the observed count x, we iterate to find the smallest n where the half-width constraint is met for expected outcomes.

#### C) Clopperâ€“Pearson â€œexactâ€ interval
Uses Beta quantiles to form conservative intervals. Typically yields larger sample sizes.

---

### Practical defaults

* **Confidence level:** 95% is standard.
* **Half-width (d):** Â±0.01 to Â±0.03 (1%â€“3%) are common targets.
* **Method:** Wilson is a strong default.

### Key references
1. **Wilson EB.** Probable inference, the law of succession, and statistical inference. *JASA.* 1927.
2. **Newcombe RG.** Two-sided confidence intervals for the single proportion. *Stat Med.* 1998.
""",

    "b3_content_md": """
### Purpose (English - Technical Details)

This module estimates the **minimum sample size** needed to detect an association between a predictor (X) and a **binary outcome** (Y) using **logistic regression**, targeting a specified **odds ratio (OR)**, **two-sided ($\\alpha$)**, and **power**.

This is a **prognostic factor / association-focused** power calculation (testing a regression coefficient), **not** a prediction-model performance method. It does **not** guarantee good calibration or discrimination of a multivariable prediction model.

---

### When to use

Use B3 when:

* You want power to detect a **clinically meaningful OR** for a **single predictor** (binary or continuous) in logistic regression.
* Your primary goal is **hypothesis testing** (is the predictor associated with the outcome?), not building a risk prediction model.

### When NOT to use

Do not use B3 as your main approach when:

* Your goal is **prediction model development** (use Riley/pmsampsize or simulation/assurance methods).
* You plan **data-driven variable selection**, many interactions/splines, or complex machine-learning tuning (power for a single coefficient is not the right target).
* Data are **clustered** (multicenter/ward-level correlation) or strongly dependent without adjusting the design effect.
* You have a **caseâ€“control** design with fixed case/control sampling (baseline risks ($p_0$) may not represent the source population).

---

### Statistical model and parameters

Logistic regression model:
$$
\\text{logit}{P(Y=1\\mid X)}=\\beta_0+\\beta_1 X
$$

* For **binary** ($X\\in\\{0,1\\}$):
  $$
  \\mathrm{OR}=\\exp(\\beta_1)
  $$
* For **continuous** ($X$): OR must be defined for a specific change in ($X$), commonly **1 SD increase**.

Hypothesis test:
$$
H_0:\\beta_1=0 \\quad \\text{vs}\\quad H_1:\\beta_1\\neq 0
$$

---

### Inputs (what each value means)

1. **Alpha (two-sided)** ($\\alpha$)
   Common choices: 0.05 (standard), 0.01 (more stringent).

2. **Power** ($1-\\beta$)
   Common choices: 0.80 (standard), 0.90 (more conservative).

3. **Baseline event rate** ($p_0$)

   * For **binary predictor**: ($p_0 = P(Y=1\\mid X=0)$) (event rate in the reference group).
   * For **continuous predictor**: ($p_0$) is typically interpreted as the event rate at the **mean** of ($X$) (after centering).

4. **Target odds ratio** ($\\mathrm{OR}$)
   The smallest OR that is clinically meaningful and worth detecting.

5. **Predictor type**

* **Binary predictor**: requires **prevalence of (X=1)**, denoted ($q=P(X=1)$).
* **Continuous predictor**: typically requires the OR for a **1 SD increase** (or you must convert using SD).

6. **($R^2$) with other covariates**
   ($R^2$) is the squared multiple correlation from regressing ($X$) on other covariates in a multivariable model.

   * If ($X$) is correlated with other predictors, the effective information about ($\\beta_1$) decreases, so the required sample size increases.

---

# Calculation

## Step 1 â€” Convert OR and baseline risk to ($p_1$) (binary ($X$))

If ($X$) is binary, compute the event rate in the exposed group ($p_1=P(Y=1\\mid X=1)$) from ($p_0$) and OR:

$$
\\text{odds}_0=\\frac{p_0}{1-p_0},\\quad \\text{odds}_1=\\mathrm{OR}\\cdot \\text{odds}_0,\\quad
p_1=\\frac{\\text{odds}_1}{1+\\text{odds}_1}
$$

Overall event rate:
$$
p=(1-q)p_0+q p_1
$$

## Step 2 â€” Z-scores

Let:
$$
z_{\\alpha}=z_{1-\\alpha/2}, \\qquad z_{\\beta}=z_{1-\\beta}=z_{\\text{power}}
$$

## A) Binary predictor sample size (Hsieh approach)

With ($q=P(X=1)$), ($p_0=P(Y=1\\mid X=0)$), ($p_1=P(Y=1\\mid X=1)$), and ($p$) as above:

$$
n_0=
\\frac{
\\left[
z_{\\alpha}\\sqrt{\\frac{p(1-p)}{q(1-q)}}
+
z_{\\beta}\\sqrt{\\frac{p_1(1-p_1)}{q}+\\frac{p_0(1-p_0)}{1-q}}
\\right]^2
}
{(p_1-p_0)^2}
$$

### Adjustment for correlation with other covariates

If you plan a multivariable model and the predictor of interest ($X$) correlates with other covariates, inflate the sample size using:

$$
n=\\frac{n_0}{1-R^2}
$$

### Expected number of events

$$
E \\approx n\\cdot p
$$

---

## B) Continuous predictor sample size (Hsieh approach)

Assume a logistic model with a continuous predictor ($X$) and define OR for a **1 SD increase** in ($X$), denoted ($\\mathrm{OR}_{SD}$). Let ($p_0$) be the event rate at the mean of ($X$):

$$
n_0=\\frac{(z_{\\alpha}+z_{\\beta})^2}{p_0(1-p_0) [\\log(\\mathrm{OR}_{SD})]^2}
$$

If the user has an OR per 1-unit increase, ($\\mathrm{OR}_{unit}$), and SD of ($X$) is ($\\sigma_X$), convert:
$$
\\log(\\mathrm{OR}_{SD})=\\log(\\mathrm{OR}_{unit})\\cdot \\sigma_X
$$

Then apply the same multivariable correlation inflation:
$$
n=\\frac{n_0}{1-R^2}
$$

---

## Practical guidance: what values to choose (common conventions)

* **($\\alpha$)**: 0.05 (two-sided) is typical; use smaller ($\\alpha$) if multiple testing is expected.
* **Power**: 0.80 is common; 0.90 is preferred when missing the effect would be costly.
* **OR**: choose the **minimum clinically meaningful** OR (often in the 1.2â€“2.0 range depending on context).
* **Baseline risk ($p_0$)**: use local hospital/cohort data if available; otherwise use literature estimates and run sensitivity analyses.
* **Binary predictor prevalence ($q$)**: use local prevalence; note ($q$) near 0.5 gives the **largest information** (smaller ($n$)); very small/large ($q$) increases required ($n$).
* **($R^2$)**: if uncertain, run a sensitivity range (e.g., 0, 0.1, 0.25, 0.5). Even moderate correlation can inflate ($n$) substantially via ($1/(1-R^2)$).
* **Continuous predictors**: consider standardizing ($X$) to mean 0, SD 1 so ($\\mathrm{OR}_{SD}$) is easy to interpret.

---

## Key references (2â€“5)

1. Hsieh FY, Bloch DA, Larsen MD. *A simple method of sample size calculation for linear and logistic regression.* Statistics in Medicine. 1998;17(14):1623â€“1634.
2. Hsieh FY. *Sample size tables for logistic regression.* Statistics in Medicine. 1989;8(7):795â€“802.
3. Whittemore AS. *Sample size for logistic regression with small response probability.* Journal of the American Statistical Association. 1981;76:27â€“32.
""",
    "c5_content_md": """
### What this method is (English - Technical Details)

C5 implements the **Riley et al. analytical minimum sample size criteria** for **developing a multivariable clinical prediction model** with a **binary outcome** (logistic regression). The goal is to ensure the development dataset is large enough to:

1. **Limit overfitting** (via a target global shrinkage / calibration slope),
2. Achieve **adequate precision** for model performance (via a bound on optimism in $R^2$), and
3. Estimate the **overall outcome risk** (intercept/baseline risk) with acceptable precision.

This is a **model development** method (not external validation). It is particularly suitable when you plan a **pre-specified model form** (predictors and coding defined in advance) and want a **principled alternative to EPV rules**.

---

### When to use

Use C5 when:

* You are **developing** a new prediction model for a **binary outcome**.
* You can specify (even approximately) the **event rate** and an anticipated **overall model performance** (Coxâ€“Snell $R^2$ or AUC).
* You want to target **low overfitting** (e.g., shrinkage $S \\ge 0.90$) and reasonable precision.

### When NOT to use (or use with caution)

Do not rely on C5 alone when:

* You will do extensive **data-driven variable selection**, multiple interactions/splines, or heavy ML tuning without adjusting the **effective number of parameters (df)**.
* Your data are strongly **clustered** (multicenter) without accounting for design effects.
* The intended modeling approach is not standard logistic regression (e.g., complex ML) unless you map complexity to an appropriate **effective df** or switch to simulation-based sizing.
* You cannot justify any plausible performance input (AUC/$R^2$); in that case run wide sensitivity analyses and consider simulation-based methods.

---

## Key inputs (what each means)

1. **Outcome prevalence / event rate** (p)
   Expected proportion with (Y=1) in the development dataset.

2. **Number of predictor parameters (df)** (P)
   Total degrees of freedom for all candidate predictors **excluding the intercept**.
   Include: dummy variables, spline bases, interactions (and any other basis expansions).

3. **Anticipated performance** (choose one)

* **Coxâ€“Snell ($R^2_{CS}$)**: preferred if available from related prior studies (ideally optimism-adjusted).
* **AUC (C-statistic)**: if $R^2_{CS}$ is unavailable, the tool can approximate $R^2_{CS}$ from AUC and ($p$) using a published approach.
* **Conservative (15% of max $R^2$)**: a fallback when neither AUC nor $R^2$ is available; use with caution.

4. **Target global shrinkage** (S)
   A target for **overall overfitting control** (often interpreted similarly to an expected calibration slope after internal validation).

* Common default: $S = 0.90$ ($\\approx$ 10% shrinkage of predictor effects).
* More conservative: $S = 0.95$ (requires larger sample size).

---

## Core concepts and formulas

### Coxâ€“Snell ($R^2$) and its maximum

Coxâ€“Snell ($R^2$) for a fitted logistic model can be written as:
$$
R^2_{CS} = 1-\\exp!\\left(\\frac{2}{n}(\\ell_0-\\ell_1)\\right),
$$
where (\\ell_0) is the intercept-only log-likelihood and (\\ell_1) is the model log-likelihood.

For binary outcomes, ($R^2_{CS}$) cannot reach 1. Its maximum depends on the outcome prevalence:
$$
\\ell_0 = n\\Big[p\\ln(p) + (1-p)\\ln(1-p)\\Big],
$$
$$
R^2_{CS,\\max}=1-\\exp!\\left(\\frac{2\\ell_0}{n}\\right)
=1-\\exp!\\Big(2[p\\ln(p) + (1-p)\\ln(1-p)]\\Big).
$$

Nagelkerke ($R^2$) rescales Coxâ€“Snell ($R^2$) to ([0,1]):
$$
R^2_{Nag}=\\frac{R^2_{CS}}{R^2_{CS,\\max}}.
$$

---

## The three Riley criteria (binary outcome)

### Criterion 1 â€” Control overfitting via target shrinkage (S)

Minimum sample size to target global shrinkage (S):
$$
n_1=\\left\\lceil
\\frac{P}{(S-1),\\ln!\\left(1-\\frac{R^2_{CS}}{S}\\right)}
\\right\\rceil.
$$

### Criterion 2 â€” Limit optimism in ($R^2$) (default absolute difference 0.05)

This criterion targets a small absolute difference (default (\\delta=0.05)) between apparent and adjusted **Nagelkerke** ($R^2$). The required shrinkage implied by this constraint is:
$$
S_{\\delta}=\\frac{R^2_{CS}}{R^2_{CS}+\\delta,R^2_{CS,\\max}}.
$$
Then:
$$
n_2=\\left\\lceil
\\frac{P}{(S_{\\delta}-1),\\ln!\\left(1-\\frac{R^2_{CS}}{S_{\\delta}}\\right)}
\\right\\rceil.
$$

### Criterion 3 â€” Precise estimation of the overall outcome risk (intercept)

This targets precision of the **average outcome risk** (p) (baseline risk) within (\\pm d) on the probability scale (default (d=0.05) at 95% CI):
$$
n_3=\\left\\lceil
\\left(\\frac{z_{1-\\alpha/2}}{d}\\right)^2 p(1-p)
\\right\\rceil,
\\quad \\text{default } z_{0.975}=1.96,; d=0.05.
$$

### Final recommendation

$$
n_{\\min}=\\max(n_1,n_2,n_3),\\qquad
E = n_{\\min},p,\\qquad
EPP=\\frac{E}{P}.
$$

---

## Practical guidance (typical choices)

* **Shrinkage (S)**: use **0.90** as a standard target; consider **0.95** if you want stronger overfitting control or if the model is complex.
* **(\\delta=0.05)** for Criterion 2: commonly kept at the default.
* **Intercept precision (d=0.05)**: default corresponds to estimating baseline risk within Â±5%. If baseline risk must be estimated more precisely, you would need a smaller (d) (larger (n)).
* **Anticipated ($R^2_{CS}$)**:

  * Prefer **optimism-adjusted** values from related studies (or apparent values from external validation data).
  * If only AUC is available, use the published AUCâ†’($R^2_{CS}$) approximation method.
  * If neither is available, the **15% of ($R^2_{CS,\\max}$)** option is a conservative fallback for exploratory planningâ€”always run sensitivity analyses.

---

## Key references (2â€“5)

1. Riley RD, Snell KIE, Ensor J, et al. *Minimum sample size required for developing a multivariable prediction model: PART IIâ€”binary and time-to-event outcomes.* Statistics in Medicine. 2019.
2. Riley RD, Ensor J, Snell KIE, et al. *Calculating the sample size required for developing a clinical prediction model.* BMJ. 2020.
3. Riley RD, Van Calster B, Collins GS. *A note on estimating the Coxâ€“Snell ($R^2$) from a reported C statistic (AUROC) to inform sample size calculations for developing a prediction model with a binary outcome.* Statistics in Medicine. 2021.
4. Harrell FE Jr, Lee KL, Mark DB. *Multivariable prognostic models: issues in developing models, evaluating assumptions and adequacy, and measuring and reducing errors.* Statistics in Medicine. 1996.
""",
    "c6_content_md": """
## C6: Development Simulation (Frequentist; custom DGM) (English - Technical Details)

### What this method is

C6 is a **simulation-based sample size planning** approach for **prediction model development** (binary outcome), inspired by the philosophy of **samplesizedev** and broader simulation-based design principles.

Instead of relying on a single analytical formula, C6 asks:

> â€œIf we repeatedly develop the model using the planned approach on datasets of size (N), how often will the model meet pre-specified performance criteria on new data?â€

It therefore targets **expected performance** (and/or probability of acceptable performance) under a **data-generating mechanism (DGM)** that represents your anticipated clinical population.

---

## When to use

Use C6 when:

* You want a planning method aligned with â€œ**simulate what you will do**,â€ especially when:

  * predictors may be correlated,
  * you include non-linear terms or interactions,
  * event rates are modest or uncertain,
  * you want criteria based on **calibration** and **discrimination**.
* You can specify a reasonable DGM using local data or the literature.
* You are comfortable with simulation and want a more flexible alternative to purely analytical sizing.

## When NOT to use (or use with caution)

Avoid relying on C6 alone when:

* You cannot justify a plausible DGM (predictor distribution, correlations, effect sizes).
* You do not have computational budget (simulation can be expensive).
* You plan highly data-adaptive ML pipelines (feature selection, complex tuning) without explicitly simulating the full pipeline (C6 must reflect the actual pipeline to be valid).
* The target population is heterogeneous across hospitals/centers and you are not simulating clustering/case-mix shifts.

---

# Overview of the algorithm

For each candidate sample size (N), simulate (R) development datasets, fit the planned model, evaluate it on â€œnew data,â€ and summarize performance.

### Step 1 â€” Choose a DGM

Define how predictors (X) and outcomes (Y) are generated.

Typical binary-outcome DGM:
$$
Y \mid X \sim \\text{Bernoulli}(\\pi), \\qquad
\\pi = \\text{logit}^{-1}(\\eta),
$$
$$
\\eta = \\beta_0 + \\sum_{j=1}^{P}\\beta_j f_j(X_j),
$$
where:

* (P) is the **number of parameters/df** used in the fitted model,
* (f_j(\\cdot)) represent coding choices (linear term, spline basis, dummy coding, etc.).

To achieve a target event rate (p), choose (\\beta_0) so that:
$$
\\mathbb{E}[\\pi] = p.
$$
In practice, (\\beta_0) is found by numerical root-finding using Monte Carlo draws from (X).

### Step 2 â€” Generate a development dataset

For replicate (r):

* Simulate (X^{(r)}) of size (N) from the chosen predictor distribution (with specified correlations).
* Simulate (Y^{(r)}) from the Bernoulli model above.

### Step 3 â€” Fit the development model

Fit the planned logistic regression model:
$$
\\widehat{\\eta} = \\widehat{\\beta}*0 + \\sum*{j=1}^{P}\\widehat{\\beta}_j f_j(X_j).
$$
**Important:** Simulation must match your intended development strategy (e.g., penalization, pre-specified terms). If separation/non-convergence occurs, a ridge-penalized fallback is often used (and should be counted and reported).

### Step 4 â€” Evaluate on new data

Generate an independent test set (size (N_{\\text{test}}), often large such as 5000â€“10000) from the same DGM and compute:

**(a) Discrimination (AUC / C-statistic)**
$$
\\mathrm{AUC}=\\Pr(\\widehat{\\eta}_1 > \\widehat{\\eta}_0),
$$
the probability that a randomly selected case has a higher predicted risk than a non-case.

**(b) Calibration slope**
Estimate (b) from a calibration model on the test set:
$$
\\text{logit}(Y) = a + b \\cdot \\text{logit}(\\widehat{p}),
$$
or equivalently using the linear predictor:
$$
\\text{logit}(Y) = a + b \\cdot \\widehat{\\eta}.
$$
Here, (b\\approx 1) indicates good calibration; (b<1) suggests overfitting (predictions too extreme).

### Step 5 â€” Define pass/fail criteria and compute success rates

Across (R) simulations for each (N), compute:

* Mean calibration slope:
  $$
  \\overline{b} = \\frac{1}{R}\\sum_{r=1}^R b^{(r)}.
  $$
* Probability slope is within an acceptable range:
  $$
  \\widehat{\\Pr}(b \\in [L,U]) = \\frac{1}{R}\\sum_{r=1}^R \\mathbf{1}{b^{(r)}\\in[L,U]}.
  $$
* Mean AUC:
  $$
  \\overline{\\mathrm{AUC}}=\\frac{1}{R}\\sum_{r=1}^R \\mathrm{AUC}^{(r)}.
  $$

A candidate (N) is â€œacceptableâ€ if all selected criteria are met, e.g.:

* (\\overline{b} \\ge 0.90)
* (\\widehat{\\Pr}(0.9 \\le b \\le 1.1) \\ge 0.80)
* (\\overline{\\mathrm{AUC}} \\ge \\mathrm{AUC}_{\\text{target}})

Choose smallest (N) that passes.

---

# Key inputs (where to find, what to pick)

### 1) Event rate (p)

**Where:** local hospital/cohort data; literature default.
**Planning range:** 5%â€“15% (fluctuates by disease).
**Recommendation:** run sensitivity on plausible range.

### 2) Parameters (df) (P)

**Where:** intended model specification (including dummies, splines, interactions).
**Typical:** 10â€“30 df common; more df demands much larger N.

### 3) Target AUC (Mode A)

**Where:** similar published models (ideally external validation); pilot data.
**Typical:** 0.70â€“0.85 common; >0.90 rare/often optimistic.

### 4) Candidates (N)

Choose a range wide enough to see the pass/fail transition (e.g., 1000â€“5000).

### 5) Simulations per N (R)

* Demo: (R \\approx 200)
* Final: (R \\ge 1000)
  Monte Carlo Error for success probability:
  $$
  \\mathrm{MCSE}=\\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{R}}.
  $$

### 6) Pass/Fail Criteria

* Mean calibration slope â‰¥ 0.9
* Pr(0.9 â‰¤ slope â‰¤ 1.1) â‰¥ 80%
* Mean AUC â‰¥ target

**Convention:** slope 0.90-1.10 and 0.80 probability threshold often used for planning; 0.90 for stricter requirements.

---

# Strengths & Weaknesses

**Strengths**

* Flexible (correlation, non-linearity, interactions).
* Targets performance on new data directly, specifically calibration.
* Easy to do sensitivity analysis.

**Weaknesses**

* Strong dependence on DGM assumptions.
* Computationally expensive.
* Must simulate the exact intended pipeline; mismatches lead to invalid N.

---

## Key references (2â€“5)

1. Pavlou M, Ambler G, Seaman SR, et al. *How to develop a more accurate risk prediction model when there are few events.* BMJ. 2015.
2. Riley RD, Snell KIE, Ensor J, et al. *Minimum sample size required for developing a multivariable prediction model: Part IIâ€”binary and time-to-event outcomes.* Statistics in Medicine. 2019.
3. Pavlou M, et al. *Simulation-based sample size calculation for prediction model performance targets* (validation/development methodology). Statistics in Medicine. 2021.
4. Steyerberg EW. *Clinical Prediction Models: A Practical Approach to Development, Validation, and Updating.* 2nd ed. Springer. 2019.
""",
    "c7_content_md": """
## C7: Bayesian Assurance (MCMC) (English - Technical Details)

### What this method is
**Bayesian assurance** is a simulation-based sample size planning method for **Bayesian model building** (here: Bayesian logistic regression for binary outcomes).
Unlike "power" (frequentist), assurance targets the **unconditional probability** that the study will yield a **successful outcome** given the priors.

Simply put:
> "If we repeat the full study many times (generate data + fit Bayes via MCMC), what is the probability the model meets requirements?"

---

### When to use
Use C7 when:
- The final analysis will be **Bayesian** estimated via **MCMC**.
- You want to sample size for a target **success probability** (e.g., â‰¥80% or â‰¥90%).
- You can make reasonable assumptions about:
  - event rates,
  - predictor correlations,
  - plausible effect sizes (pilot/literature),
  - priors for regression coefficients.

### When NOT to use (or use with caution)
- You are doing frequentist analysis (use C5 or C6).
- Computational resources are very limited (MCMC inside simulation is slow).
- You have no idea about priors.
"""
}
